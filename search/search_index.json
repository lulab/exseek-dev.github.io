{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"exSeek Workflow Installation Install required software packages according to installation Download the scripts: git clone https://github.com/lulab/exSeek-dev.git Input files Genome and annotation directory Download preprocessed genome annotations to genome/hg38 Refer to the documentation for details. Input data files File name Description ${input_dir}/fastq/${sample_id}.fastq Read files (single-end sequencing) ${input_dir}/fastq/${sample_id}_1.fastq , ${input_dir}/fastq/${sample_id}_2.fastq Read files (paired-end sequencing) ${input_dir}/sample_ids.txt A text file with one sample ID per line. ${input_dir}/sample_classes.txt A tab-deliminated file (with header) with two columns: sample_id, label (optional) ${input_dir}/batch_info.txt A comma-deliminated file (with header) with at least two columns: sample_id, batch1, batch2, ... (optional) ${input_dir}/compare_groups.yaml A YAML file defining positive and negative classes. (optional) ${config_dir}/${dataset}.yaml A YAML file for configuration parameters for the dataset compare_groups.yaml Every key-value pairs defines a compare group and a negative-positive class pair: Normal-CRC: [\"Healthy Control\", \"Colorectal Cancer\"] Dataset configuration file All parameters are specified in a configuration file in YAML format. The default configuration file is (snakemake/default_config.yaml). Example configuration files can be found in config/ . The parameter values in the configuration file can also be overrided through the --config option in snakemake . The following parameters should be changed: Parameter Description Example genome_dir Directory for genome and annotation files genome/hg38 data_dir Directory for input files data/dataset temp_dir Temporary directory tmp output_dir Directory for all output files output/dataset aligner Mapping software bowtie2 adaptor 3' adaptor sequence for single-end RNA-seq AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC Cluster configuration file Please refer the link for descriptions of cluster configuration file. Basic usage of exSeek Run exseek.py --help to get basic usage: usage: exseek.py [-h] --dataset DATASET [--config-dir CONFIG_DIR] [--cluster] [--cluster-config CLUSTER_CONFIG] [--cluster-command CLUSTER_COMMAND] [--singularity SINGULARITY] [--singularity-wrapper-dir SINGULARITY_WRAPPER_DIR] {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} exSeek main program positional arguments: {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} optional arguments: -h, --help show this help message and exit --dataset DATASET, -d DATASET dataset name --config-dir CONFIG_DIR, -c CONFIG_DIR directory for configuration files --cluster submit to cluster --cluster-config CLUSTER_CONFIG cluster configuration file ({config_dir}/cluster.yaml by default) --cluster-command CLUSTER_COMMAND command for submitting job to cluster (default read from {config_dir}/cluster_command.txt --singularity SINGULARITY singularity image file --singularity-wrapper-dir SINGULARITY_WRAPPER_DIR directory for singularity wrappers Note Other arguments are passed to snakemake Specify number of processes to run in parallel with -j Small RNA-seq analysis Configuration file An example configuration file for small RNA single-end sequencing can be found in config/small_se_example.yaml . Quality control, adaptor removal and trimming ${exseek_path}/bin/exseek.py quality_control --dataset ${dataset} Mapping exseek.py mapping --dataset ${dataset} Note If you changed mapping order in the rna_types config variable, you should update the snakefile with the command: exseek.py update_sequential_mapping --dataset ${dataset} Description of output files: output_files Generate count matrix ${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset} Count matrix File path: ${output_dir}/count_matrix/transcript.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name Call domains ${exseek_path}/bin/exseek.py call_domains --dataset ${dataset} Read count matrix File path: ${output_dir}/count_matrix/domain_long.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name|domain_id|transcript_id|start|end Combine read counts of miRNA/piRNA and domains ${exseek_path}/bin/exseek.py combine_domains --dataset ${dataset} Normalization ${exseek_path}/bin/exseek.py normalization --dataset ${dataset} Feature selection ${exseek_path}/bin/exseek.py feature_selection --dataset ${dataset} Differential expression ${exseek_path}/bin/exseek.py differential_expression --dataset ${dataset} Long RNA-seq analysis Configuration file An example configuration file for long RNA paired-end sequencing can be found in config/long_pe_example.yaml . Quality control and adaptor removal ${exseek_path}/bin/exseek.py quality_control --dataset ${dataset} Mapping ${exseek_path}/bin/exseek.py mapping --dataset ${dataset} Generate count matrix ${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset} Frequently asked Questions FAQs","title":"Overview"},{"location":"#exseek","text":"","title":"exSeek"},{"location":"#workflow","text":"","title":"Workflow"},{"location":"#installation","text":"Install required software packages according to installation Download the scripts: git clone https://github.com/lulab/exSeek-dev.git","title":"Installation"},{"location":"#input-files","text":"","title":"Input files"},{"location":"#genome-and-annotation-directory","text":"Download preprocessed genome annotations to genome/hg38 Refer to the documentation for details.","title":"Genome and annotation directory"},{"location":"#input-data-files","text":"File name Description ${input_dir}/fastq/${sample_id}.fastq Read files (single-end sequencing) ${input_dir}/fastq/${sample_id}_1.fastq , ${input_dir}/fastq/${sample_id}_2.fastq Read files (paired-end sequencing) ${input_dir}/sample_ids.txt A text file with one sample ID per line. ${input_dir}/sample_classes.txt A tab-deliminated file (with header) with two columns: sample_id, label (optional) ${input_dir}/batch_info.txt A comma-deliminated file (with header) with at least two columns: sample_id, batch1, batch2, ... (optional) ${input_dir}/compare_groups.yaml A YAML file defining positive and negative classes. (optional) ${config_dir}/${dataset}.yaml A YAML file for configuration parameters for the dataset compare_groups.yaml Every key-value pairs defines a compare group and a negative-positive class pair: Normal-CRC: [\"Healthy Control\", \"Colorectal Cancer\"]","title":"Input data files"},{"location":"#dataset-configuration-file","text":"All parameters are specified in a configuration file in YAML format. The default configuration file is (snakemake/default_config.yaml). Example configuration files can be found in config/ . The parameter values in the configuration file can also be overrided through the --config option in snakemake . The following parameters should be changed: Parameter Description Example genome_dir Directory for genome and annotation files genome/hg38 data_dir Directory for input files data/dataset temp_dir Temporary directory tmp output_dir Directory for all output files output/dataset aligner Mapping software bowtie2 adaptor 3' adaptor sequence for single-end RNA-seq AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC","title":"Dataset configuration file"},{"location":"#cluster-configuration-file","text":"Please refer the link for descriptions of cluster configuration file.","title":"Cluster configuration file"},{"location":"#basic-usage-of-exseek","text":"Run exseek.py --help to get basic usage: usage: exseek.py [-h] --dataset DATASET [--config-dir CONFIG_DIR] [--cluster] [--cluster-config CLUSTER_CONFIG] [--cluster-command CLUSTER_COMMAND] [--singularity SINGULARITY] [--singularity-wrapper-dir SINGULARITY_WRAPPER_DIR] {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} exSeek main program positional arguments: {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} optional arguments: -h, --help show this help message and exit --dataset DATASET, -d DATASET dataset name --config-dir CONFIG_DIR, -c CONFIG_DIR directory for configuration files --cluster submit to cluster --cluster-config CLUSTER_CONFIG cluster configuration file ({config_dir}/cluster.yaml by default) --cluster-command CLUSTER_COMMAND command for submitting job to cluster (default read from {config_dir}/cluster_command.txt --singularity SINGULARITY singularity image file --singularity-wrapper-dir SINGULARITY_WRAPPER_DIR directory for singularity wrappers Note Other arguments are passed to snakemake Specify number of processes to run in parallel with -j","title":"Basic usage of exSeek"},{"location":"#small-rna-seq-analysis","text":"","title":"Small RNA-seq analysis"},{"location":"#configuration-file","text":"An example configuration file for small RNA single-end sequencing can be found in config/small_se_example.yaml .","title":"Configuration file"},{"location":"#quality-control-adaptor-removal-and-trimming","text":"${exseek_path}/bin/exseek.py quality_control --dataset ${dataset}","title":"Quality control, adaptor removal and trimming"},{"location":"#mapping","text":"exseek.py mapping --dataset ${dataset} Note If you changed mapping order in the rna_types config variable, you should update the snakefile with the command: exseek.py update_sequential_mapping --dataset ${dataset} Description of output files: output_files","title":"Mapping"},{"location":"#generate-count-matrix","text":"${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset} Count matrix File path: ${output_dir}/count_matrix/transcript.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name","title":"Generate count matrix"},{"location":"#call-domains","text":"${exseek_path}/bin/exseek.py call_domains --dataset ${dataset} Read count matrix File path: ${output_dir}/count_matrix/domain_long.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name|domain_id|transcript_id|start|end","title":"Call domains"},{"location":"#combine-read-counts-of-mirnapirna-and-domains","text":"${exseek_path}/bin/exseek.py combine_domains --dataset ${dataset}","title":"Combine read counts of miRNA/piRNA and domains"},{"location":"#normalization","text":"${exseek_path}/bin/exseek.py normalization --dataset ${dataset}","title":"Normalization"},{"location":"#feature-selection","text":"${exseek_path}/bin/exseek.py feature_selection --dataset ${dataset}","title":"Feature selection"},{"location":"#differential-expression","text":"${exseek_path}/bin/exseek.py differential_expression --dataset ${dataset}","title":"Differential expression"},{"location":"#long-rna-seq-analysis","text":"","title":"Long RNA-seq analysis"},{"location":"#configuration-file_1","text":"An example configuration file for long RNA paired-end sequencing can be found in config/long_pe_example.yaml .","title":"Configuration file"},{"location":"#quality-control-and-adaptor-removal","text":"${exseek_path}/bin/exseek.py quality_control --dataset ${dataset}","title":"Quality control and adaptor removal"},{"location":"#mapping_1","text":"${exseek_path}/bin/exseek.py mapping --dataset ${dataset}","title":"Mapping"},{"location":"#generate-count-matrix_1","text":"${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset}","title":"Generate count matrix"},{"location":"#frequently-asked-questions","text":"FAQs","title":"Frequently asked Questions"},{"location":"FAQ/","text":"Frequently Asked Questions How to install and set up the environment We have packaged everything into docker and singularity. The easiest and recommended way is via Singularity. You can refer to this doc's Singularity part How to use exSeek exSeek is an integrative tool for exRNA processing and feature selection. We use snakemake for parallel running and further integrate snakemake pipeline into one single command. Details of preparing steps are described here . Basically you should complete the following steps before running the command: Install exseek and requirements Prepare genome and annotation prepare input files in right file path set up configuration Then you can run the command, you can specify the module you want to run and dataset you provide. ${exseek_path}/bin/exseek.py quality_control --dataset ${dataset} What is Snakemake The Snakemake workflow management system is a tool to create reproducible and scalable data analyses. We have hide the details of snakemake and you only need to run one single command. However you can customize some of the codes if you are familiar with snakemake. How to set configurations in config file There are many parameters to be specified. You should make a new copy of config file in config directory. For example you can nake one copy of scirep.yaml. Then rename the file to config/${dataset}.yaml. Other parameters are defined in snakemake/default_config.yaml. You may also change parameters. How to generate report After running some modules, e.g., mapping, normalization and evaluation. You can open jupyter notebook files in notebooks file. The only thing to do is to fill in the dataset name and sequencing type. For example: dataset='scirep' sequencing_type = 'short' Then you can get plots of your mapping, processing and feature selection details in one jupyter notebook. Note: the notebook is based on exseek output style. If you process your data on your own without exseek and only need the jupyter to generate plots, you should change the codes for file paths in jupyter notebook to successfully generate plots. When bugs appear: The quickest way is to create a new issue If you want us to add more functions in exseek, please create a new issue","title":"Frequently Asked Questions"},{"location":"FAQ/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"FAQ/#how-to-install-and-set-up-the-environment","text":"We have packaged everything into docker and singularity. The easiest and recommended way is via Singularity. You can refer to this doc's Singularity part","title":"How to install and set up the environment"},{"location":"FAQ/#how-to-use-exseek","text":"exSeek is an integrative tool for exRNA processing and feature selection. We use snakemake for parallel running and further integrate snakemake pipeline into one single command. Details of preparing steps are described here . Basically you should complete the following steps before running the command: Install exseek and requirements Prepare genome and annotation prepare input files in right file path set up configuration Then you can run the command, you can specify the module you want to run and dataset you provide. ${exseek_path}/bin/exseek.py quality_control --dataset ${dataset}","title":"How to use exSeek"},{"location":"FAQ/#what-is-snakemake","text":"The Snakemake workflow management system is a tool to create reproducible and scalable data analyses. We have hide the details of snakemake and you only need to run one single command. However you can customize some of the codes if you are familiar with snakemake.","title":"What is Snakemake"},{"location":"FAQ/#how-to-set-configurations-in-config-file","text":"There are many parameters to be specified. You should make a new copy of config file in config directory. For example you can nake one copy of scirep.yaml. Then rename the file to config/${dataset}.yaml. Other parameters are defined in snakemake/default_config.yaml. You may also change parameters.","title":"How to set configurations in config file"},{"location":"FAQ/#how-to-generate-report","text":"After running some modules, e.g., mapping, normalization and evaluation. You can open jupyter notebook files in notebooks file. The only thing to do is to fill in the dataset name and sequencing type. For example: dataset='scirep' sequencing_type = 'short' Then you can get plots of your mapping, processing and feature selection details in one jupyter notebook. Note: the notebook is based on exseek output style. If you process your data on your own without exseek and only need the jupyter to generate plots, you should change the codes for file paths in jupyter notebook to successfully generate plots.","title":"How to generate report"},{"location":"FAQ/#when-bugs-appear","text":"The quickest way is to create a new issue If you want us to add more functions in exseek, please create a new issue","title":"When bugs appear:"},{"location":"adapter_removal/","text":"","title":"Adapter Removal"},{"location":"bigwig/","text":"","title":"Generate BigWig Files"},{"location":"cluster_configuration/","text":"Cluster configuration cluster configuration : config/cluster.yaml Here is an example configuration: __default__: queue: queue name: {rule}.{wildcards} stderr: logs/cluster/{rule}/{wildcards}.stderr stdout: logs/cluster/{rule}/{wildcards}.stdout threads: {threads} resources: span[hosts=1] cluster command : config/cluster_command.txt bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads} Commonly used parameters Parameter Description __default__ Rule name ( __default__ ) for default configuration) queue Queue name (required) name Job name stderr Log file for standard error stdout Log file for standard output threads Number of parallel threads for a job resources Resource requirements. span[hosts=1] prevents parallel jobs from being submitted to different nodes Refer to the snakemake documentation .","title":"Run on a cluster"},{"location":"cluster_configuration/#cluster-configuration","text":"cluster configuration : config/cluster.yaml Here is an example configuration: __default__: queue: queue name: {rule}.{wildcards} stderr: logs/cluster/{rule}/{wildcards}.stderr stdout: logs/cluster/{rule}/{wildcards}.stdout threads: {threads} resources: span[hosts=1] cluster command : config/cluster_command.txt bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads} Commonly used parameters Parameter Description __default__ Rule name ( __default__ ) for default configuration) queue Queue name (required) name Job name stderr Log file for standard error stdout Log file for standard output threads Number of parallel threads for a job resources Resource requirements. span[hosts=1] prevents parallel jobs from being submitted to different nodes Refer to the snakemake documentation .","title":"Cluster configuration"},{"location":"configuration/","text":"# RNA types for sequential mapping in small-RNA pipeline rna_types: [rRNA, lncRNA, miRNA, mRNA, piRNA, snoRNA, snRNA, srpRNA, tRNA, tucpRNA, Y_RNA] # Adjusted p-value threshold for defining domains call_domain_pvalue: \"05\" # Distribution to use to model read coverage in each bin distribution: ZeroTruncatedNegativeBinomial # Size of each bin to compute read coverage bin_size: 20 # Define recurrent domain as domains called in fraction of samples above this value cov_threshold: 0.2 # Method to scale features scale_method: robust # Classifier for feature selection classifiers: random_forest # Number of features to select n_selects: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50] resample_method: bootstrap # Feature selection methods select_methods: [robust] # Parameters for classifiers classifier_params: logistic_regression: penalty: l2 random_forest: n_estimators: 10 # Parameters for grid search for classifier parameters grid_search: logistic_regression: C: [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e2, 1e3, 1e4, 1e5] linear_svm: C: [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e2, 1e3, 1e4, 1e5] random_forest: n_estimators: [25, 50, 75] max_depth: [3, 4, 5, 6, 7, 8] # Splitter for cross-validation cv_splitter: stratified_shuffle_split # Number of cross-validation folds for grid search grid_search_n_splits: 5 # Number of train-test splits for cross-validation cv_n_splits: 50 # Fraction/number of test samples in cross-validation cv_test_size: 0.2 # Compute sample weight for imbalanced classes compute_sample_weight: true # Fold change filter in feature selection (up, down, both) fold_change_direction: up # Fold change filter threshold fold_change_threshold: 1 # Fraction of features to eliminate in each RFE step rfe_step: 0.1 # Number of cross-validation splits in RFE rfe_n_splits: 10 # Number of cross-validation splits in robust feature selection robust_feature_selection_n_splits: 10 # Splitter for robust feature selection robust_feature_selection_splitter: stratified_shuffle_split # Number of random train-test splits for cross-validation cross_validation_splits: 50 # Type of counts for feature selection # domains_combined: combine miRNA/piRNA with long RNA domains # transcript: transcript-level features # featurecounts: gene-level features counted using featureCounts count_method: domains_combined # Define low expression value as read counts below this value filtercount: 10 # Keep features with high expression in fraction of samples above this value filtersample: 0.2 # Imputation methods to try (set to \"null\" to skip imputation) imputation_methods: [\"scimpute_count\", \"viper_count\", \"null\"] # Read depth normalization methods to try normalization_methods: [\"SCnorm\", \"TMM\", \"RLE\", \"CPM\", \"CPM_top\", \"CPM_rm\"] # Batch effect removal methods to try (set \"null\" to skip batch effect removal) batch_removal_methods: [\"null\", \"Combat\", \"RUV\"] # Column index of batch effect in batch_info.txt to considier for Combat batch_indices: [] # Root directory root_dir: \".\" # Directory for sequences and annotations genome_dir: \"genome/hg38\" # Temporary directory (e.g. samtools sort, sort) temp_dir: \"tmp\" # Directory for third-party tools tools_dir: \"tools\" # Directory for exSeek scripts bin_dir: \"bin\" # Number of threads for uncompression and compression threads_compress: 1 # Default number of threads to use threads: 1 # alignment software to use (valie choices: bowtie, star) aligner: bowtie2 # Remove 3'-end adaptor sequence from single-end reads adaptor: \"\" # Remove 5'-end adaptor sequence from single-end reads adaptor_5p: \"\" # Remove 3'-end adaptor sequence from the first read in a pair adaptor1: \"\" # Remove 3'-end adaptor sequence from the second read in a pair adaptor2: \"\" # Remove 5'-end adaptor sequence from the first read in a pair adaptor1_5p: \"\" # Remove 5'-end adaptor sequence from the second in a pair adaptor2_5p: \"\" # Exact number of bases to trim from 5'-end trim_5p: 0 # Exact number of bases to trim from 3'-end trim_3p: 0 # Discard reads of length below this value min_read_length: 16 # Maximum read length max_read_length: 100 # Trim bases with quality below this value from 3'-end min_base_quality: 30 # Trim bases with quality below this value from 5'-end min_base_quality_5p: 30 # Trim bases with quality below this value from 3'-end min_base_quality_3p: 30 # Quality encoding in FASTQ files quality_base: 33 # Strandness (valid choices: forward, reverse, no) strandness: forward # Filter out reads with mapping quality below this value min_mapping_quality: 0 # Only considier longest transcript for transcriptome mapping use_longest_transcript: true # Expected read length for mapping using STAR star_sjdboverhang: 100 # Number of threads for mapping threads_mapping: 4 # Remove duplicates for long RNA-seq before feature counting remove_duplicates_long: false # Input reads are paired-end paired_end: false # Use small RNA-seq pipeline (sequential mapping) small_rna: true # Remove UMI tags (leading nucleotides) umi_tags: false # Length of the UMI barcode umi_length: 0 # Evaluate published biomarkers evaluate_features_preprocess_methods: [] # Differential expression method diffexp_method: deseq2 # Count multi-mapping reads count_multimap_reads: true # Count overlapping features count_overlapping_features: true","title":"Configuration File Reference"},{"location":"feature_selection/","text":"Feature Selection Run feature selection module Assume that we have already run normalization module and selected best matrix processing method based on the UCA score, we can run feature selection module using the following command: exseek.py feature_selection -d ${dataset} Output files Outuput directory Feature selection results using one combination of parameters are saved in a separate directory: ${output_dir}/cross_validation/${preprocess_method}.${count_method}/${compare_group}/${classifier}.${n_select}.${selector}.${fold_change_filter_direction} Variables in file patterns Variable Descrpition output_dir Output directory for the dataset, e.g. output/dataset preprocess_method Combination of matrix processing methods count_method Type of feature counts, e.g. domains_combined , domains_long , transcript , featurecounts compare_group Name of the negative-positive class pair defined in compare_groups.yaml classifier Classifier defined in the configuration file n_select Maximum number of features to select selector Feature selection method, e.g. robust , rfe fold_change_filter_direction Direction of fold change for filtering features. Three possible values: up , down and any Files in output directory File name pattern Descrpition features.txt Selected features. Plain text with one column: feature names feature_importances.txt Plain text with two columns: feature name, feature importance samples.txt Sample IDs in input matrix selected for feature selection classes.txt Sample class labels selected for feature selection final_model.pkl Final model fitted on all samples in Python pickle format metrics.train.txt Evaluation metrics on training data. First row is metric names. First column is index of each train-test split metrics.test.txt Same format with metrics.train.txt on test data. cross_validation.h5 Cross-validation details in HDF5 format. Cross validation details (cross_validation.h5) Dataset name Dimension Description feature_selection (n_splits, n_features) Binary matrix indicating features selected in each cross-validation split labels (n_samples,) True class labels predicted_labels (n_splits, n_samples) Predicted class labels on all samples predictions (n_splits, n_samples) Predicted probabilities of the positive class (or decision function for SVM) train_index (n_splits, n_samples) Binary matrix indicating training samples in each cross-validation split","title":"Feature Selection"},{"location":"feature_selection/#feature-selection","text":"","title":"Feature Selection"},{"location":"feature_selection/#run-feature-selection-module","text":"Assume that we have already run normalization module and selected best matrix processing method based on the UCA score, we can run feature selection module using the following command: exseek.py feature_selection -d ${dataset}","title":"Run feature selection module"},{"location":"feature_selection/#output-files","text":"","title":"Output files"},{"location":"feature_selection/#outuput-directory","text":"Feature selection results using one combination of parameters are saved in a separate directory: ${output_dir}/cross_validation/${preprocess_method}.${count_method}/${compare_group}/${classifier}.${n_select}.${selector}.${fold_change_filter_direction} Variables in file patterns Variable Descrpition output_dir Output directory for the dataset, e.g. output/dataset preprocess_method Combination of matrix processing methods count_method Type of feature counts, e.g. domains_combined , domains_long , transcript , featurecounts compare_group Name of the negative-positive class pair defined in compare_groups.yaml classifier Classifier defined in the configuration file n_select Maximum number of features to select selector Feature selection method, e.g. robust , rfe fold_change_filter_direction Direction of fold change for filtering features. Three possible values: up , down and any","title":"Outuput directory"},{"location":"feature_selection/#files-in-output-directory","text":"File name pattern Descrpition features.txt Selected features. Plain text with one column: feature names feature_importances.txt Plain text with two columns: feature name, feature importance samples.txt Sample IDs in input matrix selected for feature selection classes.txt Sample class labels selected for feature selection final_model.pkl Final model fitted on all samples in Python pickle format metrics.train.txt Evaluation metrics on training data. First row is metric names. First column is index of each train-test split metrics.test.txt Same format with metrics.train.txt on test data. cross_validation.h5 Cross-validation details in HDF5 format. Cross validation details (cross_validation.h5) Dataset name Dimension Description feature_selection (n_splits, n_features) Binary matrix indicating features selected in each cross-validation split labels (n_samples,) True class labels predicted_labels (n_splits, n_samples) Predicted class labels on all samples predictions (n_splits, n_samples) Predicted probabilities of the positive class (or decision function for SVM) train_index (n_splits, n_samples) Binary matrix indicating training samples in each cross-validation split","title":"Files in output directory"},{"location":"genome_and_annotations/","text":"Genome and Annotations Annotation summary table Type Number of genes Source miRNA 1917 miRBase hairpin (Version 22) piRNA 23431 piRNABank lncRNA 15778 GENCODE V27 and mitranscriptome rRNA 37 NCBI refSeq 109 mRNA 19836 GENCODE V27 snoRNA 943 GENCODE V27 snRNA 1900 GENCODE V27 srpRNA 680 GENCODE V27 tRNA 649 GENCODE V27 tucpRNA 3734 GENCODE V27 Y_RNA 756 GENCODE V27 circRNA 140527 circBase repeats - UCSC Genome Browser (rmsk) promoter - ChromHMM tracks from 9 cell lines from UCSC Genome Browser enhancer - ChromHMM tracks from 9 cell lines from UCSC Genome Browser Genome and annotation files File Description fasta/genome.fa genome sequence fasta/circRNA.fa junction sequence in circBase fasta/rRNA.fa rRNA sequences in NCBI RefSeq fasta/miRNA.fa miRNA hairpin (precursor) sequences in miRBase fasta/piRNA.fa piRNA sequences in piRNABank fasta/${rna_type}.fa Longest isoform for each gene extracted from GENCODE annotations gtf_by_biotype/${rna_type}.gtf separate GTF files for each RNA type gtf/gencode.gtf GENCODE GTF file gtf/mitranscriptome.gtf Mitranscriptome GTF file gtf/long_RNA.gtf GTF file of Long RNA (GENCODE + Mitranscriptome - miRNA) gtf/piRNABank.gtf piRNA GTF file from piRNABank gtf/gencode_tRNA.gtf GTF file of tRNA from GENCODE transcript_table/all.txt Table of transcript information (gene_id, transcript_id) rsem_index/bowtie2/${rna_type} RSEM index files for each RNA type (built using the longest transcripts) rsem_index/bowtie2/${rna_type}.transcripts.fa Sequence for each RNA type (longest transcripts) gtf_longest_transcript/${rna_type}.gtf GTF files for the longest isoforms from GENCODE and Mitranscriptome bed/*.bed Transcript in BED12 format extracted from GTF files in `gtf/*.gtf index/bowtie2/${rna_type} STAR index for transcripts index/star/${rna_type} STAR index for transcripts long_index/star/ STAR index including splicing junctions of long RNA Generate the genome and annotation files Create genome directory [ -d \"genome/hg38/source\" ] || mkdir -p \"genome/hg38/source\" Chromosome ID conversion table Column 1: UCSC chromosome ID Column 2: RefSeq chromosome ID mysql --user=genome --host=genome-mysql.cse.ucsc.edu -A -N -e \"SELECT * FROM ucscToRefSeq;\" hg38 | cut -f1,4 > genome/hg38/source/ucscToRefSeq.txt Download Gene annotation (NCBI) # NCBI Human Release 109 wget -P genome/hg38/source ftp://ftp.ncbi.nlm.nih.gov/genomes/H_sapiens/GFF/ref_GRCh38.p12_top_level.gff3.gz [ -d genome/hg38/gff3 ] || mkdir -p genome/hg38/gff3 awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"} NR==FNR{c[$2]=$1;next} !/^#/{chrom=c[$1]; if(length(chrom) > 0) print c[$1],$2,$3,$4,$5,$6,$7,$8,$9}' \\ genome/hg38/source/ucscToRefSeq.txt <(zcat genome/hg38/source/ref_GRCh38.p12_top_level.gff3.gz) \\ > genome/hg38/gff3/refseq.gff3 gffread --bed -o genome/hg38/bed/ncbi.bed genome/hg38/gff3/refseq.gff3 wget -O genome/hg38/source/refSeq_rna.fa.gz ftp://ftp.ncbi.nlm.nih.gov/genomes/H_sapiens/RNA/rna.fa.gz # get rRNA sequence IDs zgrep 'ribosomal RNA$' genome/hg38/source/refSeq_rna.fa.gz \\ | sed 's/>ref|\\(NR_[0-9.]\\+\\)|.*(\\([^)]\\+\\)).*/\\1|\\2/' > genome/hg38/source/refSeq_rRNA.ids.txt # get rRNA sequences zcat genome/hg38/source/refSeq_rna.fa.gz \\ | awk 'FNR==NR{split($0,a,\"|\");ids[a[1]]=1;next} {if($0 ~ /^>/){split($0,a,\"|\");if(ids[a[2]] == 1){keep=1; print \">\" a[2];}else{keep=0}} else{if(keep == 1){print}}}' \\ genome/hg38/source/refSeq_rRNA.ids.txt - > genome/hg38/fasta/rRNA.fa samtools faidx genome/hg38/fasta/rRNA.fa # generate transcript table { echo -e 'chrom\\tstart\\tend\\tname\\tscore\\tstrand\\tgene_id\\ttranscript_id\\tgene_name\\ttranscript_name\\tgene_type\\ttranscript_type\\tsource' awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}FNR==NR{split($0,a,\"|\");gene_name[a[1]]=a[2];next}{print $1,0,$2,a[1],0,\"+\",$1,$1,gene_name[$1],gene_name[$1],\"rRNA\",\"rRNA\",\"RefSeq\"}' \\ genome/hg38/source/refSeq_rRNA.ids.txt genome/hg38/fasta/rRNA.fa.fai } > genome/hg38/transcript_table/rRNA.txt # get transcript sizes cut -f1,2 genome/hg38/fasta/rRNA.fa.fai > genome/hg38/chrom_sizes/rRNA # build STAR index (small genome) STAR --runMode genomeGenerate --genomeSAindexNbases 5 --genomeDir genome/hg38/index/star/rRNA/ --genomeFastaFiles genome/hg38/fasta/rRNA.fa Download chain files for CrossMap wget -O genome/hg38/source/hg18ToHg38.over.chain.gz http://hgdownload.soe.ucsc.edu/goldenPath/hg18/liftOver/hg18ToHg38.over.chain.gz wget -O genome/hg38/source/NCBI36_to_GRCh38.chain.gz https://sourceforge.net/projects/crossmap/files/Ensembl_chain_files/homo_sapiens%28human%29/NCBI36_to_GRCh38.chain.gz Genome assembly (UCSC hg38) wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz gzip -d -c genome/hg38/source/hg38.fa.gz > genome/hg38/fasta/genome.fa samtools faidx genome/hg38/fasta/genome.fa ENCODE annotations wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.annotation.gtf.gz #wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.annotation.gff3.gz wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.long_noncoding_RNAs.gtf.gz #wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.long_noncoding_RNAs.gff3.gz wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.tRNAs.gtf.gz #wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.tRNAs.gff3.gz zcat genome/hg38/source/gencode.v27.annotation.gtf.gz > genome/hg38/gtf/gencode.gtf zcat genome/hg38/source/gencode.v27.long_noncoding_RNAs.gtf.gz > genome/hg38/gtf/gencode_lncRNA.gtf zcat genome/hg38/source/gencode.v27.tRNAs.gtf.gz \\ | awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"}{print $1,$2,\"exon\",$4,$5,$6,$7,$8,$9}' > genome/hg38/gtf/gencode_tRNA.gtf # Chain file for converting hg19 to hg38 wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz Mitranscriptome wget -P genome/hg38/source http://mitranscriptome.org/download/mitranscriptome.gtf.tar.gz tar -C genome/hg38/source --strip-components=1 -zxf genome/hg38/source/mitranscriptome.gtf.tar.gz mitranscriptome.gtf/mitranscriptome.v2.gtf.gz # convert from hg19 to hg38 zcat genome/hg38/source/mitranscriptome.v2.gtf.gz \\ | CrossMap.py gff genome/hg38/source/hg19ToHg38.over.chain.gz /dev/stdin genome/hg38/source/mitranscriptome.v2.hg38.gtf # remove invalid transcripts bin/preprocess.py fix_gtf -i genome/hg38/source/mitranscriptome.v2.hg38.gtf -o genome/hg38/gtf/mitranscriptome.gtf Extract lncRNA and TUCP RNA to separate GTF files: grep 'tcat \"lncrna\"' genome/hg38/gtf/mitranscriptome.gtf > genome/hg38/gtf/mitranscriptome_lncRNA.gtf # add exon feature grep 'tcat \"tucp\"' genome/hg38/gtf/mitranscriptome.gtf \\ | awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print;print $1,$2,\"exon\",$4,$5,$6,$7,$8,$9}' > genome/hg38/gtf/mitranscriptome_tucp.gtf cp genome/hg38/gtf/mitranscriptome_tucp.gtf genome/hg38/gtf_by_biotype/tucpRNA.gtf NONCODE wget -P genome/hg38/source http://www.noncode.org/datadownload/NONCODEv5_human_hg38_lncRNA.gtf.gz zcat genome/hg38/source/NONCODEv5_human_hg38_lncRNA.gtf.gz \\ | awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"}$7 != \".\" {print $1,\"NONCODE\",$3,$4,$5,$6,$7,$8,$9}' > genome/hg38/gtf/noncode.gtf lncRNAs identified in HCC (Nature communications 2017) wget -P genome/hg38/source https://media.nature.com/original/nature-assets/ncomms/2017/170213/ncomms14421/extref/ncomms14421-s3.txt awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"}{print $1,\"ncomms2017\",$3,$4,$5,$6,$7,$8,$9}' genome/hg38/source/ncomms14421-s3.txt > genome/hg38/source/ncomms2017.gtf CrossMap.py gff genome/hg38/source/hg19ToHg38.over.chain.gz genome/hg38/source/ncomms2017.gtf genome/hg38/source/ncomms2017.hg38.gtf ln genome/hg38/source/ncomms2017.hg38.gtf genome/hg38/gtf/ncomms2017.gtf Merge lncRNA (GENCODE and Mitranscriptome) cat genome/hg38/gtf/gencode_lncRNA.gtf \\ genome/hg38/gtf/mitranscriptome_lncRNA.gtf \\ > genome/hg38/gtf/merged_lncRNA.gtf cp genome/hg38/gtf/merged_lncRNA.gtf genome/hg38/gtf_by_biotype/lncRNA.gtf piRBase (v1.0) wget -O genome/hg38/source/piRBase-hsa-v1.0.bed.gz http://www.regulatoryrna.org/database/piRNA/download/archive/v1.0/bed/piR_hg19_v1.0.bed.gz zcat genome/hg38/source/piRBase-hsa-v1.0.bed.gz \\ | CrossMap.py bed genome/hg38/source/hg19ToHg38.over.chain.gz /dev/stdin genome/hg38/source/piRBase-hsa-v1.0.hg38.bed bedToGenePred genome/hg38/source/piRBase-hsa-v1.0.hg38.bed genome/hg38/source/piRBase-hsa-v1.0.hg38.genePred genePredToGtf -source=piRBase file genome/hg38/source/piRBase-hsa-v1.0.hg38.genePred genome/hg38/source/piRBase-hsa-v1.0.hg38.gtf ln genome/hg38/source/piRBase-hsa-v1.0.hg38.gtf genome/hg38/gtf/piRBase.gtf piRBase (v2.0) wget -O genome/hg38/source/piRBase-hsa-v2.0.bed.gz http://www.regulatoryrna.org/database/piRNA/download/archive/v2.0/bed/hsa.bed.gz zcat genome/hg38/source/piRBase-hsa-v2.0.bed.gz | bedtools sort > source/piRBase-hsa-v2.0.bed bedToGenePred source/piRBase-hsa-v2.0.bed source/piRBase-hsa-v2.0.genePred genePredToGtf -source=piRBase file source/piRBase-hsa-v2.0.genePred source/piRBase-hsa-v2.0.gtf Long RNA (GENCODE + Mitranscriptome - miRNA) # Merge GTF files cat genome/hg38/gtf/gencode.gtf \\ genome/hg38/gtf/mitranscriptome_lncRNA.gtf \\ genome/hg38/gtf/mitranscriptome_tucp.gtf \\ | grep -v 'gene_type \"miRNA' \\ > genome/hg38/gtf/long_RNA.gtf # Get gene lengths tools/GTFtools_0.6.5/gtftools.py -c 1-22,X,Y,M -l genome/hg38/gene_length/long_RNA genome/hg38/gtf/long_RNA.gtf # GTF to BED12 format gffread --bed -o genome/hg38/bed/long_RNA.bed genome/hg38/gtf/long_RNA.gtf gene_length/long_RNA Tab-deliminated text file First row: header Column 1 (gene): gene_id Column 2 (mean): mean length of isoforms Column 3 (median): median length of isoforms Column 4 (longest_isoform): length of the longest isoform Column 5 (merged): merged length of isoforms piRNABank (NCBI36) wget -O genome/hg38/source/ http://pirnabank.ibab.ac.in/downloads/all/human_all.zip unzip genome/hg38/source/human_all.zip -d genome/hg38/source/ mv genome/hg38/source/human_pir.txt genome/hg38/source/piRNABank.human.txt # Extract genomic coordinates from piRNABank awk 'BEGIN{OFS=\"\\t\"} /^>/{na=split(substr($0,2),a,\"|\");split(a[na],b,\":\"); if(b[5]==\"Plus\"){s=\"+\"} else{s=\"-\"} if(a[1]!=name){print \"chr\" b[2],b[3]-1,b[4],a[1],0,s} name=a[1]}' genome/hg38/source/piRNABank.human.txt \\ | bedtools sort > genome/hg38/source/piRNABank.human.bed awk 'BEGIN{OFS=\"\\t\"} {if($0 ~ /^>/) {split(substr($0,2),a,\"|\"); if((a[1] != name)&&(length(seq) > 0)){print \">\" name;gsub(/U/,\"T\",seq);print seq} name=a[1]} else{seq=$0}}' genome/hg38/source/piRNABank.human.txt > genome/hg38/source/piRNABank.human.fa bedToGenePred genome/hg38/source/piRNABank.human.bed genome/hg38/source/piRNABank.human.genePred genePredToGtf -source=piRNABank file genome/hg38/source/piRNABank.human.genePred stdout \\ | awk '$3==\"exon\"' > genome/hg38/source/piRNABank.human.gtf CrossMap.py gff genome/hg38/source/hg18ToHg38.over.chain.gz genome/hg38/source/piRNABank.human.gtf \\ genome/hg38/source/piRNABank.human.hg38.gtf cp genome/hg38/source/piRNABank.human.hg38.gtf genome/hg38/gtf/piRNABank.gtf cp genome/hg38/gtf/piRNABank.gtf genome/hg38/gtf_by_biotype/piRNA.gtf gffread --bed -o genome/hg38/source/piRNABank.human.hg38.bed genome/hg38/source/piRNABank.human.hg38.gtf bedtools getfasta -s -name -fi genome/hg38/fasta/genome.fa -bed genome/hg38/source/piRNABank.human.hg38.bed -split \\ > genome/hg38/source/piRNABank.human.hg38.fa miRBase (Version 22) wget -O genome/hg38/source/miRBase.hsa.gff3 ftp://mirbase.org/pub/mirbase/CURRENT/genomes/hsa.gff3 wget -O genome/hg38/source/miRBase.hairpin.fa.gz ftp://mirbase.org/pub/mirbase/CURRENT/hairpin.fa.gz wget -O genome/hg38/source/miRBase.mature.fa.gz ftp://mirbase.org/pub/mirbase/CURRENT/mature.fa.gz cp genome/hg38/source/miRBase.hsa.gff3 genome/hg38/gtf/miRBase.gff3 # extract human pre-miRNA zcat genome/hg38/source/miRBase.hairpin.fa.gz \\ | awk '/^>/{if($0 ~ />hsa-/) {keep=1; print $1} else{keep=0}; next}{if(keep==1){gsub(/U/, \"T\");print}}' \\ > genome/hg38/fasta/miRNA.fa samtools faidx genome/hg38/fasta/miRNA.fa # extract human mature miRNA zcat genome/hg38/source/miRBase.mature.fa.gz \\ | awk '/^>/{if($0 ~ />hsa-/) {keep=1; print $1} else{keep=0}; next}{if(keep==1){gsub(/U/, \"T\");print}}' \\ > genome/hg38/fasta/mature_miRNA.fa samtools faidx genome/hg38/fasta/mature_miRNA.fa # generate transcript table (mature miRNA) { echo -e 'chrom\\tstart\\tend\\tname\\tscore\\tstrand\\tgene_id\\ttranscript_id\\tgene_name\\ttranscript_name\\tgene_type\\ttranscript_type\\tsource' awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,0,$2,$1,0,\"+\",$1,$1,$1,$1,\"miRNA\",\"miRNA\",\"miRBase\"}' \\ genome/hg38/fasta/miRNA.fa.fai genome/hg38/fasta/mature_miRNA.fa.fai } > genome/hg38/transcript_table/miRNA.txt # get transcript sizes cut -f1,2 genome/hg38/fasta/miRNA.fa.fai genome/hg38/fasta/mature_miRNA.fa.fai > genome/hg38/chrom_sizes/miRNA # gff3 to genePred awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\";d[\"miRNA\"]=\"transcript\";d[\"miRNA_primary_transcript\"]=\"primary_transcript\"}/^#/{print}!/^#/{$3=d[$3];print $1,$2,$3,$4,$5,$6,$7,$8,$9}' \\ genome/hg38/gff3/miRBase.gff3 > genome/hg38/source/miRBase.fixed.gff3 gff3ToGenePred -useName genome/hg38/source/miRBase.fixed.gff3 genome/hg38/genePred/miRBase.genePred Intron bin/preprocess.py extract_gene -i genome/hg38/gtf/long_RNA.gtf | bedtools sort > genome/hg38/bed/long_RNA.gene.bed awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"} !/^#/{match($9,/gene_id \"([^\"]+)\"/,a);print $1,$4-1,$5,a[1],0,$7}' genome/hg38/gtf/long_RNA.gtf \\ | bedtools sort > genome/hg38/bed/long_RNA.exon.bed bedtools subtract -sorted -s -a genome/hg38/bed/long_RNA.gene.bed -b genome/hg38/bed/long_RNA.exon.bed \\ | bedtools sort > genome/hg38/bed/long_RNA.intron.bed Promoter/enhancer from ChromHMM (hg19) wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmGm12878HMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmH1hescHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHepg2HMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHmecHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHsmmHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHuvecHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmK562HMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmNhekHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmNhlfHMM.bed.gz # hg19 => hg38 tracks=\"wgEncodeBroadHmmGm12878HMM wgEncodeBroadHmmH1hescHMM wgEncodeBroadHmmHepg2HMM wgEncodeBroadHmmHmecHMM wgEncodeBroadHmmHsmmHMM wgEncodeBroadHmmHuvecHMM wgEncodeBroadHmmK562HMM wgEncodeBroadHmmNhekHMM wgEncodeBroadHmmNhlfHMM\" for track in $tracks;do CrossMap.py bed genome/hg38/source/hg18ToHg38.over.chain.gz <(zcat genome/hg38/source/${track}.bed.gz) genome/hg38/source/${track}.hg38.bed awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}($4==\"1_Active_Promoter\")||($4==\"2_Weak_Promoter\")||($4==\"3_Poised_Promoter\"){print $1,$2,$3,$4,$5,$6}' \\ genome/hg38/source/${track}.hg38.bed | bedtools sort > genome/hg38/bed/promoter.${track}.bed awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}($4==\"4_Strong_Enhancer\")||($4==\"5_Strong_Enhancer\")||($4==\"6_Weak_Enhancer\")||($4==\"7_Weak_Enhancer\"){print $1,$2,$3,$4,$5,$6}' \\ genome/hg38/source/${track}.hg38.bed | bedtools sort > genome/hg38/bed/enhancer.${track}.bed done # merge promoters and enhancers from 9 cell lines cat $(for track in $tracks;do echo genome/hg38/bed/promoter.${track}.bed;done) \\ | bedtools sort | bedtools merge -d 1 \\ | awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,$2,$3,\"promoter\",0,\".\"}' > genome/hg38/bed/promoter.merged.bed cat $(for track in $tracks;do echo genome/hg38/bed/enhancer.${track}.bed;done) \\ | bedtools sort | bedtools merge -d 1 \\ | awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,$2,$3,\"enhancer\",0,\".\"}' > genome/hg38/bed/enhancer.merged.bed Repeats UCSC GenomeBrowser -> Tools -> Table Browser assembly: GRCh38/hg38 group: repeats track: RepeatMasker table: rmsk Dowload to: genome/hg38/source/rmsk.bed.gz gunzip -c genome/hg38/source/rmsk.bed.gz | bedtools sort > genome/hg38/bed/rmsk.bed circRNA database (circBase) wget -O genome/hg38/source/circbase.hg19.fa.gz http://www.circbase.org/download/human_hg19_circRNAs_putative_spliced_sequence.fa.gz zcat genome/hg38/source/circbase.hg19.fa.gz | bin/preprocess.py extract_circrna_junction -s 150 -o genome/hg38/fasta/circRNA.fa samtools faidx genome/hg38/fasta/circRNA.fa STAR --runMode genomeGenerate --genomeSAindexNbases 10 --genomeChrBinNbits 7 --genomeDir genome/hg38/index/star/circRNA/ --genomeFastaFiles genome/hg38/fasta/circRNA.fa Merge transcript table { echo -e 'chrom\\tstart\\tend\\tname\\tscore\\tstrand\\tgene_id\\ttranscript_id\\tgene_name\\ttranscript_name\\tgene_type\\ttranscript_type\\tsource' for rna_type in rRNA lncRNA miRNA mRNA piRNA snoRNA snRNA srpRNA tRNA tucpRNA Y_RNA;do sed '1 d' genome/hg38/transcript_table/${rna_type}.txt done } > genome/hg38/transcript_table/all.txt","title":"Genome and Annotations"},{"location":"genome_and_annotations/#genome-and-annotations","text":"","title":"Genome and Annotations"},{"location":"genome_and_annotations/#annotation-summary-table","text":"Type Number of genes Source miRNA 1917 miRBase hairpin (Version 22) piRNA 23431 piRNABank lncRNA 15778 GENCODE V27 and mitranscriptome rRNA 37 NCBI refSeq 109 mRNA 19836 GENCODE V27 snoRNA 943 GENCODE V27 snRNA 1900 GENCODE V27 srpRNA 680 GENCODE V27 tRNA 649 GENCODE V27 tucpRNA 3734 GENCODE V27 Y_RNA 756 GENCODE V27 circRNA 140527 circBase repeats - UCSC Genome Browser (rmsk) promoter - ChromHMM tracks from 9 cell lines from UCSC Genome Browser enhancer - ChromHMM tracks from 9 cell lines from UCSC Genome Browser","title":"Annotation summary table"},{"location":"genome_and_annotations/#genome-and-annotation-files","text":"File Description fasta/genome.fa genome sequence fasta/circRNA.fa junction sequence in circBase fasta/rRNA.fa rRNA sequences in NCBI RefSeq fasta/miRNA.fa miRNA hairpin (precursor) sequences in miRBase fasta/piRNA.fa piRNA sequences in piRNABank fasta/${rna_type}.fa Longest isoform for each gene extracted from GENCODE annotations gtf_by_biotype/${rna_type}.gtf separate GTF files for each RNA type gtf/gencode.gtf GENCODE GTF file gtf/mitranscriptome.gtf Mitranscriptome GTF file gtf/long_RNA.gtf GTF file of Long RNA (GENCODE + Mitranscriptome - miRNA) gtf/piRNABank.gtf piRNA GTF file from piRNABank gtf/gencode_tRNA.gtf GTF file of tRNA from GENCODE transcript_table/all.txt Table of transcript information (gene_id, transcript_id) rsem_index/bowtie2/${rna_type} RSEM index files for each RNA type (built using the longest transcripts) rsem_index/bowtie2/${rna_type}.transcripts.fa Sequence for each RNA type (longest transcripts) gtf_longest_transcript/${rna_type}.gtf GTF files for the longest isoforms from GENCODE and Mitranscriptome bed/*.bed Transcript in BED12 format extracted from GTF files in `gtf/*.gtf index/bowtie2/${rna_type} STAR index for transcripts index/star/${rna_type} STAR index for transcripts long_index/star/ STAR index including splicing junctions of long RNA","title":"Genome and annotation files"},{"location":"genome_and_annotations/#generate-the-genome-and-annotation-files","text":"","title":"Generate the genome and annotation files"},{"location":"genome_and_annotations/#create-genome-directory","text":"[ -d \"genome/hg38/source\" ] || mkdir -p \"genome/hg38/source\"","title":"Create genome directory"},{"location":"genome_and_annotations/#chromosome-id-conversion-table","text":"Column 1: UCSC chromosome ID Column 2: RefSeq chromosome ID mysql --user=genome --host=genome-mysql.cse.ucsc.edu -A -N -e \"SELECT * FROM ucscToRefSeq;\" hg38 | cut -f1,4 > genome/hg38/source/ucscToRefSeq.txt","title":"Chromosome ID conversion table"},{"location":"genome_and_annotations/#download-gene-annotation-ncbi","text":"# NCBI Human Release 109 wget -P genome/hg38/source ftp://ftp.ncbi.nlm.nih.gov/genomes/H_sapiens/GFF/ref_GRCh38.p12_top_level.gff3.gz [ -d genome/hg38/gff3 ] || mkdir -p genome/hg38/gff3 awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"} NR==FNR{c[$2]=$1;next} !/^#/{chrom=c[$1]; if(length(chrom) > 0) print c[$1],$2,$3,$4,$5,$6,$7,$8,$9}' \\ genome/hg38/source/ucscToRefSeq.txt <(zcat genome/hg38/source/ref_GRCh38.p12_top_level.gff3.gz) \\ > genome/hg38/gff3/refseq.gff3 gffread --bed -o genome/hg38/bed/ncbi.bed genome/hg38/gff3/refseq.gff3 wget -O genome/hg38/source/refSeq_rna.fa.gz ftp://ftp.ncbi.nlm.nih.gov/genomes/H_sapiens/RNA/rna.fa.gz # get rRNA sequence IDs zgrep 'ribosomal RNA$' genome/hg38/source/refSeq_rna.fa.gz \\ | sed 's/>ref|\\(NR_[0-9.]\\+\\)|.*(\\([^)]\\+\\)).*/\\1|\\2/' > genome/hg38/source/refSeq_rRNA.ids.txt # get rRNA sequences zcat genome/hg38/source/refSeq_rna.fa.gz \\ | awk 'FNR==NR{split($0,a,\"|\");ids[a[1]]=1;next} {if($0 ~ /^>/){split($0,a,\"|\");if(ids[a[2]] == 1){keep=1; print \">\" a[2];}else{keep=0}} else{if(keep == 1){print}}}' \\ genome/hg38/source/refSeq_rRNA.ids.txt - > genome/hg38/fasta/rRNA.fa samtools faidx genome/hg38/fasta/rRNA.fa # generate transcript table { echo -e 'chrom\\tstart\\tend\\tname\\tscore\\tstrand\\tgene_id\\ttranscript_id\\tgene_name\\ttranscript_name\\tgene_type\\ttranscript_type\\tsource' awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}FNR==NR{split($0,a,\"|\");gene_name[a[1]]=a[2];next}{print $1,0,$2,a[1],0,\"+\",$1,$1,gene_name[$1],gene_name[$1],\"rRNA\",\"rRNA\",\"RefSeq\"}' \\ genome/hg38/source/refSeq_rRNA.ids.txt genome/hg38/fasta/rRNA.fa.fai } > genome/hg38/transcript_table/rRNA.txt # get transcript sizes cut -f1,2 genome/hg38/fasta/rRNA.fa.fai > genome/hg38/chrom_sizes/rRNA # build STAR index (small genome) STAR --runMode genomeGenerate --genomeSAindexNbases 5 --genomeDir genome/hg38/index/star/rRNA/ --genomeFastaFiles genome/hg38/fasta/rRNA.fa","title":"Download Gene annotation (NCBI)"},{"location":"genome_and_annotations/#download-chain-files-for-crossmap","text":"wget -O genome/hg38/source/hg18ToHg38.over.chain.gz http://hgdownload.soe.ucsc.edu/goldenPath/hg18/liftOver/hg18ToHg38.over.chain.gz wget -O genome/hg38/source/NCBI36_to_GRCh38.chain.gz https://sourceforge.net/projects/crossmap/files/Ensembl_chain_files/homo_sapiens%28human%29/NCBI36_to_GRCh38.chain.gz","title":"Download chain files for CrossMap"},{"location":"genome_and_annotations/#genome-assembly-ucsc-hg38","text":"wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz gzip -d -c genome/hg38/source/hg38.fa.gz > genome/hg38/fasta/genome.fa samtools faidx genome/hg38/fasta/genome.fa","title":"Genome assembly (UCSC hg38)"},{"location":"genome_and_annotations/#encode-annotations","text":"wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.annotation.gtf.gz #wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.annotation.gff3.gz wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.long_noncoding_RNAs.gtf.gz #wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.long_noncoding_RNAs.gff3.gz wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.tRNAs.gtf.gz #wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.tRNAs.gff3.gz zcat genome/hg38/source/gencode.v27.annotation.gtf.gz > genome/hg38/gtf/gencode.gtf zcat genome/hg38/source/gencode.v27.long_noncoding_RNAs.gtf.gz > genome/hg38/gtf/gencode_lncRNA.gtf zcat genome/hg38/source/gencode.v27.tRNAs.gtf.gz \\ | awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"}{print $1,$2,\"exon\",$4,$5,$6,$7,$8,$9}' > genome/hg38/gtf/gencode_tRNA.gtf # Chain file for converting hg19 to hg38 wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz","title":"ENCODE annotations"},{"location":"genome_and_annotations/#mitranscriptome","text":"wget -P genome/hg38/source http://mitranscriptome.org/download/mitranscriptome.gtf.tar.gz tar -C genome/hg38/source --strip-components=1 -zxf genome/hg38/source/mitranscriptome.gtf.tar.gz mitranscriptome.gtf/mitranscriptome.v2.gtf.gz # convert from hg19 to hg38 zcat genome/hg38/source/mitranscriptome.v2.gtf.gz \\ | CrossMap.py gff genome/hg38/source/hg19ToHg38.over.chain.gz /dev/stdin genome/hg38/source/mitranscriptome.v2.hg38.gtf # remove invalid transcripts bin/preprocess.py fix_gtf -i genome/hg38/source/mitranscriptome.v2.hg38.gtf -o genome/hg38/gtf/mitranscriptome.gtf Extract lncRNA and TUCP RNA to separate GTF files: grep 'tcat \"lncrna\"' genome/hg38/gtf/mitranscriptome.gtf > genome/hg38/gtf/mitranscriptome_lncRNA.gtf # add exon feature grep 'tcat \"tucp\"' genome/hg38/gtf/mitranscriptome.gtf \\ | awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print;print $1,$2,\"exon\",$4,$5,$6,$7,$8,$9}' > genome/hg38/gtf/mitranscriptome_tucp.gtf cp genome/hg38/gtf/mitranscriptome_tucp.gtf genome/hg38/gtf_by_biotype/tucpRNA.gtf","title":"Mitranscriptome"},{"location":"genome_and_annotations/#noncode","text":"wget -P genome/hg38/source http://www.noncode.org/datadownload/NONCODEv5_human_hg38_lncRNA.gtf.gz zcat genome/hg38/source/NONCODEv5_human_hg38_lncRNA.gtf.gz \\ | awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"}$7 != \".\" {print $1,\"NONCODE\",$3,$4,$5,$6,$7,$8,$9}' > genome/hg38/gtf/noncode.gtf","title":"NONCODE"},{"location":"genome_and_annotations/#lncrnas-identified-in-hcc-nature-communications-2017","text":"wget -P genome/hg38/source https://media.nature.com/original/nature-assets/ncomms/2017/170213/ncomms14421/extref/ncomms14421-s3.txt awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"}{print $1,\"ncomms2017\",$3,$4,$5,$6,$7,$8,$9}' genome/hg38/source/ncomms14421-s3.txt > genome/hg38/source/ncomms2017.gtf CrossMap.py gff genome/hg38/source/hg19ToHg38.over.chain.gz genome/hg38/source/ncomms2017.gtf genome/hg38/source/ncomms2017.hg38.gtf ln genome/hg38/source/ncomms2017.hg38.gtf genome/hg38/gtf/ncomms2017.gtf","title":"lncRNAs identified in HCC (Nature communications 2017)"},{"location":"genome_and_annotations/#merge-lncrna-gencode-and-mitranscriptome","text":"cat genome/hg38/gtf/gencode_lncRNA.gtf \\ genome/hg38/gtf/mitranscriptome_lncRNA.gtf \\ > genome/hg38/gtf/merged_lncRNA.gtf cp genome/hg38/gtf/merged_lncRNA.gtf genome/hg38/gtf_by_biotype/lncRNA.gtf","title":"Merge lncRNA (GENCODE and Mitranscriptome)"},{"location":"genome_and_annotations/#pirbase-v10","text":"wget -O genome/hg38/source/piRBase-hsa-v1.0.bed.gz http://www.regulatoryrna.org/database/piRNA/download/archive/v1.0/bed/piR_hg19_v1.0.bed.gz zcat genome/hg38/source/piRBase-hsa-v1.0.bed.gz \\ | CrossMap.py bed genome/hg38/source/hg19ToHg38.over.chain.gz /dev/stdin genome/hg38/source/piRBase-hsa-v1.0.hg38.bed bedToGenePred genome/hg38/source/piRBase-hsa-v1.0.hg38.bed genome/hg38/source/piRBase-hsa-v1.0.hg38.genePred genePredToGtf -source=piRBase file genome/hg38/source/piRBase-hsa-v1.0.hg38.genePred genome/hg38/source/piRBase-hsa-v1.0.hg38.gtf ln genome/hg38/source/piRBase-hsa-v1.0.hg38.gtf genome/hg38/gtf/piRBase.gtf","title":"piRBase (v1.0)"},{"location":"genome_and_annotations/#pirbase-v20","text":"wget -O genome/hg38/source/piRBase-hsa-v2.0.bed.gz http://www.regulatoryrna.org/database/piRNA/download/archive/v2.0/bed/hsa.bed.gz zcat genome/hg38/source/piRBase-hsa-v2.0.bed.gz | bedtools sort > source/piRBase-hsa-v2.0.bed bedToGenePred source/piRBase-hsa-v2.0.bed source/piRBase-hsa-v2.0.genePred genePredToGtf -source=piRBase file source/piRBase-hsa-v2.0.genePred source/piRBase-hsa-v2.0.gtf","title":"piRBase (v2.0)"},{"location":"genome_and_annotations/#long-rna-gencode-mitranscriptome-mirna","text":"# Merge GTF files cat genome/hg38/gtf/gencode.gtf \\ genome/hg38/gtf/mitranscriptome_lncRNA.gtf \\ genome/hg38/gtf/mitranscriptome_tucp.gtf \\ | grep -v 'gene_type \"miRNA' \\ > genome/hg38/gtf/long_RNA.gtf # Get gene lengths tools/GTFtools_0.6.5/gtftools.py -c 1-22,X,Y,M -l genome/hg38/gene_length/long_RNA genome/hg38/gtf/long_RNA.gtf # GTF to BED12 format gffread --bed -o genome/hg38/bed/long_RNA.bed genome/hg38/gtf/long_RNA.gtf gene_length/long_RNA Tab-deliminated text file First row: header Column 1 (gene): gene_id Column 2 (mean): mean length of isoforms Column 3 (median): median length of isoforms Column 4 (longest_isoform): length of the longest isoform Column 5 (merged): merged length of isoforms","title":"Long RNA (GENCODE + Mitranscriptome - miRNA)"},{"location":"genome_and_annotations/#pirnabank-ncbi36","text":"wget -O genome/hg38/source/ http://pirnabank.ibab.ac.in/downloads/all/human_all.zip unzip genome/hg38/source/human_all.zip -d genome/hg38/source/ mv genome/hg38/source/human_pir.txt genome/hg38/source/piRNABank.human.txt # Extract genomic coordinates from piRNABank awk 'BEGIN{OFS=\"\\t\"} /^>/{na=split(substr($0,2),a,\"|\");split(a[na],b,\":\"); if(b[5]==\"Plus\"){s=\"+\"} else{s=\"-\"} if(a[1]!=name){print \"chr\" b[2],b[3]-1,b[4],a[1],0,s} name=a[1]}' genome/hg38/source/piRNABank.human.txt \\ | bedtools sort > genome/hg38/source/piRNABank.human.bed awk 'BEGIN{OFS=\"\\t\"} {if($0 ~ /^>/) {split(substr($0,2),a,\"|\"); if((a[1] != name)&&(length(seq) > 0)){print \">\" name;gsub(/U/,\"T\",seq);print seq} name=a[1]} else{seq=$0}}' genome/hg38/source/piRNABank.human.txt > genome/hg38/source/piRNABank.human.fa bedToGenePred genome/hg38/source/piRNABank.human.bed genome/hg38/source/piRNABank.human.genePred genePredToGtf -source=piRNABank file genome/hg38/source/piRNABank.human.genePred stdout \\ | awk '$3==\"exon\"' > genome/hg38/source/piRNABank.human.gtf CrossMap.py gff genome/hg38/source/hg18ToHg38.over.chain.gz genome/hg38/source/piRNABank.human.gtf \\ genome/hg38/source/piRNABank.human.hg38.gtf cp genome/hg38/source/piRNABank.human.hg38.gtf genome/hg38/gtf/piRNABank.gtf cp genome/hg38/gtf/piRNABank.gtf genome/hg38/gtf_by_biotype/piRNA.gtf gffread --bed -o genome/hg38/source/piRNABank.human.hg38.bed genome/hg38/source/piRNABank.human.hg38.gtf bedtools getfasta -s -name -fi genome/hg38/fasta/genome.fa -bed genome/hg38/source/piRNABank.human.hg38.bed -split \\ > genome/hg38/source/piRNABank.human.hg38.fa","title":"piRNABank (NCBI36)"},{"location":"genome_and_annotations/#mirbase-version-22","text":"wget -O genome/hg38/source/miRBase.hsa.gff3 ftp://mirbase.org/pub/mirbase/CURRENT/genomes/hsa.gff3 wget -O genome/hg38/source/miRBase.hairpin.fa.gz ftp://mirbase.org/pub/mirbase/CURRENT/hairpin.fa.gz wget -O genome/hg38/source/miRBase.mature.fa.gz ftp://mirbase.org/pub/mirbase/CURRENT/mature.fa.gz cp genome/hg38/source/miRBase.hsa.gff3 genome/hg38/gtf/miRBase.gff3 # extract human pre-miRNA zcat genome/hg38/source/miRBase.hairpin.fa.gz \\ | awk '/^>/{if($0 ~ />hsa-/) {keep=1; print $1} else{keep=0}; next}{if(keep==1){gsub(/U/, \"T\");print}}' \\ > genome/hg38/fasta/miRNA.fa samtools faidx genome/hg38/fasta/miRNA.fa # extract human mature miRNA zcat genome/hg38/source/miRBase.mature.fa.gz \\ | awk '/^>/{if($0 ~ />hsa-/) {keep=1; print $1} else{keep=0}; next}{if(keep==1){gsub(/U/, \"T\");print}}' \\ > genome/hg38/fasta/mature_miRNA.fa samtools faidx genome/hg38/fasta/mature_miRNA.fa # generate transcript table (mature miRNA) { echo -e 'chrom\\tstart\\tend\\tname\\tscore\\tstrand\\tgene_id\\ttranscript_id\\tgene_name\\ttranscript_name\\tgene_type\\ttranscript_type\\tsource' awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,0,$2,$1,0,\"+\",$1,$1,$1,$1,\"miRNA\",\"miRNA\",\"miRBase\"}' \\ genome/hg38/fasta/miRNA.fa.fai genome/hg38/fasta/mature_miRNA.fa.fai } > genome/hg38/transcript_table/miRNA.txt # get transcript sizes cut -f1,2 genome/hg38/fasta/miRNA.fa.fai genome/hg38/fasta/mature_miRNA.fa.fai > genome/hg38/chrom_sizes/miRNA # gff3 to genePred awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\";d[\"miRNA\"]=\"transcript\";d[\"miRNA_primary_transcript\"]=\"primary_transcript\"}/^#/{print}!/^#/{$3=d[$3];print $1,$2,$3,$4,$5,$6,$7,$8,$9}' \\ genome/hg38/gff3/miRBase.gff3 > genome/hg38/source/miRBase.fixed.gff3 gff3ToGenePred -useName genome/hg38/source/miRBase.fixed.gff3 genome/hg38/genePred/miRBase.genePred","title":"miRBase (Version 22)"},{"location":"genome_and_annotations/#intron","text":"bin/preprocess.py extract_gene -i genome/hg38/gtf/long_RNA.gtf | bedtools sort > genome/hg38/bed/long_RNA.gene.bed awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"} !/^#/{match($9,/gene_id \"([^\"]+)\"/,a);print $1,$4-1,$5,a[1],0,$7}' genome/hg38/gtf/long_RNA.gtf \\ | bedtools sort > genome/hg38/bed/long_RNA.exon.bed bedtools subtract -sorted -s -a genome/hg38/bed/long_RNA.gene.bed -b genome/hg38/bed/long_RNA.exon.bed \\ | bedtools sort > genome/hg38/bed/long_RNA.intron.bed","title":"Intron"},{"location":"genome_and_annotations/#promoterenhancer-from-chromhmm-hg19","text":"wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmGm12878HMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmH1hescHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHepg2HMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHmecHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHsmmHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHuvecHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmK562HMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmNhekHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmNhlfHMM.bed.gz # hg19 => hg38 tracks=\"wgEncodeBroadHmmGm12878HMM wgEncodeBroadHmmH1hescHMM wgEncodeBroadHmmHepg2HMM wgEncodeBroadHmmHmecHMM wgEncodeBroadHmmHsmmHMM wgEncodeBroadHmmHuvecHMM wgEncodeBroadHmmK562HMM wgEncodeBroadHmmNhekHMM wgEncodeBroadHmmNhlfHMM\" for track in $tracks;do CrossMap.py bed genome/hg38/source/hg18ToHg38.over.chain.gz <(zcat genome/hg38/source/${track}.bed.gz) genome/hg38/source/${track}.hg38.bed awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}($4==\"1_Active_Promoter\")||($4==\"2_Weak_Promoter\")||($4==\"3_Poised_Promoter\"){print $1,$2,$3,$4,$5,$6}' \\ genome/hg38/source/${track}.hg38.bed | bedtools sort > genome/hg38/bed/promoter.${track}.bed awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}($4==\"4_Strong_Enhancer\")||($4==\"5_Strong_Enhancer\")||($4==\"6_Weak_Enhancer\")||($4==\"7_Weak_Enhancer\"){print $1,$2,$3,$4,$5,$6}' \\ genome/hg38/source/${track}.hg38.bed | bedtools sort > genome/hg38/bed/enhancer.${track}.bed done # merge promoters and enhancers from 9 cell lines cat $(for track in $tracks;do echo genome/hg38/bed/promoter.${track}.bed;done) \\ | bedtools sort | bedtools merge -d 1 \\ | awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,$2,$3,\"promoter\",0,\".\"}' > genome/hg38/bed/promoter.merged.bed cat $(for track in $tracks;do echo genome/hg38/bed/enhancer.${track}.bed;done) \\ | bedtools sort | bedtools merge -d 1 \\ | awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,$2,$3,\"enhancer\",0,\".\"}' > genome/hg38/bed/enhancer.merged.bed","title":"Promoter/enhancer from ChromHMM (hg19)"},{"location":"genome_and_annotations/#repeats","text":"UCSC GenomeBrowser -> Tools -> Table Browser assembly: GRCh38/hg38 group: repeats track: RepeatMasker table: rmsk Dowload to: genome/hg38/source/rmsk.bed.gz gunzip -c genome/hg38/source/rmsk.bed.gz | bedtools sort > genome/hg38/bed/rmsk.bed","title":"Repeats"},{"location":"genome_and_annotations/#circrna-database-circbase","text":"wget -O genome/hg38/source/circbase.hg19.fa.gz http://www.circbase.org/download/human_hg19_circRNAs_putative_spliced_sequence.fa.gz zcat genome/hg38/source/circbase.hg19.fa.gz | bin/preprocess.py extract_circrna_junction -s 150 -o genome/hg38/fasta/circRNA.fa samtools faidx genome/hg38/fasta/circRNA.fa STAR --runMode genomeGenerate --genomeSAindexNbases 10 --genomeChrBinNbits 7 --genomeDir genome/hg38/index/star/circRNA/ --genomeFastaFiles genome/hg38/fasta/circRNA.fa","title":"circRNA database (circBase)"},{"location":"genome_and_annotations/#merge-transcript-table","text":"{ echo -e 'chrom\\tstart\\tend\\tname\\tscore\\tstrand\\tgene_id\\ttranscript_id\\tgene_name\\ttranscript_name\\tgene_type\\ttranscript_type\\tsource' for rna_type in rRNA lncRNA miRNA mRNA piRNA snoRNA snRNA srpRNA tRNA tucpRNA Y_RNA;do sed '1 d' genome/hg38/transcript_table/${rna_type}.txt done } > genome/hg38/transcript_table/all.txt","title":"Merge transcript table"},{"location":"get_started/","text":"exSeek Workflow Installation Install required software packages according to requirements Download the scripts: git clone https://github.com/lulab/exSeek-dev.git Input files Genome and annotation directory Download preprocessed genome annotations to genome/hg38 Refer to the documentation for details. Input data files File name Description ${input_dir}/fastq/${sample_id}.fastq Read files (single-end sequencing) ${input_dir}/fastq/${sample_id}_1.fastq , ${input_dir}/fastq/${sample_id}_2.fastq Read files (paired-end sequencing) ${input_dir}/sample_ids.txt A text file with one sample ID per line. ${input_dir}/sample_classes.txt A tab-deliminated file (with header) with two columns: sample_id, label (optional) ${input_dir}/batch_info.txt A comma-deliminated file (with header) with at least two columns: sample_id, batch1, batch2, ... (optional) ${input_dir}/compare_groups.yaml A YAML file defining positive and negative classes. (optional) ${config_dir}/${dataset}.yaml A YAML file for configuration parameters for the dataset compare_groups.yaml Every key-value pairs defines a compare group and a negative-positive class pair: Normal-CRC: [\"Healthy Control\", \"Colorectal Cancer\"] Dataset configuration file All parameters are specified in a configuration file in YAML format. The default configuration file is (snakemake/default_config.yaml). Example configuration files can be found in config/ . The parameter values in the configuration file can also be overrided through the --config option in snakemake . The following parameters should be changed: Parameter Description Example genome_dir Directory for genome and annotation files genome/hg38 data_dir Directory for input files data/dataset temp_dir Temporary directory tmp output_dir Directory for all output files output/dataset aligner Mapping software bowtie2 adaptor 3' adaptor sequence for single-end RNA-seq AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC Cluster configuration file Please refer the link for descriptions of cluster configuration file. Basic usage of exSeek Run exseek.py --help to get basic usage: usage: exseek.py [-h] --dataset DATASET [--config-dir CONFIG_DIR] [--cluster] [--cluster-config CLUSTER_CONFIG] [--cluster-command CLUSTER_COMMAND] [--singularity SINGULARITY] [--singularity-wrapper-dir SINGULARITY_WRAPPER_DIR] {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} exSeek main program positional arguments: {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} optional arguments: -h, --help show this help message and exit --dataset DATASET, -d DATASET dataset name --config-dir CONFIG_DIR, -c CONFIG_DIR directory for configuration files --cluster submit to cluster --cluster-config CLUSTER_CONFIG cluster configuration file ({config_dir}/cluster.yaml by default) --cluster-command CLUSTER_COMMAND command for submitting job to cluster (default read from {config_dir}/cluster_command.txt --singularity SINGULARITY singularity image file --singularity-wrapper-dir SINGULARITY_WRAPPER_DIR directory for singularity wrappers Note Other arguments are passed to snakemake Specify number of processes to run in parallel with -j Small RNA-seq analysis Configuration file An example configuration file for small RNA single-end sequencing can be found in config/small_se_example.yaml . Quality control, adaptor removal and trimming ${exseek_path}/bin/exseek.py quality_control --dataset ${dataset} Mapping exseek.py mapping --dataset ${dataset} Note If you changed mapping order in the rna_types config variable, you should update the snakefile with the command: exseek.py update_sequential_mapping --dataset ${dataset} Description of output files: output_files Generate count matrix ${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset} Count matrix File path: ${output_dir}/count_matrix/transcript.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name Call domains ${exseek_path}/bin/exseek.py call_domains --dataset ${dataset} Read count matrix File path: ${output_dir}/count_matrix/domain_long.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name|domain_id|transcript_id|start|end Combine read counts of miRNA/piRNA and domains ${exseek_path}/bin/exseek.py combine_domains --dataset ${dataset} Normalization ${exseek_path}/bin/exseek.py normalization --dataset ${dataset} Feature selection ${exseek_path}/bin/exseek.py feature_selection --dataset ${dataset} Differential expression ${exseek_path}/bin/exseek.py differential_expression --dataset ${dataset} Long RNA-seq analysis Configuration file An example configuration file for long RNA paired-end sequencing can be found in config/long_pe_example.yaml . Quality control and adaptor removal ${exseek_path}/bin/exseek.py quality_control --dataset ${dataset} Mapping ${exseek_path}/bin/exseek.py mapping --dataset ${dataset} Generate count matrix ${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset} Frequently asked Questions FAQs","title":"Get Started"},{"location":"get_started/#exseek","text":"","title":"exSeek"},{"location":"get_started/#workflow","text":"","title":"Workflow"},{"location":"get_started/#installation","text":"Install required software packages according to requirements Download the scripts: git clone https://github.com/lulab/exSeek-dev.git","title":"Installation"},{"location":"get_started/#input-files","text":"","title":"Input files"},{"location":"get_started/#genome-and-annotation-directory","text":"Download preprocessed genome annotations to genome/hg38 Refer to the documentation for details.","title":"Genome and annotation directory"},{"location":"get_started/#input-data-files","text":"File name Description ${input_dir}/fastq/${sample_id}.fastq Read files (single-end sequencing) ${input_dir}/fastq/${sample_id}_1.fastq , ${input_dir}/fastq/${sample_id}_2.fastq Read files (paired-end sequencing) ${input_dir}/sample_ids.txt A text file with one sample ID per line. ${input_dir}/sample_classes.txt A tab-deliminated file (with header) with two columns: sample_id, label (optional) ${input_dir}/batch_info.txt A comma-deliminated file (with header) with at least two columns: sample_id, batch1, batch2, ... (optional) ${input_dir}/compare_groups.yaml A YAML file defining positive and negative classes. (optional) ${config_dir}/${dataset}.yaml A YAML file for configuration parameters for the dataset compare_groups.yaml Every key-value pairs defines a compare group and a negative-positive class pair: Normal-CRC: [\"Healthy Control\", \"Colorectal Cancer\"]","title":"Input data files"},{"location":"get_started/#dataset-configuration-file","text":"All parameters are specified in a configuration file in YAML format. The default configuration file is (snakemake/default_config.yaml). Example configuration files can be found in config/ . The parameter values in the configuration file can also be overrided through the --config option in snakemake . The following parameters should be changed: Parameter Description Example genome_dir Directory for genome and annotation files genome/hg38 data_dir Directory for input files data/dataset temp_dir Temporary directory tmp output_dir Directory for all output files output/dataset aligner Mapping software bowtie2 adaptor 3' adaptor sequence for single-end RNA-seq AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC","title":"Dataset configuration file"},{"location":"get_started/#cluster-configuration-file","text":"Please refer the link for descriptions of cluster configuration file.","title":"Cluster configuration file"},{"location":"get_started/#basic-usage-of-exseek","text":"Run exseek.py --help to get basic usage: usage: exseek.py [-h] --dataset DATASET [--config-dir CONFIG_DIR] [--cluster] [--cluster-config CLUSTER_CONFIG] [--cluster-command CLUSTER_COMMAND] [--singularity SINGULARITY] [--singularity-wrapper-dir SINGULARITY_WRAPPER_DIR] {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} exSeek main program positional arguments: {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} optional arguments: -h, --help show this help message and exit --dataset DATASET, -d DATASET dataset name --config-dir CONFIG_DIR, -c CONFIG_DIR directory for configuration files --cluster submit to cluster --cluster-config CLUSTER_CONFIG cluster configuration file ({config_dir}/cluster.yaml by default) --cluster-command CLUSTER_COMMAND command for submitting job to cluster (default read from {config_dir}/cluster_command.txt --singularity SINGULARITY singularity image file --singularity-wrapper-dir SINGULARITY_WRAPPER_DIR directory for singularity wrappers Note Other arguments are passed to snakemake Specify number of processes to run in parallel with -j","title":"Basic usage of exSeek"},{"location":"get_started/#small-rna-seq-analysis","text":"","title":"Small RNA-seq analysis"},{"location":"get_started/#configuration-file","text":"An example configuration file for small RNA single-end sequencing can be found in config/small_se_example.yaml .","title":"Configuration file"},{"location":"get_started/#quality-control-adaptor-removal-and-trimming","text":"${exseek_path}/bin/exseek.py quality_control --dataset ${dataset}","title":"Quality control, adaptor removal and trimming"},{"location":"get_started/#mapping","text":"exseek.py mapping --dataset ${dataset} Note If you changed mapping order in the rna_types config variable, you should update the snakefile with the command: exseek.py update_sequential_mapping --dataset ${dataset} Description of output files: output_files","title":"Mapping"},{"location":"get_started/#generate-count-matrix","text":"${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset} Count matrix File path: ${output_dir}/count_matrix/transcript.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name","title":"Generate count matrix"},{"location":"get_started/#call-domains","text":"${exseek_path}/bin/exseek.py call_domains --dataset ${dataset} Read count matrix File path: ${output_dir}/count_matrix/domain_long.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name|domain_id|transcript_id|start|end","title":"Call domains"},{"location":"get_started/#combine-read-counts-of-mirnapirna-and-domains","text":"${exseek_path}/bin/exseek.py combine_domains --dataset ${dataset}","title":"Combine read counts of miRNA/piRNA and domains"},{"location":"get_started/#normalization","text":"${exseek_path}/bin/exseek.py normalization --dataset ${dataset}","title":"Normalization"},{"location":"get_started/#feature-selection","text":"${exseek_path}/bin/exseek.py feature_selection --dataset ${dataset}","title":"Feature selection"},{"location":"get_started/#differential-expression","text":"${exseek_path}/bin/exseek.py differential_expression --dataset ${dataset}","title":"Differential expression"},{"location":"get_started/#long-rna-seq-analysis","text":"","title":"Long RNA-seq analysis"},{"location":"get_started/#configuration-file_1","text":"An example configuration file for long RNA paired-end sequencing can be found in config/long_pe_example.yaml .","title":"Configuration file"},{"location":"get_started/#quality-control-and-adaptor-removal","text":"${exseek_path}/bin/exseek.py quality_control --dataset ${dataset}","title":"Quality control and adaptor removal"},{"location":"get_started/#mapping_1","text":"${exseek_path}/bin/exseek.py mapping --dataset ${dataset}","title":"Mapping"},{"location":"get_started/#generate-count-matrix_1","text":"${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset}","title":"Generate count matrix"},{"location":"get_started/#frequently-asked-questions","text":"FAQs","title":"Frequently asked Questions"},{"location":"igv_browser/","text":"IGV Genome Browser Reference genome configuration file A template for reference configuration can be found in templates/igv/config/genome.yaml : genome: hg38 reference: id: hg38 name: hg38 fastaURL: genome/hg38/fasta/genome.fa indexURL: genome/hg38/fasta/genome.fa.fai cytobandURL: genome/hg38/igv/cytoBandIdeo.txt tracks: GENCODE_V27: name: GENCODE_V27 type: annotation format: bed url: genome/hg38/bed/gencode.bed indexURL: genome/hg38/bed/gencode.bed.idx displayMode: \"EXPANDED\" searchable: true visibilityWindow: 300000000 height: 100 show: true long_RNA_gene: name: long_RNA_gene type: annotation format: bed url: genome/hg38/bed/long_RNA.gene.bed indexURL: genome/hg38/bed/long_RNA.gene.bed.idx displayMode: \"EXPANDED\" searchable: true visibilityWindow: 300000000 height: 100 show: true Two keys are required: genome and reference . The annotation tracks can be provided in BED, genePred, genePredExt, GTF or GFF format. Custom reference genome from FASTA file Human rRNA # map NR_* ids to gene names tr '|' $'\\t' < \"genome/hg38/source/refSeq_rRNA.ids.txt\" > genome/hg38/source/refSeq_rRNA.gene_names.txt # create reference bin/create_igv.py create_reference --genome rRNA --name 'Human (rRNA)' \\ --gene-names genome/hg38/source/refSeq_rRNA.gene_names.txt \\ --fasta genome/hg38/fasta/rRNA.fa -o genome/hg38/igv/rRNA The create_reference command generates a directory names genome/hg38/igv/rRNA that contains the following files: Filename Description reference.fa Reference genome sequences reference.fa.fai FASTA index for reference.fa config.yaml Track configuration file for creating IGV web page annotation.bed Annotation for each sequence in FASTA file annotation.genePred Annotation in genePred format cytoband.txt Cytoband file Generate IGV HTML Configure web server Setup a web server using Apache or other HTTP engines and set the base URL: base_url=\"http://example.com/igv\" The directory structure of IGV should be like: /genome hg38/ igv/ fasta/ genome.fa genome.fai bed/ gencode.bed gencode.bed.idx long_RNA.bed long_RNA.bed.idx /igv config/ ${dataset}_${map_step}.yaml html/ ${dataset}_${map_step}.html Transcriptomic BigWig files (small RNA) bin/create_igv.py generate_config \\ --sample-classes data/${dataset}/sample_classes.txt \\ --bigwig-pattern \"${dataset}/{sample_id}.transcriptome.{strand}.bigWig\" \\ --base-url \"$base_url\" \\ --max-samples-per-class 10 \\ --reference \"templates/igv/config/genome.yaml\" \\ -o genome_browser/config/${dataset}_transcriptome.yaml bin/create_igv.py render -i templates/igv/main.html \\ -c genome_browser/config/${dataset}_transcriptome.yaml \\ -o genome_browser/igv/${dataset}_transcriptome.html BigWig files on custom reference genome (Long RNA) map_step=\"rRNA\" bin/create_igv.py generate_config --locus \"$locus\" \\ --sample-classes data/${dataset}/sample_classes.txt \\ --bigwig-pattern \"${dataset}/{sample_id}.${map_step}_rmdup.{strand}.bigWig\" \\ --base-url \"$base_url\" \\ --strand \"+\" \\ --max-samples-per-class 10 \\ --reference \"genome/hg38/igv/${map_step}/config.yaml\" \\ -o genome_browser/config/${dataset}_${map_step}.yaml Create feature database Create a feature database for searching genomic locus with feature names from a list of annotation files: [ -d \"igv/database\" ] || mkdir -p \"igv/database\" bin/web_server.py --build-database --genome hg38 \\ -i genome/hg38/gtf/gencode.gtf \\ -i genome/hg38/gtf/mitranscriptome_lncRNA.gtf \\ -i genome/hg38/gtf/mitranscriptome_tucp.gtf \\ -i genome/hg38/gff3/miRBase.gff3 \\ -o igv/database/hg38.pkl Start web server Start a web server that listens on port 5000 bin/web_server.py --host 0.0.0.0 --port 5000 -i igv/database/hg38.pkl Then navigate to http://<server>:5000/igv/${dataset}_genome.html to visit the genome browser.","title":"IGV Browser"},{"location":"igv_browser/#igv-genome-browser","text":"","title":"IGV Genome Browser"},{"location":"igv_browser/#reference-genome-configuration-file","text":"A template for reference configuration can be found in templates/igv/config/genome.yaml : genome: hg38 reference: id: hg38 name: hg38 fastaURL: genome/hg38/fasta/genome.fa indexURL: genome/hg38/fasta/genome.fa.fai cytobandURL: genome/hg38/igv/cytoBandIdeo.txt tracks: GENCODE_V27: name: GENCODE_V27 type: annotation format: bed url: genome/hg38/bed/gencode.bed indexURL: genome/hg38/bed/gencode.bed.idx displayMode: \"EXPANDED\" searchable: true visibilityWindow: 300000000 height: 100 show: true long_RNA_gene: name: long_RNA_gene type: annotation format: bed url: genome/hg38/bed/long_RNA.gene.bed indexURL: genome/hg38/bed/long_RNA.gene.bed.idx displayMode: \"EXPANDED\" searchable: true visibilityWindow: 300000000 height: 100 show: true Two keys are required: genome and reference . The annotation tracks can be provided in BED, genePred, genePredExt, GTF or GFF format.","title":"Reference genome configuration file"},{"location":"igv_browser/#custom-reference-genome-from-fasta-file","text":"","title":"Custom reference genome from FASTA file"},{"location":"igv_browser/#human-rrna","text":"# map NR_* ids to gene names tr '|' $'\\t' < \"genome/hg38/source/refSeq_rRNA.ids.txt\" > genome/hg38/source/refSeq_rRNA.gene_names.txt # create reference bin/create_igv.py create_reference --genome rRNA --name 'Human (rRNA)' \\ --gene-names genome/hg38/source/refSeq_rRNA.gene_names.txt \\ --fasta genome/hg38/fasta/rRNA.fa -o genome/hg38/igv/rRNA The create_reference command generates a directory names genome/hg38/igv/rRNA that contains the following files: Filename Description reference.fa Reference genome sequences reference.fa.fai FASTA index for reference.fa config.yaml Track configuration file for creating IGV web page annotation.bed Annotation for each sequence in FASTA file annotation.genePred Annotation in genePred format cytoband.txt Cytoband file","title":"Human rRNA"},{"location":"igv_browser/#generate-igv-html","text":"","title":"Generate IGV HTML"},{"location":"igv_browser/#configure-web-server","text":"Setup a web server using Apache or other HTTP engines and set the base URL: base_url=\"http://example.com/igv\" The directory structure of IGV should be like: /genome hg38/ igv/ fasta/ genome.fa genome.fai bed/ gencode.bed gencode.bed.idx long_RNA.bed long_RNA.bed.idx /igv config/ ${dataset}_${map_step}.yaml html/ ${dataset}_${map_step}.html","title":"Configure web server"},{"location":"igv_browser/#transcriptomic-bigwig-files-small-rna","text":"bin/create_igv.py generate_config \\ --sample-classes data/${dataset}/sample_classes.txt \\ --bigwig-pattern \"${dataset}/{sample_id}.transcriptome.{strand}.bigWig\" \\ --base-url \"$base_url\" \\ --max-samples-per-class 10 \\ --reference \"templates/igv/config/genome.yaml\" \\ -o genome_browser/config/${dataset}_transcriptome.yaml bin/create_igv.py render -i templates/igv/main.html \\ -c genome_browser/config/${dataset}_transcriptome.yaml \\ -o genome_browser/igv/${dataset}_transcriptome.html","title":"Transcriptomic BigWig files (small RNA)"},{"location":"igv_browser/#bigwig-files-on-custom-reference-genome-long-rna","text":"map_step=\"rRNA\" bin/create_igv.py generate_config --locus \"$locus\" \\ --sample-classes data/${dataset}/sample_classes.txt \\ --bigwig-pattern \"${dataset}/{sample_id}.${map_step}_rmdup.{strand}.bigWig\" \\ --base-url \"$base_url\" \\ --strand \"+\" \\ --max-samples-per-class 10 \\ --reference \"genome/hg38/igv/${map_step}/config.yaml\" \\ -o genome_browser/config/${dataset}_${map_step}.yaml","title":"BigWig files on custom reference genome (Long RNA)"},{"location":"igv_browser/#create-feature-database","text":"Create a feature database for searching genomic locus with feature names from a list of annotation files: [ -d \"igv/database\" ] || mkdir -p \"igv/database\" bin/web_server.py --build-database --genome hg38 \\ -i genome/hg38/gtf/gencode.gtf \\ -i genome/hg38/gtf/mitranscriptome_lncRNA.gtf \\ -i genome/hg38/gtf/mitranscriptome_tucp.gtf \\ -i genome/hg38/gff3/miRBase.gff3 \\ -o igv/database/hg38.pkl","title":"Create feature database"},{"location":"igv_browser/#start-web-server","text":"Start a web server that listens on port 5000 bin/web_server.py --host 0.0.0.0 --port 5000 -i igv/database/hg38.pkl Then navigate to http://<server>:5000/igv/${dataset}_genome.html to visit the genome browser.","title":"Start web server"},{"location":"installation/","text":"Installation Install exSeek git clone https://github.com/lulab/exSeek-dev.git Install required software Python 3.6 (miniconda) Python 2.7 (miniconda) Java 8 R 3.4 (https://mran.microsoft.com/download) Configure conda channels conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/mro/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ Install Python packages using conda conda install -y numpy scipy scikit-learn conda install -y pandas matplotlib seaborn conda install -y tqdm snakemake h5py bokeh conda install -y umap jinja2 pip install mlxtend pip install flask Flask-AutoIndex Install Bioconda packages List of all available Bioconda packages: (https://bioconda.github.io/recipes.html) conda install -y bedtools samtools star subread bowtie2 conda install -y rsem bamtools cutadapt picard gffread gffcompare conda install -y ucsc-bedtogenepred ucsc-genepredtogtf ucsc-bedgraphtobigwig ucsc-bigwigtobedgraph conda install -y htseq fastx_toolkit biopython rpy2 conda install -y flexbar Install Ubuntu packages sudo apt-get install -y gzip pigz openjdk-8-jdk libgraphviz-dev uuid-dev zlib1g-dev libpng-dev gawk Install R packages Install by running the following code in an R interactive session: options(\"repos\" = c(CRAN=\"https://mirrors.tuna.tsinghua.edu.cn/CRAN/\")) options(BioC_mirror=\"https://mirrors.tuna.tsinghua.edu.cn/bioconductor\") # From CRAN install.packages(c('devtools', 'sva', 'VGAM', 'argparse', 'magrittr', 'readr', 'mvoutlier', 'ggpubr', 'fastqr')) # From Bioconductor source('https://bioconductor.org/biocLite.R') biocLite(c('SingleCellExperiment', 'scater', 'scran', 'SCnorm', 'EDASeq', 'RUVSeq', 'DESeq2', 'edgeR', 'sva', 'apeglm')) # From R-forge install.packages('countreg', repos = c('http://R-Forge.R-project.org', 'https://mirrors.tuna.tsinghua.edu.cn/CRAN/'), dep = TRUE) # From GitHub library(devtools) install_github('ChenMengjie/VIPER') install_github('kassambara/easyGgplot2') install_github(\"Vivianstats/scImpute\") install_github(\"hemberg-lab/scRNA.seq.funcs\") Other packages find_circ 1.2 (depends on Python 2.7) GTFTools (depends on Python) Prinseq (requires Perl) Singularity Build image singularity build singularity/exseek.img singularity/Singularity Make wrappers for singularity executables bin/make_singularity_wrappers.py \\ --image ~/singularity/simg/exseek.simg \\ --list-file singularity/exports.txt \\ --singularity-path $(which singularity) \\ -o ~/singularity/wrappers/exseek Add wrappers to PATH export PATH=\"$HOME/singularity/wrappers/exseek:$PATH\" Build Pykent wget -O tools/ucsc-tools.tar.gz http://hgdownload.soe.ucsc.edu/admin/exe/userApps.src.tgz tar -C tools -zxf tools/ucsc-tools.tar.gz (cd tools/userApps/kent/src/htslib/ CFLAGS=\"-fPIC -DUCSC_CRAM=0 -DKNETFILE_HOOKS=1\" ./configure make ) (cd tools/userApps/kent/src/lib/ echo ' %.o: %.c ${CC} -fPIC ${COPT} ${CFLAGS} ${HG_DEFS} ${LOWELAB_DEFS} ${HG_WARN} ${HG_INC} ${XINC} -o $@ -c $< $(MACHTYPE)/libjkweb.so: $(O) $(MACHTYPE) gcc -fPIC -shared -o $(MACHTYPE)/libjkweb.so $(O) -Wl,-z,defs -L../htslib -lhts -lm -lz -lpthread -lpng -lcrypto -lssl -luuid ' > makefile make x86_64/libjkweb.so ) cp tools/userApps/kent/src/lib/x86_64/libjkweb.so lib/","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#install-exseek","text":"git clone https://github.com/lulab/exSeek-dev.git","title":"Install exSeek"},{"location":"installation/#install-required-software","text":"Python 3.6 (miniconda) Python 2.7 (miniconda) Java 8 R 3.4 (https://mran.microsoft.com/download)","title":"Install required software"},{"location":"installation/#configure-conda-channels","text":"conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/mro/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/","title":"Configure conda channels"},{"location":"installation/#install-python-packages-using-conda","text":"conda install -y numpy scipy scikit-learn conda install -y pandas matplotlib seaborn conda install -y tqdm snakemake h5py bokeh conda install -y umap jinja2 pip install mlxtend pip install flask Flask-AutoIndex","title":"Install Python packages using conda"},{"location":"installation/#install-bioconda-packages","text":"List of all available Bioconda packages: (https://bioconda.github.io/recipes.html) conda install -y bedtools samtools star subread bowtie2 conda install -y rsem bamtools cutadapt picard gffread gffcompare conda install -y ucsc-bedtogenepred ucsc-genepredtogtf ucsc-bedgraphtobigwig ucsc-bigwigtobedgraph conda install -y htseq fastx_toolkit biopython rpy2 conda install -y flexbar","title":"Install Bioconda packages"},{"location":"installation/#install-ubuntu-packages","text":"sudo apt-get install -y gzip pigz openjdk-8-jdk libgraphviz-dev uuid-dev zlib1g-dev libpng-dev gawk","title":"Install Ubuntu packages"},{"location":"installation/#install-r-packages","text":"Install by running the following code in an R interactive session: options(\"repos\" = c(CRAN=\"https://mirrors.tuna.tsinghua.edu.cn/CRAN/\")) options(BioC_mirror=\"https://mirrors.tuna.tsinghua.edu.cn/bioconductor\") # From CRAN install.packages(c('devtools', 'sva', 'VGAM', 'argparse', 'magrittr', 'readr', 'mvoutlier', 'ggpubr', 'fastqr')) # From Bioconductor source('https://bioconductor.org/biocLite.R') biocLite(c('SingleCellExperiment', 'scater', 'scran', 'SCnorm', 'EDASeq', 'RUVSeq', 'DESeq2', 'edgeR', 'sva', 'apeglm')) # From R-forge install.packages('countreg', repos = c('http://R-Forge.R-project.org', 'https://mirrors.tuna.tsinghua.edu.cn/CRAN/'), dep = TRUE) # From GitHub library(devtools) install_github('ChenMengjie/VIPER') install_github('kassambara/easyGgplot2') install_github(\"Vivianstats/scImpute\") install_github(\"hemberg-lab/scRNA.seq.funcs\")","title":"Install R packages"},{"location":"installation/#other-packages","text":"find_circ 1.2 (depends on Python 2.7) GTFTools (depends on Python) Prinseq (requires Perl)","title":"Other packages"},{"location":"installation/#singularity","text":"","title":"Singularity"},{"location":"installation/#build-image","text":"singularity build singularity/exseek.img singularity/Singularity","title":"Build image"},{"location":"installation/#make-wrappers-for-singularity-executables","text":"bin/make_singularity_wrappers.py \\ --image ~/singularity/simg/exseek.simg \\ --list-file singularity/exports.txt \\ --singularity-path $(which singularity) \\ -o ~/singularity/wrappers/exseek","title":"Make wrappers for singularity executables"},{"location":"installation/#add-wrappers-to-path","text":"export PATH=\"$HOME/singularity/wrappers/exseek:$PATH\"","title":"Add wrappers to PATH"},{"location":"installation/#build-pykent","text":"wget -O tools/ucsc-tools.tar.gz http://hgdownload.soe.ucsc.edu/admin/exe/userApps.src.tgz tar -C tools -zxf tools/ucsc-tools.tar.gz (cd tools/userApps/kent/src/htslib/ CFLAGS=\"-fPIC -DUCSC_CRAM=0 -DKNETFILE_HOOKS=1\" ./configure make ) (cd tools/userApps/kent/src/lib/ echo ' %.o: %.c ${CC} -fPIC ${COPT} ${CFLAGS} ${HG_DEFS} ${LOWELAB_DEFS} ${HG_WARN} ${HG_INC} ${XINC} -o $@ -c $< $(MACHTYPE)/libjkweb.so: $(O) $(MACHTYPE) gcc -fPIC -shared -o $(MACHTYPE)/libjkweb.so $(O) -Wl,-z,defs -L../htslib -lhts -lm -lz -lpthread -lpng -lcrypto -lssl -luuid ' > makefile make x86_64/libjkweb.so ) cp tools/userApps/kent/src/lib/x86_64/libjkweb.so lib/","title":"Build Pykent"},{"location":"long_rna_mapping/","text":"","title":"Long RNA-seq mapping"},{"location":"matrix_processing/","text":"Matrix Processing usage: bin/matrix-process.R [-h] -s STEP -i INPUT -c CLASS -b BATCH --filterout FILTEROUT --imputeout IMPUTEOUT --normalizeout NORMALIZEOUT --batchremoveout BATCHREMOVEOUT [--filtercount NUMBER] [--filtersample NUMBER] [--imputemethod STRING] [--imputecluster NUMBER] [--imputenum NUMBER] [--imputecutoff NUMBER] [--imputealpha NUMBER] [--normmethod STRING] [--normtopk NUMBER] [--cvthreshold NUMBER] [--removetype STRING] [--refergenefile STRING] [--batchmethod STRING] [--batchindex INT] [-p NUMBER] optional arguments: -h, --help show this help message and exit -s STEP, --step STEP which step to run -i INPUT, --input INPUT input expression matrix file -c CLASS, --class CLASS input class info file -b BATCH, --batch BATCH input batch info file --filterout FILTEROUT output filter path --imputeout IMPUTEOUT output imputation path --normalizeout NORMALIZEOUT output normalization file --batchremoveout BATCHREMOVEOUT output batchremoved file --filtercount NUMBER filter by counts of a gene [default = 5] --filtersample NUMBER filter by counts of sample above certain counts of a gene [default = 10] --imputemethod STRING the imputation algorithm to use [default = scimpute_count] --imputecluster NUMBER cluster number in scImpute [default = 5] --imputenum NUMBER number in viper [default = 5000] --imputecutoff NUMBER cutoff in viper [default = 0.5] --imputealpha NUMBER alpha in viper [default = 0.1] --normmethod STRING the normalization algorithm to use [default = SCNorm] --normtopk NUMBER top K feature as scale factor [default = 20] --cvthreshold NUMBER coefficient variance threshold of reference gene, filter ref gene with CV bigger than [default = 0.5] --removetype STRING remove some time of RNA for normalization scale factor calculation [default = miRNA,piRNA] --refergenefile STRING reference gene file path [default = None] --batchmethod STRING the batch removal algorithm to use [default = RUV] --batchindex INT batch index to select which batch to use [default = 1] -p NUMBER, --processors NUMBER Number of processors to use. This option is useful on multicore *nix or Mac machine only, when performing multiple runs (nrun > 1) [default = 1] Some parameters: -s filter imputation normalization batch_removal --imputemethod scimpute_count,viper_count,null --normmethod SCnorm,TMM,RLE,CPM,CPM_top,CPM_rm,CPM_refer,null --batchmetod RUV,Combat,null --batchindex 1 Example: bin/matrix-process.R -s imputation \\ -i output/lulab_hcc/count_matrix/domains_combined.txt \\ --filterout output/lulab_hcc/matrix_processing/ \\ --imputemethod viper_count \\ --imputeout output/lulab_hcc/matrix_processing/ \\ --filtercount 5 \\ --filtersample 10 \\ --imputecluster 5 \\ --imputenum 5000 \\ --imputecutoff 0.1 \\ --imputealpha 0.5 \\ -p 4 \\ --normalizeout output/lulab_hcc/matrix_processing/ \\ --normmethod RLE \\ --normtopk 20 \\ --removetype miRNA,piRNA \\ --cvthreshold 0.5 \\ --refergenefile data/matrix_processing/refer_gene_id.txt \\ -c data/lulab_hcc/sample_classes.txt \\ -b data/lulab_hcc/batch_info.txt \\ --batchremoveout output/scirep/matrix_processing/ \\ --batchmethod RUV \\ --batchindex 1 Filter filter lowly expressed reads Imputation scImpute Normalization Normalization is performed for the systematic error of each sample (such as the sequencing depth). Different Normalization Methods CPM(counts per million) Use candidate reference gene. For example: 'MIR1228', 'MIR16-1', 'MIR16-2', 'MIR21', 'MIR23A', 'MIR23B', 'MIR23C', 'MIR451A', 'MIR15A', 'MIR15B' remove piRNA and miRNA and use CPM(counts per million) Remove top k and scale others (then add top k back) use packages: SCNorm RLE TMM Select Reference Gene A density plot or a violin plot is used to analyze the coefficient of variation of different reference genes, and select stable miRNAs as an internal references with a small coefficient of variation. It can be seen that the variation coefficient of MIR1228 and MIR15B is not stable enough, and should not be used as an internal reference. Density plot of CV Boxplot of expression value (log) Criteria to use top20 We recommend to remove top20 and use left genes sum as scale factor if they account for more than 50% of total counts. cumulative ratio highest expressed gene Batch Removal Visualize Batch Effect - visualize batch by counts - visualize batch by specific RNA counts [ ] to do select batch factor plot Batch Removal methods RUVs Combat visualize processed result PCA visualization Use alignment score to Quantify Clustering effect. PCA and t-SNE can visualize the aggregation degree of the sample, but it cannot be quantified to compare different methods. We provide the following two functions alignment_socre & knn_score to quantify the binary classification and multi-class classification respectively. The closer the value is to 1, the more aggregated samples are. PCA visualization of original matrix and processed matrix expression vs count depth scImpute CPM CPM, remove mi and piRNA CPM remove top CPM use reference gene RLE -TMM -SCnorm Relative Log Expression box plot","title":"Matrix processing"},{"location":"matrix_processing/#matrix-processing","text":"usage: bin/matrix-process.R [-h] -s STEP -i INPUT -c CLASS -b BATCH --filterout FILTEROUT --imputeout IMPUTEOUT --normalizeout NORMALIZEOUT --batchremoveout BATCHREMOVEOUT [--filtercount NUMBER] [--filtersample NUMBER] [--imputemethod STRING] [--imputecluster NUMBER] [--imputenum NUMBER] [--imputecutoff NUMBER] [--imputealpha NUMBER] [--normmethod STRING] [--normtopk NUMBER] [--cvthreshold NUMBER] [--removetype STRING] [--refergenefile STRING] [--batchmethod STRING] [--batchindex INT] [-p NUMBER] optional arguments: -h, --help show this help message and exit -s STEP, --step STEP which step to run -i INPUT, --input INPUT input expression matrix file -c CLASS, --class CLASS input class info file -b BATCH, --batch BATCH input batch info file --filterout FILTEROUT output filter path --imputeout IMPUTEOUT output imputation path --normalizeout NORMALIZEOUT output normalization file --batchremoveout BATCHREMOVEOUT output batchremoved file --filtercount NUMBER filter by counts of a gene [default = 5] --filtersample NUMBER filter by counts of sample above certain counts of a gene [default = 10] --imputemethod STRING the imputation algorithm to use [default = scimpute_count] --imputecluster NUMBER cluster number in scImpute [default = 5] --imputenum NUMBER number in viper [default = 5000] --imputecutoff NUMBER cutoff in viper [default = 0.5] --imputealpha NUMBER alpha in viper [default = 0.1] --normmethod STRING the normalization algorithm to use [default = SCNorm] --normtopk NUMBER top K feature as scale factor [default = 20] --cvthreshold NUMBER coefficient variance threshold of reference gene, filter ref gene with CV bigger than [default = 0.5] --removetype STRING remove some time of RNA for normalization scale factor calculation [default = miRNA,piRNA] --refergenefile STRING reference gene file path [default = None] --batchmethod STRING the batch removal algorithm to use [default = RUV] --batchindex INT batch index to select which batch to use [default = 1] -p NUMBER, --processors NUMBER Number of processors to use. This option is useful on multicore *nix or Mac machine only, when performing multiple runs (nrun > 1) [default = 1] Some parameters: -s filter imputation normalization batch_removal --imputemethod scimpute_count,viper_count,null --normmethod SCnorm,TMM,RLE,CPM,CPM_top,CPM_rm,CPM_refer,null --batchmetod RUV,Combat,null --batchindex 1 Example: bin/matrix-process.R -s imputation \\ -i output/lulab_hcc/count_matrix/domains_combined.txt \\ --filterout output/lulab_hcc/matrix_processing/ \\ --imputemethod viper_count \\ --imputeout output/lulab_hcc/matrix_processing/ \\ --filtercount 5 \\ --filtersample 10 \\ --imputecluster 5 \\ --imputenum 5000 \\ --imputecutoff 0.1 \\ --imputealpha 0.5 \\ -p 4 \\ --normalizeout output/lulab_hcc/matrix_processing/ \\ --normmethod RLE \\ --normtopk 20 \\ --removetype miRNA,piRNA \\ --cvthreshold 0.5 \\ --refergenefile data/matrix_processing/refer_gene_id.txt \\ -c data/lulab_hcc/sample_classes.txt \\ -b data/lulab_hcc/batch_info.txt \\ --batchremoveout output/scirep/matrix_processing/ \\ --batchmethod RUV \\ --batchindex 1","title":"Matrix Processing"},{"location":"matrix_processing/#filter","text":"filter lowly expressed reads","title":"Filter"},{"location":"matrix_processing/#imputation","text":"scImpute","title":"Imputation"},{"location":"matrix_processing/#normalization","text":"Normalization is performed for the systematic error of each sample (such as the sequencing depth). Different Normalization Methods CPM(counts per million) Use candidate reference gene. For example: 'MIR1228', 'MIR16-1', 'MIR16-2', 'MIR21', 'MIR23A', 'MIR23B', 'MIR23C', 'MIR451A', 'MIR15A', 'MIR15B' remove piRNA and miRNA and use CPM(counts per million) Remove top k and scale others (then add top k back) use packages: SCNorm RLE TMM","title":"Normalization"},{"location":"matrix_processing/#select-reference-gene","text":"A density plot or a violin plot is used to analyze the coefficient of variation of different reference genes, and select stable miRNAs as an internal references with a small coefficient of variation. It can be seen that the variation coefficient of MIR1228 and MIR15B is not stable enough, and should not be used as an internal reference. Density plot of CV Boxplot of expression value (log)","title":"Select Reference Gene"},{"location":"matrix_processing/#criteria-to-use-top20","text":"We recommend to remove top20 and use left genes sum as scale factor if they account for more than 50% of total counts. cumulative ratio highest expressed gene","title":"Criteria to use top20"},{"location":"matrix_processing/#batch-removal","text":"","title":"Batch Removal"},{"location":"matrix_processing/#visualize-batch-effect","text":"","title":"Visualize Batch Effect"},{"location":"matrix_processing/#-visualize-batch-by-counts","text":"","title":"- visualize batch by counts"},{"location":"matrix_processing/#-visualize-batch-by-specific-rna-counts","text":"[ ] to do select batch factor plot","title":"- visualize batch by specific RNA counts"},{"location":"matrix_processing/#batch-removal-methods","text":"RUVs Combat","title":"Batch Removal methods"},{"location":"matrix_processing/#visualize-processed-result","text":"","title":"visualize processed result"},{"location":"matrix_processing/#pca-visualization","text":"Use alignment score to Quantify Clustering effect. PCA and t-SNE can visualize the aggregation degree of the sample, but it cannot be quantified to compare different methods. We provide the following two functions alignment_socre & knn_score to quantify the binary classification and multi-class classification respectively. The closer the value is to 1, the more aggregated samples are. PCA visualization of original matrix and processed matrix","title":"PCA visualization"},{"location":"matrix_processing/#expression-vs-count-depth","text":"scImpute CPM CPM, remove mi and piRNA CPM remove top CPM use reference gene RLE -TMM -SCnorm","title":"expression vs count depth"},{"location":"matrix_processing/#relative-log-expression-box-plot","text":"","title":"Relative Log Expression box plot"},{"location":"quality_control/","text":"","title":"Quality Control"},{"location":"small_rna_mapping/","text":"","title":"Small RNA-seq mapping"}]}