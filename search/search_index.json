{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"exSeek Workflow Installation Install required software packages according to requirements Download the scripts: git clone https://github.com/lulab/exSeek-dev.git Input files Genome and annotation directory Download preprocessed genome annotations to genome/hg38 Refer to the documentation for details. Input data files File name Description ${input_dir}/fastq/${sample_id}.fastq Read files (single-end sequencing) ${input_dir}/fastq/${sample_id}_1.fastq , ${input_dir}/fastq/${sample_id}_2.fastq Read files (paired-end sequencing) ${input_dir}/sample_ids.txt A text file with one sample ID per line. ${input_dir}/sample_classes.txt A tab-deliminated file (with header) with two columns: sample_id, label (optional) ${input_dir}/batch_info.txt A comma-deliminated file (with header) with at least two columns: sample_id, batch1, batch2, ... (optional) ${input_dir}/compare_groups.yaml A YAML file defining positive and negative classes. (optional) ${config_dir}/${dataset}.yaml A YAML file for configuration parameters for the dataset compare_groups.yaml Every key-value pairs defines a compare group and a negative-positive class pair: Normal-CRC: [\"Healthy Control\", \"Colorectal Cancer\"] Dataset configuration file All parameters are specified in a configuration file in YAML format. The default configuration file is (snakemake/default_config.yaml). Example configuration files can be found in config/ . The parameter values in the configuration file can also be overrided through the --config option in snakemake . The following parameters should be changed: Parameter Description Example genome_dir Directory for genome and annotation files genome/hg38 data_dir Directory for input files data/dataset temp_dir Temporary directory tmp output_dir Directory for all output files output/dataset aligner Mapping software bowtie2 adaptor 3' adaptor sequence for single-end RNA-seq AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC Cluster configuration file Please refer the link for descriptions of cluster configuration file. Basic usage of exSeek Run exseek.py --help to get basic usage: usage: exseek.py [-h] --dataset DATASET [--config-dir CONFIG_DIR] [--cluster] [--cluster-config CLUSTER_CONFIG] [--cluster-command CLUSTER_COMMAND] [--singularity SINGULARITY] [--singularity-wrapper-dir SINGULARITY_WRAPPER_DIR] {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} exSeek main program positional arguments: {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} optional arguments: -h, --help show this help message and exit --dataset DATASET, -d DATASET dataset name --config-dir CONFIG_DIR, -c CONFIG_DIR directory for configuration files --cluster submit to cluster --cluster-config CLUSTER_CONFIG cluster configuration file ({config_dir}/cluster.yaml by default) --cluster-command CLUSTER_COMMAND command for submitting job to cluster (default read from {config_dir}/cluster_command.txt --singularity SINGULARITY singularity image file --singularity-wrapper-dir SINGULARITY_WRAPPER_DIR directory for singularity wrappers Note Other arguments are passed to snakemake Specify number of processes to run in parallel with -j Small RNA-seq analysis Configuration file An example configuration file for small RNA single-end sequencing can be found in config/small_se_example.yaml . Quality control, adaptor removal and trimming ${exseek_path}/bin/exseek.py quality_control --dataset ${dataset} Mapping exseek.py mapping --dataset ${dataset} Note If you changed mapping order in the rna_types config variable, you should update the snakefile with the command: exseek.py update_sequential_mapping --dataset ${dataset} Description of output files: output_files Generate count matrix ${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset} Count matrix File path: ${output_dir}/count_matrix/transcript.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name Call domains ${exseek_path}/bin/exseek.py call_domains --dataset ${dataset} Read count matrix File path: ${output_dir}/count_matrix/domain_long.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name|domain_id|transcript_id|start|end Combine read counts of miRNA/piRNA and domains ${exseek_path}/bin/exseek.py combine_domains --dataset ${dataset} Normalization ${exseek_path}/bin/exseek.py normalization --dataset ${dataset} Feature selection ${exseek_path}/bin/exseek.py feature_selection --dataset ${dataset} Differential expression ${exseek_path}/bin/exseek.py differential_expression --dataset ${dataset} Long RNA-seq analysis Configuration file An example configuration file for long RNA paired-end sequencing can be found in config/long_pe_example.yaml . Quality control and adaptor removal ${exseek_path}/bin/exseek.py quality_control --dataset ${dataset} Mapping ${exseek_path}/bin/exseek.py mapping --dataset ${dataset} Generate count matrix ${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset} Frequently asked Questions FAQs","title":"Overview"},{"location":"#exseek","text":"","title":"exSeek"},{"location":"#workflow","text":"","title":"Workflow"},{"location":"#installation","text":"Install required software packages according to requirements Download the scripts: git clone https://github.com/lulab/exSeek-dev.git","title":"Installation"},{"location":"#input-files","text":"","title":"Input files"},{"location":"#genome-and-annotation-directory","text":"Download preprocessed genome annotations to genome/hg38 Refer to the documentation for details.","title":"Genome and annotation directory"},{"location":"#input-data-files","text":"File name Description ${input_dir}/fastq/${sample_id}.fastq Read files (single-end sequencing) ${input_dir}/fastq/${sample_id}_1.fastq , ${input_dir}/fastq/${sample_id}_2.fastq Read files (paired-end sequencing) ${input_dir}/sample_ids.txt A text file with one sample ID per line. ${input_dir}/sample_classes.txt A tab-deliminated file (with header) with two columns: sample_id, label (optional) ${input_dir}/batch_info.txt A comma-deliminated file (with header) with at least two columns: sample_id, batch1, batch2, ... (optional) ${input_dir}/compare_groups.yaml A YAML file defining positive and negative classes. (optional) ${config_dir}/${dataset}.yaml A YAML file for configuration parameters for the dataset compare_groups.yaml Every key-value pairs defines a compare group and a negative-positive class pair: Normal-CRC: [\"Healthy Control\", \"Colorectal Cancer\"]","title":"Input data files"},{"location":"#dataset-configuration-file","text":"All parameters are specified in a configuration file in YAML format. The default configuration file is (snakemake/default_config.yaml). Example configuration files can be found in config/ . The parameter values in the configuration file can also be overrided through the --config option in snakemake . The following parameters should be changed: Parameter Description Example genome_dir Directory for genome and annotation files genome/hg38 data_dir Directory for input files data/dataset temp_dir Temporary directory tmp output_dir Directory for all output files output/dataset aligner Mapping software bowtie2 adaptor 3' adaptor sequence for single-end RNA-seq AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC","title":"Dataset configuration file"},{"location":"#cluster-configuration-file","text":"Please refer the link for descriptions of cluster configuration file.","title":"Cluster configuration file"},{"location":"#basic-usage-of-exseek","text":"Run exseek.py --help to get basic usage: usage: exseek.py [-h] --dataset DATASET [--config-dir CONFIG_DIR] [--cluster] [--cluster-config CLUSTER_CONFIG] [--cluster-command CLUSTER_COMMAND] [--singularity SINGULARITY] [--singularity-wrapper-dir SINGULARITY_WRAPPER_DIR] {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} exSeek main program positional arguments: {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} optional arguments: -h, --help show this help message and exit --dataset DATASET, -d DATASET dataset name --config-dir CONFIG_DIR, -c CONFIG_DIR directory for configuration files --cluster submit to cluster --cluster-config CLUSTER_CONFIG cluster configuration file ({config_dir}/cluster.yaml by default) --cluster-command CLUSTER_COMMAND command for submitting job to cluster (default read from {config_dir}/cluster_command.txt --singularity SINGULARITY singularity image file --singularity-wrapper-dir SINGULARITY_WRAPPER_DIR directory for singularity wrappers Note Other arguments are passed to snakemake Specify number of processes to run in parallel with -j","title":"Basic usage of exSeek"},{"location":"#small-rna-seq-analysis","text":"","title":"Small RNA-seq analysis"},{"location":"#configuration-file","text":"An example configuration file for small RNA single-end sequencing can be found in config/small_se_example.yaml .","title":"Configuration file"},{"location":"#quality-control-adaptor-removal-and-trimming","text":"${exseek_path}/bin/exseek.py quality_control --dataset ${dataset}","title":"Quality control, adaptor removal and trimming"},{"location":"#mapping","text":"exseek.py mapping --dataset ${dataset} Note If you changed mapping order in the rna_types config variable, you should update the snakefile with the command: exseek.py update_sequential_mapping --dataset ${dataset} Description of output files: output_files","title":"Mapping"},{"location":"#generate-count-matrix","text":"${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset} Count matrix File path: ${output_dir}/count_matrix/transcript.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name","title":"Generate count matrix"},{"location":"#call-domains","text":"${exseek_path}/bin/exseek.py call_domains --dataset ${dataset} Read count matrix File path: ${output_dir}/count_matrix/domain_long.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name|domain_id|transcript_id|start|end","title":"Call domains"},{"location":"#combine-read-counts-of-mirnapirna-and-domains","text":"${exseek_path}/bin/exseek.py combine_domains --dataset ${dataset}","title":"Combine read counts of miRNA/piRNA and domains"},{"location":"#normalization","text":"${exseek_path}/bin/exseek.py normalization --dataset ${dataset}","title":"Normalization"},{"location":"#feature-selection","text":"${exseek_path}/bin/exseek.py feature_selection --dataset ${dataset}","title":"Feature selection"},{"location":"#differential-expression","text":"${exseek_path}/bin/exseek.py differential_expression --dataset ${dataset}","title":"Differential expression"},{"location":"#long-rna-seq-analysis","text":"","title":"Long RNA-seq analysis"},{"location":"#configuration-file_1","text":"An example configuration file for long RNA paired-end sequencing can be found in config/long_pe_example.yaml .","title":"Configuration file"},{"location":"#quality-control-and-adaptor-removal","text":"${exseek_path}/bin/exseek.py quality_control --dataset ${dataset}","title":"Quality control and adaptor removal"},{"location":"#mapping_1","text":"${exseek_path}/bin/exseek.py mapping --dataset ${dataset}","title":"Mapping"},{"location":"#generate-count-matrix_1","text":"${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset}","title":"Generate count matrix"},{"location":"#frequently-asked-questions","text":"FAQs","title":"Frequently asked Questions"},{"location":"FAQ/","text":"Frequently Asked Questions How to install and set up the environment We have packaged everything into docker and singularity. The easiest and recommended way is via Singularity. You can refer to this doc's Singularity part How to use exSeek exSeek is an integrative tool for exRNA processing and feature selection. We use snakemake for parallel running and further integrate snakemake pipeline into one single command. Details of preparing steps are described here . Basically you should complete the following steps before running the command: Install exseek and requirements Prepare genome and annotation prepare input files in right file path set up configuration Then you can run the command, you can specify the module you want to run and dataset you provide. ${exseek_path}/bin/exseek.py quality_control --dataset ${dataset} What is Snakemake The Snakemake workflow management system is a tool to create reproducible and scalable data analyses. We have hide the details of snakemake and you only need to run one single command. However you can customize some of the codes if you are familiar with snakemake. How to set configurations in config file There are many parameters to be specified. You should make a new copy of config file in config directory. For example you can nake one copy of scirep.yaml. Then rename the file to config/${dataset}.yaml. Other parameters are defined in snakemake/default_config.yaml. You may also change parameters. How to generate report After running some modules, e.g., mapping, normalization and evaluation. You can open jupyter notebook files in notebooks file. The only thing to do is to fill in the dataset name and sequencing type. For example: dataset='scirep' sequencing_type = 'short' Then you can get plots of your mapping, processing and feature selection details in one jupyter notebook. Note: the notebook is based on exseek output style. If you process your data on your own without exseek and only need the jupyter to generate plots, you should change the codes for file paths in jupyter notebook to successfully generate plots. When bugs appear: The quickest way is to create a new issue If you want us to add more functions in exseek, please create a new issue","title":"Frequently Asked Questions"},{"location":"FAQ/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"FAQ/#how-to-install-and-set-up-the-environment","text":"We have packaged everything into docker and singularity. The easiest and recommended way is via Singularity. You can refer to this doc's Singularity part","title":"How to install and set up the environment"},{"location":"FAQ/#how-to-use-exseek","text":"exSeek is an integrative tool for exRNA processing and feature selection. We use snakemake for parallel running and further integrate snakemake pipeline into one single command. Details of preparing steps are described here . Basically you should complete the following steps before running the command: Install exseek and requirements Prepare genome and annotation prepare input files in right file path set up configuration Then you can run the command, you can specify the module you want to run and dataset you provide. ${exseek_path}/bin/exseek.py quality_control --dataset ${dataset}","title":"How to use exSeek"},{"location":"FAQ/#what-is-snakemake","text":"The Snakemake workflow management system is a tool to create reproducible and scalable data analyses. We have hide the details of snakemake and you only need to run one single command. However you can customize some of the codes if you are familiar with snakemake.","title":"What is Snakemake"},{"location":"FAQ/#how-to-set-configurations-in-config-file","text":"There are many parameters to be specified. You should make a new copy of config file in config directory. For example you can nake one copy of scirep.yaml. Then rename the file to config/${dataset}.yaml. Other parameters are defined in snakemake/default_config.yaml. You may also change parameters.","title":"How to set configurations in config file"},{"location":"FAQ/#how-to-generate-report","text":"After running some modules, e.g., mapping, normalization and evaluation. You can open jupyter notebook files in notebooks file. The only thing to do is to fill in the dataset name and sequencing type. For example: dataset='scirep' sequencing_type = 'short' Then you can get plots of your mapping, processing and feature selection details in one jupyter notebook. Note: the notebook is based on exseek output style. If you process your data on your own without exseek and only need the jupyter to generate plots, you should change the codes for file paths in jupyter notebook to successfully generate plots.","title":"How to generate report"},{"location":"FAQ/#when-bugs-appear","text":"The quickest way is to create a new issue If you want us to add more functions in exseek, please create a new issue","title":"When bugs appear:"},{"location":"adapter_removal/","text":"","title":"Adapter Removal"},{"location":"bigwig/","text":"","title":"Generate BigWig Files"},{"location":"cluster_configuration/","text":"Cluster configuration cluster configuration : config/cluster.yaml Here is an example configuration: __default__: queue: queue name: {rule}.{wildcards} stderr: logs/cluster/{rule}/{wildcards}.stderr stdout: logs/cluster/{rule}/{wildcards}.stdout threads: {threads} resources: span[hosts=1] cluster command : config/cluster_command.txt bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads} Commonly used parameters Parameter Description __default__ Rule name ( __default__ ) for default configuration) queue Queue name (required) name Job name stderr Log file for standard error stdout Log file for standard output threads Number of parallel threads for a job resources Resource requirements. span[hosts=1] prevents parallel jobs from being submitted to different nodes Refer to the snakemake documentation .","title":"Run on a cluster"},{"location":"cluster_configuration/#cluster-configuration","text":"cluster configuration : config/cluster.yaml Here is an example configuration: __default__: queue: queue name: {rule}.{wildcards} stderr: logs/cluster/{rule}/{wildcards}.stderr stdout: logs/cluster/{rule}/{wildcards}.stdout threads: {threads} resources: span[hosts=1] cluster command : config/cluster_command.txt bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads} Commonly used parameters Parameter Description __default__ Rule name ( __default__ ) for default configuration) queue Queue name (required) name Job name stderr Log file for standard error stdout Log file for standard output threads Number of parallel threads for a job resources Resource requirements. span[hosts=1] prevents parallel jobs from being submitted to different nodes Refer to the snakemake documentation .","title":"Cluster configuration"},{"location":"configuration/","text":"","title":"Configuration File Reference"},{"location":"genome_and_annotations/","text":"Genome and Annotations Annotation summary table Type Number of genes Source miRNA 1917 miRBase hairpin (Version 22) piRNA 23431 piRNABank lncRNA 15778 GENCODE V27 and mitranscriptome rRNA 37 NCBI refSeq 109 mRNA 19836 GENCODE V27 snoRNA 943 GENCODE V27 snRNA 1900 GENCODE V27 srpRNA 680 GENCODE V27 tRNA 649 GENCODE V27 tucpRNA 3734 GENCODE V27 Y_RNA 756 GENCODE V27 circRNA 140527 circBase repeats - UCSC Genome Browser (rmsk) promoter - ChromHMM tracks from 9 cell lines from UCSC Genome Browser enhancer - ChromHMM tracks from 9 cell lines from UCSC Genome Browser Genome and annotation files File Description fasta/genome.fa genome sequence fasta/circRNA.fa junction sequence in circBase fasta/rRNA.fa rRNA sequences in NCBI RefSeq fasta/miRNA.fa miRNA hairpin (precursor) sequences in miRBase fasta/piRNA.fa piRNA sequences in piRNABank fasta/${rna_type}.fa Longest isoform for each gene extracted from GENCODE annotations gtf_by_biotype/${rna_type}.gtf separate GTF files for each RNA type gtf/gencode.gtf GENCODE GTF file gtf/mitranscriptome.gtf Mitranscriptome GTF file gtf/long_RNA.gtf GTF file of Long RNA (GENCODE + Mitranscriptome - miRNA) gtf/piRNABank.gtf piRNA GTF file from piRNABank gtf/gencode_tRNA.gtf GTF file of tRNA from GENCODE transcript_table/all.txt Table of transcript information (gene_id, transcript_id) rsem_index/bowtie2/${rna_type} RSEM index files for each RNA type (built using the longest transcripts) rsem_index/bowtie2/${rna_type}.transcripts.fa Sequence for each RNA type (longest transcripts) gtf_longest_transcript/${rna_type}.gtf GTF files for the longest isoforms from GENCODE and Mitranscriptome bed/*.bed Transcript in BED12 format extracted from GTF files in `gtf/*.gtf index/bowtie2/${rna_type} STAR index for transcripts index/star/${rna_type} STAR index for transcripts long_index/star/ STAR index including splicing junctions of long RNA Generate the genome and annotation files Create genome directory [ -d \"genome/hg38/source\" ] || mkdir -p \"genome/hg38/source\" Chromosome ID conversion table Column 1: UCSC chromosome ID Column 2: RefSeq chromosome ID mysql --user=genome --host=genome-mysql.cse.ucsc.edu -A -N -e \"SELECT * FROM ucscToRefSeq;\" hg38 | cut -f1,4 > genome/hg38/source/ucscToRefSeq.txt Download Gene annotation (NCBI) # NCBI Human Release 109 wget -P genome/hg38/source ftp://ftp.ncbi.nlm.nih.gov/genomes/H_sapiens/GFF/ref_GRCh38.p12_top_level.gff3.gz [ -d genome/hg38/gff3 ] || mkdir -p genome/hg38/gff3 awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"} NR==FNR{c[$2]=$1;next} !/^#/{chrom=c[$1]; if(length(chrom) > 0) print c[$1],$2,$3,$4,$5,$6,$7,$8,$9}' \\ genome/hg38/source/ucscToRefSeq.txt <(zcat genome/hg38/source/ref_GRCh38.p12_top_level.gff3.gz) \\ > genome/hg38/gff3/refseq.gff3 gffread --bed -o genome/hg38/bed/ncbi.bed genome/hg38/gff3/refseq.gff3 wget -O genome/hg38/source/refSeq_rna.fa.gz ftp://ftp.ncbi.nlm.nih.gov/genomes/H_sapiens/RNA/rna.fa.gz # get rRNA sequence IDs zgrep 'ribosomal RNA$' genome/hg38/source/refSeq_rna.fa.gz \\ | sed 's/>ref|\\(NR_[0-9.]\\+\\)|.*(\\([^)]\\+\\)).*/\\1|\\2/' > genome/hg38/source/refSeq_rRNA.ids.txt # get rRNA sequences zcat genome/hg38/source/refSeq_rna.fa.gz \\ | awk 'FNR==NR{split($0,a,\"|\");ids[a[1]]=1;next} {if($0 ~ /^>/){split($0,a,\"|\");if(ids[a[2]] == 1){keep=1; print \">\" a[2];}else{keep=0}} else{if(keep == 1){print}}}' \\ genome/hg38/source/refSeq_rRNA.ids.txt - > genome/hg38/fasta/rRNA.fa samtools faidx genome/hg38/fasta/rRNA.fa # generate transcript table { echo -e 'chrom\\tstart\\tend\\tname\\tscore\\tstrand\\tgene_id\\ttranscript_id\\tgene_name\\ttranscript_name\\tgene_type\\ttranscript_type\\tsource' awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}FNR==NR{split($0,a,\"|\");gene_name[a[1]]=a[2];next}{print $1,0,$2,a[1],0,\"+\",$1,$1,gene_name[$1],gene_name[$1],\"rRNA\",\"rRNA\",\"RefSeq\"}' \\ genome/hg38/source/refSeq_rRNA.ids.txt genome/hg38/fasta/rRNA.fa.fai } > genome/hg38/transcript_table/rRNA.txt # get transcript sizes cut -f1,2 genome/hg38/fasta/rRNA.fa.fai > genome/hg38/chrom_sizes/rRNA # build STAR index (small genome) STAR --runMode genomeGenerate --genomeSAindexNbases 5 --genomeDir genome/hg38/index/star/rRNA/ --genomeFastaFiles genome/hg38/fasta/rRNA.fa Download chain files for CrossMap wget -O genome/hg38/source/hg18ToHg38.over.chain.gz http://hgdownload.soe.ucsc.edu/goldenPath/hg18/liftOver/hg18ToHg38.over.chain.gz wget -O genome/hg38/source/NCBI36_to_GRCh38.chain.gz https://sourceforge.net/projects/crossmap/files/Ensembl_chain_files/homo_sapiens%28human%29/NCBI36_to_GRCh38.chain.gz Genome assembly (UCSC hg38) wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz gzip -d -c genome/hg38/source/hg38.fa.gz > genome/hg38/fasta/genome.fa samtools faidx genome/hg38/fasta/genome.fa ENCODE annotations wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.annotation.gtf.gz #wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.annotation.gff3.gz wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.long_noncoding_RNAs.gtf.gz #wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.long_noncoding_RNAs.gff3.gz wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.tRNAs.gtf.gz #wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.tRNAs.gff3.gz zcat genome/hg38/source/gencode.v27.annotation.gtf.gz > genome/hg38/gtf/gencode.gtf zcat genome/hg38/source/gencode.v27.long_noncoding_RNAs.gtf.gz > genome/hg38/gtf/gencode_lncRNA.gtf zcat genome/hg38/source/gencode.v27.tRNAs.gtf.gz \\ | awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"}{print $1,$2,\"exon\",$4,$5,$6,$7,$8,$9}' > genome/hg38/gtf/gencode_tRNA.gtf # Chain file for converting hg19 to hg38 wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz Mitranscriptome wget -P genome/hg38/source http://mitranscriptome.org/download/mitranscriptome.gtf.tar.gz tar -C genome/hg38/source --strip-components=1 -zxf genome/hg38/source/mitranscriptome.gtf.tar.gz mitranscriptome.gtf/mitranscriptome.v2.gtf.gz # convert from hg19 to hg38 zcat genome/hg38/source/mitranscriptome.v2.gtf.gz \\ | CrossMap.py gff genome/hg38/source/hg19ToHg38.over.chain.gz /dev/stdin genome/hg38/source/mitranscriptome.v2.hg38.gtf # remove invalid transcripts bin/preprocess.py fix_gtf -i genome/hg38/source/mitranscriptome.v2.hg38.gtf -o genome/hg38/gtf/mitranscriptome.gtf Extract lncRNA and TUCP RNA to separate GTF files: grep 'tcat \"lncrna\"' genome/hg38/gtf/mitranscriptome.gtf > genome/hg38/gtf/mitranscriptome_lncRNA.gtf # add exon feature grep 'tcat \"tucp\"' genome/hg38/gtf/mitranscriptome.gtf \\ | awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print;print $1,$2,\"exon\",$4,$5,$6,$7,$8,$9}' > genome/hg38/gtf/mitranscriptome_tucp.gtf cp genome/hg38/gtf/mitranscriptome_tucp.gtf genome/hg38/gtf_by_biotype/tucpRNA.gtf NONCODE wget -P genome/hg38/source http://www.noncode.org/datadownload/NONCODEv5_human_hg38_lncRNA.gtf.gz zcat genome/hg38/source/NONCODEv5_human_hg38_lncRNA.gtf.gz \\ | awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"}$7 != \".\" {print $1,\"NONCODE\",$3,$4,$5,$6,$7,$8,$9}' > genome/hg38/gtf/noncode.gtf lncRNAs identified in HCC (Nature communications 2017) wget -P genome/hg38/source https://media.nature.com/original/nature-assets/ncomms/2017/170213/ncomms14421/extref/ncomms14421-s3.txt awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"}{print $1,\"ncomms2017\",$3,$4,$5,$6,$7,$8,$9}' genome/hg38/source/ncomms14421-s3.txt > genome/hg38/source/ncomms2017.gtf CrossMap.py gff genome/hg38/source/hg19ToHg38.over.chain.gz genome/hg38/source/ncomms2017.gtf genome/hg38/source/ncomms2017.hg38.gtf ln genome/hg38/source/ncomms2017.hg38.gtf genome/hg38/gtf/ncomms2017.gtf Merge lncRNA (GENCODE and Mitranscriptome) cat genome/hg38/gtf/gencode_lncRNA.gtf \\ genome/hg38/gtf/mitranscriptome_lncRNA.gtf \\ > genome/hg38/gtf/merged_lncRNA.gtf cp genome/hg38/gtf/merged_lncRNA.gtf genome/hg38/gtf_by_biotype/lncRNA.gtf piRBase (v1.0) wget -O genome/hg38/source/piRBase-hsa-v1.0.bed.gz http://www.regulatoryrna.org/database/piRNA/download/archive/v1.0/bed/piR_hg19_v1.0.bed.gz zcat genome/hg38/source/piRBase-hsa-v1.0.bed.gz \\ | CrossMap.py bed genome/hg38/source/hg19ToHg38.over.chain.gz /dev/stdin genome/hg38/source/piRBase-hsa-v1.0.hg38.bed bedToGenePred genome/hg38/source/piRBase-hsa-v1.0.hg38.bed genome/hg38/source/piRBase-hsa-v1.0.hg38.genePred genePredToGtf -source=piRBase file genome/hg38/source/piRBase-hsa-v1.0.hg38.genePred genome/hg38/source/piRBase-hsa-v1.0.hg38.gtf ln genome/hg38/source/piRBase-hsa-v1.0.hg38.gtf genome/hg38/gtf/piRBase.gtf piRBase (v2.0) wget -O genome/hg38/source/piRBase-hsa-v2.0.bed.gz http://www.regulatoryrna.org/database/piRNA/download/archive/v2.0/bed/hsa.bed.gz zcat genome/hg38/source/piRBase-hsa-v2.0.bed.gz | bedtools sort > source/piRBase-hsa-v2.0.bed bedToGenePred source/piRBase-hsa-v2.0.bed source/piRBase-hsa-v2.0.genePred genePredToGtf -source=piRBase file source/piRBase-hsa-v2.0.genePred source/piRBase-hsa-v2.0.gtf Long RNA (GENCODE + Mitranscriptome - miRNA) # Merge GTF files cat genome/hg38/gtf/gencode.gtf \\ genome/hg38/gtf/mitranscriptome_lncRNA.gtf \\ genome/hg38/gtf/mitranscriptome_tucp.gtf \\ | grep -v 'gene_type \"miRNA' \\ > genome/hg38/gtf/long_RNA.gtf # Get gene lengths tools/GTFtools_0.6.5/gtftools.py -c 1-22,X,Y,M -l genome/hg38/gene_length/long_RNA genome/hg38/gtf/long_RNA.gtf # GTF to BED12 format gffread --bed -o genome/hg38/bed/long_RNA.bed genome/hg38/gtf/long_RNA.gtf gene_length/long_RNA Tab-deliminated text file First row: header Column 1 (gene): gene_id Column 2 (mean): mean length of isoforms Column 3 (median): median length of isoforms Column 4 (longest_isoform): length of the longest isoform Column 5 (merged): merged length of isoforms piRNABank (NCBI36) wget -O genome/hg38/source/ http://pirnabank.ibab.ac.in/downloads/all/human_all.zip unzip genome/hg38/source/human_all.zip -d genome/hg38/source/ mv genome/hg38/source/human_pir.txt genome/hg38/source/piRNABank.human.txt # Extract genomic coordinates from piRNABank awk 'BEGIN{OFS=\"\\t\"} /^>/{na=split(substr($0,2),a,\"|\");split(a[na],b,\":\"); if(b[5]==\"Plus\"){s=\"+\"} else{s=\"-\"} if(a[1]!=name){print \"chr\" b[2],b[3]-1,b[4],a[1],0,s} name=a[1]}' genome/hg38/source/piRNABank.human.txt \\ | bedtools sort > genome/hg38/source/piRNABank.human.bed awk 'BEGIN{OFS=\"\\t\"} {if($0 ~ /^>/) {split(substr($0,2),a,\"|\"); if((a[1] != name)&&(length(seq) > 0)){print \">\" name;gsub(/U/,\"T\",seq);print seq} name=a[1]} else{seq=$0}}' genome/hg38/source/piRNABank.human.txt > genome/hg38/source/piRNABank.human.fa bedToGenePred genome/hg38/source/piRNABank.human.bed genome/hg38/source/piRNABank.human.genePred genePredToGtf -source=piRNABank file genome/hg38/source/piRNABank.human.genePred stdout \\ | awk '$3==\"exon\"' > genome/hg38/source/piRNABank.human.gtf CrossMap.py gff genome/hg38/source/hg18ToHg38.over.chain.gz genome/hg38/source/piRNABank.human.gtf \\ genome/hg38/source/piRNABank.human.hg38.gtf cp genome/hg38/source/piRNABank.human.hg38.gtf genome/hg38/gtf/piRNABank.gtf cp genome/hg38/gtf/piRNABank.gtf genome/hg38/gtf_by_biotype/piRNA.gtf gffread --bed -o genome/hg38/source/piRNABank.human.hg38.bed genome/hg38/source/piRNABank.human.hg38.gtf bedtools getfasta -s -name -fi genome/hg38/fasta/genome.fa -bed genome/hg38/source/piRNABank.human.hg38.bed -split \\ > genome/hg38/source/piRNABank.human.hg38.fa miRBase (Version 22) wget -O genome/hg38/source/miRBase.hsa.gff3 ftp://mirbase.org/pub/mirbase/CURRENT/genomes/hsa.gff3 wget -O genome/hg38/source/miRBase.hairpin.fa.gz ftp://mirbase.org/pub/mirbase/CURRENT/hairpin.fa.gz wget -O genome/hg38/source/miRBase.mature.fa.gz ftp://mirbase.org/pub/mirbase/CURRENT/mature.fa.gz cp genome/hg38/source/miRBase.hsa.gff3 genome/hg38/gtf/miRBase.gff3 # extract human pre-miRNA zcat genome/hg38/source/miRBase.hairpin.fa.gz \\ | awk '/^>/{if($0 ~ />hsa-/) {keep=1; print $1} else{keep=0}; next}{if(keep==1){gsub(/U/, \"T\");print}}' \\ > genome/hg38/fasta/miRNA.fa samtools faidx genome/hg38/fasta/miRNA.fa # extract human mature miRNA zcat genome/hg38/source/miRBase.mature.fa.gz \\ | awk '/^>/{if($0 ~ />hsa-/) {keep=1; print $1} else{keep=0}; next}{if(keep==1){gsub(/U/, \"T\");print}}' \\ > genome/hg38/fasta/mature_miRNA.fa samtools faidx genome/hg38/fasta/mature_miRNA.fa # generate transcript table (mature miRNA) { echo -e 'chrom\\tstart\\tend\\tname\\tscore\\tstrand\\tgene_id\\ttranscript_id\\tgene_name\\ttranscript_name\\tgene_type\\ttranscript_type\\tsource' awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,0,$2,$1,0,\"+\",$1,$1,$1,$1,\"miRNA\",\"miRNA\",\"miRBase\"}' \\ genome/hg38/fasta/miRNA.fa.fai genome/hg38/fasta/mature_miRNA.fa.fai } > genome/hg38/transcript_table/miRNA.txt # get transcript sizes cut -f1,2 genome/hg38/fasta/miRNA.fa.fai genome/hg38/fasta/mature_miRNA.fa.fai > genome/hg38/chrom_sizes/miRNA # gff3 to genePred awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\";d[\"miRNA\"]=\"transcript\";d[\"miRNA_primary_transcript\"]=\"primary_transcript\"}/^#/{print}!/^#/{$3=d[$3];print $1,$2,$3,$4,$5,$6,$7,$8,$9}' \\ genome/hg38/gff3/miRBase.gff3 > genome/hg38/source/miRBase.fixed.gff3 gff3ToGenePred -useName genome/hg38/source/miRBase.fixed.gff3 genome/hg38/genePred/miRBase.genePred Intron bin/preprocess.py extract_gene -i genome/hg38/gtf/long_RNA.gtf | bedtools sort > genome/hg38/bed/long_RNA.gene.bed awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"} !/^#/{match($9,/gene_id \"([^\"]+)\"/,a);print $1,$4-1,$5,a[1],0,$7}' genome/hg38/gtf/long_RNA.gtf \\ | bedtools sort > genome/hg38/bed/long_RNA.exon.bed bedtools subtract -sorted -s -a genome/hg38/bed/long_RNA.gene.bed -b genome/hg38/bed/long_RNA.exon.bed \\ | bedtools sort > genome/hg38/bed/long_RNA.intron.bed Promoter/enhancer from ChromHMM (hg19) wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmGm12878HMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmH1hescHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHepg2HMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHmecHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHsmmHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHuvecHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmK562HMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmNhekHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmNhlfHMM.bed.gz # hg19 => hg38 tracks=\"wgEncodeBroadHmmGm12878HMM wgEncodeBroadHmmH1hescHMM wgEncodeBroadHmmHepg2HMM wgEncodeBroadHmmHmecHMM wgEncodeBroadHmmHsmmHMM wgEncodeBroadHmmHuvecHMM wgEncodeBroadHmmK562HMM wgEncodeBroadHmmNhekHMM wgEncodeBroadHmmNhlfHMM\" for track in $tracks;do CrossMap.py bed genome/hg38/source/hg18ToHg38.over.chain.gz <(zcat genome/hg38/source/${track}.bed.gz) genome/hg38/source/${track}.hg38.bed awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}($4==\"1_Active_Promoter\")||($4==\"2_Weak_Promoter\")||($4==\"3_Poised_Promoter\"){print $1,$2,$3,$4,$5,$6}' \\ genome/hg38/source/${track}.hg38.bed | bedtools sort > genome/hg38/bed/promoter.${track}.bed awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}($4==\"4_Strong_Enhancer\")||($4==\"5_Strong_Enhancer\")||($4==\"6_Weak_Enhancer\")||($4==\"7_Weak_Enhancer\"){print $1,$2,$3,$4,$5,$6}' \\ genome/hg38/source/${track}.hg38.bed | bedtools sort > genome/hg38/bed/enhancer.${track}.bed done # merge promoters and enhancers from 9 cell lines cat $(for track in $tracks;do echo genome/hg38/bed/promoter.${track}.bed;done) \\ | bedtools sort | bedtools merge -d 1 \\ | awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,$2,$3,\"promoter\",0,\".\"}' > genome/hg38/bed/promoter.merged.bed cat $(for track in $tracks;do echo genome/hg38/bed/enhancer.${track}.bed;done) \\ | bedtools sort | bedtools merge -d 1 \\ | awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,$2,$3,\"enhancer\",0,\".\"}' > genome/hg38/bed/enhancer.merged.bed Repeats UCSC GenomeBrowser -> Tools -> Table Browser assembly: GRCh38/hg38 group: repeats track: RepeatMasker table: rmsk Dowload to: genome/hg38/source/rmsk.bed.gz gunzip -c genome/hg38/source/rmsk.bed.gz | bedtools sort > genome/hg38/bed/rmsk.bed circRNA database (circBase) wget -O genome/hg38/source/circbase.hg19.fa.gz http://www.circbase.org/download/human_hg19_circRNAs_putative_spliced_sequence.fa.gz zcat genome/hg38/source/circbase.hg19.fa.gz | bin/preprocess.py extract_circrna_junction -s 150 -o genome/hg38/fasta/circRNA.fa samtools faidx genome/hg38/fasta/circRNA.fa STAR --runMode genomeGenerate --genomeSAindexNbases 10 --genomeChrBinNbits 7 --genomeDir genome/hg38/index/star/circRNA/ --genomeFastaFiles genome/hg38/fasta/circRNA.fa Merge transcript table { echo -e 'chrom\\tstart\\tend\\tname\\tscore\\tstrand\\tgene_id\\ttranscript_id\\tgene_name\\ttranscript_name\\tgene_type\\ttranscript_type\\tsource' for rna_type in rRNA lncRNA miRNA mRNA piRNA snoRNA snRNA srpRNA tRNA tucpRNA Y_RNA;do sed '1 d' genome/hg38/transcript_table/${rna_type}.txt done } > genome/hg38/transcript_table/all.txt","title":"Genome and Annotations"},{"location":"genome_and_annotations/#genome-and-annotations","text":"","title":"Genome and Annotations"},{"location":"genome_and_annotations/#annotation-summary-table","text":"Type Number of genes Source miRNA 1917 miRBase hairpin (Version 22) piRNA 23431 piRNABank lncRNA 15778 GENCODE V27 and mitranscriptome rRNA 37 NCBI refSeq 109 mRNA 19836 GENCODE V27 snoRNA 943 GENCODE V27 snRNA 1900 GENCODE V27 srpRNA 680 GENCODE V27 tRNA 649 GENCODE V27 tucpRNA 3734 GENCODE V27 Y_RNA 756 GENCODE V27 circRNA 140527 circBase repeats - UCSC Genome Browser (rmsk) promoter - ChromHMM tracks from 9 cell lines from UCSC Genome Browser enhancer - ChromHMM tracks from 9 cell lines from UCSC Genome Browser","title":"Annotation summary table"},{"location":"genome_and_annotations/#genome-and-annotation-files","text":"File Description fasta/genome.fa genome sequence fasta/circRNA.fa junction sequence in circBase fasta/rRNA.fa rRNA sequences in NCBI RefSeq fasta/miRNA.fa miRNA hairpin (precursor) sequences in miRBase fasta/piRNA.fa piRNA sequences in piRNABank fasta/${rna_type}.fa Longest isoform for each gene extracted from GENCODE annotations gtf_by_biotype/${rna_type}.gtf separate GTF files for each RNA type gtf/gencode.gtf GENCODE GTF file gtf/mitranscriptome.gtf Mitranscriptome GTF file gtf/long_RNA.gtf GTF file of Long RNA (GENCODE + Mitranscriptome - miRNA) gtf/piRNABank.gtf piRNA GTF file from piRNABank gtf/gencode_tRNA.gtf GTF file of tRNA from GENCODE transcript_table/all.txt Table of transcript information (gene_id, transcript_id) rsem_index/bowtie2/${rna_type} RSEM index files for each RNA type (built using the longest transcripts) rsem_index/bowtie2/${rna_type}.transcripts.fa Sequence for each RNA type (longest transcripts) gtf_longest_transcript/${rna_type}.gtf GTF files for the longest isoforms from GENCODE and Mitranscriptome bed/*.bed Transcript in BED12 format extracted from GTF files in `gtf/*.gtf index/bowtie2/${rna_type} STAR index for transcripts index/star/${rna_type} STAR index for transcripts long_index/star/ STAR index including splicing junctions of long RNA","title":"Genome and annotation files"},{"location":"genome_and_annotations/#generate-the-genome-and-annotation-files","text":"","title":"Generate the genome and annotation files"},{"location":"genome_and_annotations/#create-genome-directory","text":"[ -d \"genome/hg38/source\" ] || mkdir -p \"genome/hg38/source\"","title":"Create genome directory"},{"location":"genome_and_annotations/#chromosome-id-conversion-table","text":"Column 1: UCSC chromosome ID Column 2: RefSeq chromosome ID mysql --user=genome --host=genome-mysql.cse.ucsc.edu -A -N -e \"SELECT * FROM ucscToRefSeq;\" hg38 | cut -f1,4 > genome/hg38/source/ucscToRefSeq.txt","title":"Chromosome ID conversion table"},{"location":"genome_and_annotations/#download-gene-annotation-ncbi","text":"# NCBI Human Release 109 wget -P genome/hg38/source ftp://ftp.ncbi.nlm.nih.gov/genomes/H_sapiens/GFF/ref_GRCh38.p12_top_level.gff3.gz [ -d genome/hg38/gff3 ] || mkdir -p genome/hg38/gff3 awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"} NR==FNR{c[$2]=$1;next} !/^#/{chrom=c[$1]; if(length(chrom) > 0) print c[$1],$2,$3,$4,$5,$6,$7,$8,$9}' \\ genome/hg38/source/ucscToRefSeq.txt <(zcat genome/hg38/source/ref_GRCh38.p12_top_level.gff3.gz) \\ > genome/hg38/gff3/refseq.gff3 gffread --bed -o genome/hg38/bed/ncbi.bed genome/hg38/gff3/refseq.gff3 wget -O genome/hg38/source/refSeq_rna.fa.gz ftp://ftp.ncbi.nlm.nih.gov/genomes/H_sapiens/RNA/rna.fa.gz # get rRNA sequence IDs zgrep 'ribosomal RNA$' genome/hg38/source/refSeq_rna.fa.gz \\ | sed 's/>ref|\\(NR_[0-9.]\\+\\)|.*(\\([^)]\\+\\)).*/\\1|\\2/' > genome/hg38/source/refSeq_rRNA.ids.txt # get rRNA sequences zcat genome/hg38/source/refSeq_rna.fa.gz \\ | awk 'FNR==NR{split($0,a,\"|\");ids[a[1]]=1;next} {if($0 ~ /^>/){split($0,a,\"|\");if(ids[a[2]] == 1){keep=1; print \">\" a[2];}else{keep=0}} else{if(keep == 1){print}}}' \\ genome/hg38/source/refSeq_rRNA.ids.txt - > genome/hg38/fasta/rRNA.fa samtools faidx genome/hg38/fasta/rRNA.fa # generate transcript table { echo -e 'chrom\\tstart\\tend\\tname\\tscore\\tstrand\\tgene_id\\ttranscript_id\\tgene_name\\ttranscript_name\\tgene_type\\ttranscript_type\\tsource' awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}FNR==NR{split($0,a,\"|\");gene_name[a[1]]=a[2];next}{print $1,0,$2,a[1],0,\"+\",$1,$1,gene_name[$1],gene_name[$1],\"rRNA\",\"rRNA\",\"RefSeq\"}' \\ genome/hg38/source/refSeq_rRNA.ids.txt genome/hg38/fasta/rRNA.fa.fai } > genome/hg38/transcript_table/rRNA.txt # get transcript sizes cut -f1,2 genome/hg38/fasta/rRNA.fa.fai > genome/hg38/chrom_sizes/rRNA # build STAR index (small genome) STAR --runMode genomeGenerate --genomeSAindexNbases 5 --genomeDir genome/hg38/index/star/rRNA/ --genomeFastaFiles genome/hg38/fasta/rRNA.fa","title":"Download Gene annotation (NCBI)"},{"location":"genome_and_annotations/#download-chain-files-for-crossmap","text":"wget -O genome/hg38/source/hg18ToHg38.over.chain.gz http://hgdownload.soe.ucsc.edu/goldenPath/hg18/liftOver/hg18ToHg38.over.chain.gz wget -O genome/hg38/source/NCBI36_to_GRCh38.chain.gz https://sourceforge.net/projects/crossmap/files/Ensembl_chain_files/homo_sapiens%28human%29/NCBI36_to_GRCh38.chain.gz","title":"Download chain files for CrossMap"},{"location":"genome_and_annotations/#genome-assembly-ucsc-hg38","text":"wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz gzip -d -c genome/hg38/source/hg38.fa.gz > genome/hg38/fasta/genome.fa samtools faidx genome/hg38/fasta/genome.fa","title":"Genome assembly (UCSC hg38)"},{"location":"genome_and_annotations/#encode-annotations","text":"wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.annotation.gtf.gz #wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.annotation.gff3.gz wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.long_noncoding_RNAs.gtf.gz #wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.long_noncoding_RNAs.gff3.gz wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.tRNAs.gtf.gz #wget -P genome/hg38/source ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.tRNAs.gff3.gz zcat genome/hg38/source/gencode.v27.annotation.gtf.gz > genome/hg38/gtf/gencode.gtf zcat genome/hg38/source/gencode.v27.long_noncoding_RNAs.gtf.gz > genome/hg38/gtf/gencode_lncRNA.gtf zcat genome/hg38/source/gencode.v27.tRNAs.gtf.gz \\ | awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"}{print $1,$2,\"exon\",$4,$5,$6,$7,$8,$9}' > genome/hg38/gtf/gencode_tRNA.gtf # Chain file for converting hg19 to hg38 wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz","title":"ENCODE annotations"},{"location":"genome_and_annotations/#mitranscriptome","text":"wget -P genome/hg38/source http://mitranscriptome.org/download/mitranscriptome.gtf.tar.gz tar -C genome/hg38/source --strip-components=1 -zxf genome/hg38/source/mitranscriptome.gtf.tar.gz mitranscriptome.gtf/mitranscriptome.v2.gtf.gz # convert from hg19 to hg38 zcat genome/hg38/source/mitranscriptome.v2.gtf.gz \\ | CrossMap.py gff genome/hg38/source/hg19ToHg38.over.chain.gz /dev/stdin genome/hg38/source/mitranscriptome.v2.hg38.gtf # remove invalid transcripts bin/preprocess.py fix_gtf -i genome/hg38/source/mitranscriptome.v2.hg38.gtf -o genome/hg38/gtf/mitranscriptome.gtf Extract lncRNA and TUCP RNA to separate GTF files: grep 'tcat \"lncrna\"' genome/hg38/gtf/mitranscriptome.gtf > genome/hg38/gtf/mitranscriptome_lncRNA.gtf # add exon feature grep 'tcat \"tucp\"' genome/hg38/gtf/mitranscriptome.gtf \\ | awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print;print $1,$2,\"exon\",$4,$5,$6,$7,$8,$9}' > genome/hg38/gtf/mitranscriptome_tucp.gtf cp genome/hg38/gtf/mitranscriptome_tucp.gtf genome/hg38/gtf_by_biotype/tucpRNA.gtf","title":"Mitranscriptome"},{"location":"genome_and_annotations/#noncode","text":"wget -P genome/hg38/source http://www.noncode.org/datadownload/NONCODEv5_human_hg38_lncRNA.gtf.gz zcat genome/hg38/source/NONCODEv5_human_hg38_lncRNA.gtf.gz \\ | awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"}$7 != \".\" {print $1,\"NONCODE\",$3,$4,$5,$6,$7,$8,$9}' > genome/hg38/gtf/noncode.gtf","title":"NONCODE"},{"location":"genome_and_annotations/#lncrnas-identified-in-hcc-nature-communications-2017","text":"wget -P genome/hg38/source https://media.nature.com/original/nature-assets/ncomms/2017/170213/ncomms14421/extref/ncomms14421-s3.txt awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"}{print $1,\"ncomms2017\",$3,$4,$5,$6,$7,$8,$9}' genome/hg38/source/ncomms14421-s3.txt > genome/hg38/source/ncomms2017.gtf CrossMap.py gff genome/hg38/source/hg19ToHg38.over.chain.gz genome/hg38/source/ncomms2017.gtf genome/hg38/source/ncomms2017.hg38.gtf ln genome/hg38/source/ncomms2017.hg38.gtf genome/hg38/gtf/ncomms2017.gtf","title":"lncRNAs identified in HCC (Nature communications 2017)"},{"location":"genome_and_annotations/#merge-lncrna-gencode-and-mitranscriptome","text":"cat genome/hg38/gtf/gencode_lncRNA.gtf \\ genome/hg38/gtf/mitranscriptome_lncRNA.gtf \\ > genome/hg38/gtf/merged_lncRNA.gtf cp genome/hg38/gtf/merged_lncRNA.gtf genome/hg38/gtf_by_biotype/lncRNA.gtf","title":"Merge lncRNA (GENCODE and Mitranscriptome)"},{"location":"genome_and_annotations/#pirbase-v10","text":"wget -O genome/hg38/source/piRBase-hsa-v1.0.bed.gz http://www.regulatoryrna.org/database/piRNA/download/archive/v1.0/bed/piR_hg19_v1.0.bed.gz zcat genome/hg38/source/piRBase-hsa-v1.0.bed.gz \\ | CrossMap.py bed genome/hg38/source/hg19ToHg38.over.chain.gz /dev/stdin genome/hg38/source/piRBase-hsa-v1.0.hg38.bed bedToGenePred genome/hg38/source/piRBase-hsa-v1.0.hg38.bed genome/hg38/source/piRBase-hsa-v1.0.hg38.genePred genePredToGtf -source=piRBase file genome/hg38/source/piRBase-hsa-v1.0.hg38.genePred genome/hg38/source/piRBase-hsa-v1.0.hg38.gtf ln genome/hg38/source/piRBase-hsa-v1.0.hg38.gtf genome/hg38/gtf/piRBase.gtf","title":"piRBase (v1.0)"},{"location":"genome_and_annotations/#pirbase-v20","text":"wget -O genome/hg38/source/piRBase-hsa-v2.0.bed.gz http://www.regulatoryrna.org/database/piRNA/download/archive/v2.0/bed/hsa.bed.gz zcat genome/hg38/source/piRBase-hsa-v2.0.bed.gz | bedtools sort > source/piRBase-hsa-v2.0.bed bedToGenePred source/piRBase-hsa-v2.0.bed source/piRBase-hsa-v2.0.genePred genePredToGtf -source=piRBase file source/piRBase-hsa-v2.0.genePred source/piRBase-hsa-v2.0.gtf","title":"piRBase (v2.0)"},{"location":"genome_and_annotations/#long-rna-gencode-mitranscriptome-mirna","text":"# Merge GTF files cat genome/hg38/gtf/gencode.gtf \\ genome/hg38/gtf/mitranscriptome_lncRNA.gtf \\ genome/hg38/gtf/mitranscriptome_tucp.gtf \\ | grep -v 'gene_type \"miRNA' \\ > genome/hg38/gtf/long_RNA.gtf # Get gene lengths tools/GTFtools_0.6.5/gtftools.py -c 1-22,X,Y,M -l genome/hg38/gene_length/long_RNA genome/hg38/gtf/long_RNA.gtf # GTF to BED12 format gffread --bed -o genome/hg38/bed/long_RNA.bed genome/hg38/gtf/long_RNA.gtf gene_length/long_RNA Tab-deliminated text file First row: header Column 1 (gene): gene_id Column 2 (mean): mean length of isoforms Column 3 (median): median length of isoforms Column 4 (longest_isoform): length of the longest isoform Column 5 (merged): merged length of isoforms","title":"Long RNA (GENCODE + Mitranscriptome - miRNA)"},{"location":"genome_and_annotations/#pirnabank-ncbi36","text":"wget -O genome/hg38/source/ http://pirnabank.ibab.ac.in/downloads/all/human_all.zip unzip genome/hg38/source/human_all.zip -d genome/hg38/source/ mv genome/hg38/source/human_pir.txt genome/hg38/source/piRNABank.human.txt # Extract genomic coordinates from piRNABank awk 'BEGIN{OFS=\"\\t\"} /^>/{na=split(substr($0,2),a,\"|\");split(a[na],b,\":\"); if(b[5]==\"Plus\"){s=\"+\"} else{s=\"-\"} if(a[1]!=name){print \"chr\" b[2],b[3]-1,b[4],a[1],0,s} name=a[1]}' genome/hg38/source/piRNABank.human.txt \\ | bedtools sort > genome/hg38/source/piRNABank.human.bed awk 'BEGIN{OFS=\"\\t\"} {if($0 ~ /^>/) {split(substr($0,2),a,\"|\"); if((a[1] != name)&&(length(seq) > 0)){print \">\" name;gsub(/U/,\"T\",seq);print seq} name=a[1]} else{seq=$0}}' genome/hg38/source/piRNABank.human.txt > genome/hg38/source/piRNABank.human.fa bedToGenePred genome/hg38/source/piRNABank.human.bed genome/hg38/source/piRNABank.human.genePred genePredToGtf -source=piRNABank file genome/hg38/source/piRNABank.human.genePred stdout \\ | awk '$3==\"exon\"' > genome/hg38/source/piRNABank.human.gtf CrossMap.py gff genome/hg38/source/hg18ToHg38.over.chain.gz genome/hg38/source/piRNABank.human.gtf \\ genome/hg38/source/piRNABank.human.hg38.gtf cp genome/hg38/source/piRNABank.human.hg38.gtf genome/hg38/gtf/piRNABank.gtf cp genome/hg38/gtf/piRNABank.gtf genome/hg38/gtf_by_biotype/piRNA.gtf gffread --bed -o genome/hg38/source/piRNABank.human.hg38.bed genome/hg38/source/piRNABank.human.hg38.gtf bedtools getfasta -s -name -fi genome/hg38/fasta/genome.fa -bed genome/hg38/source/piRNABank.human.hg38.bed -split \\ > genome/hg38/source/piRNABank.human.hg38.fa","title":"piRNABank (NCBI36)"},{"location":"genome_and_annotations/#mirbase-version-22","text":"wget -O genome/hg38/source/miRBase.hsa.gff3 ftp://mirbase.org/pub/mirbase/CURRENT/genomes/hsa.gff3 wget -O genome/hg38/source/miRBase.hairpin.fa.gz ftp://mirbase.org/pub/mirbase/CURRENT/hairpin.fa.gz wget -O genome/hg38/source/miRBase.mature.fa.gz ftp://mirbase.org/pub/mirbase/CURRENT/mature.fa.gz cp genome/hg38/source/miRBase.hsa.gff3 genome/hg38/gtf/miRBase.gff3 # extract human pre-miRNA zcat genome/hg38/source/miRBase.hairpin.fa.gz \\ | awk '/^>/{if($0 ~ />hsa-/) {keep=1; print $1} else{keep=0}; next}{if(keep==1){gsub(/U/, \"T\");print}}' \\ > genome/hg38/fasta/miRNA.fa samtools faidx genome/hg38/fasta/miRNA.fa # extract human mature miRNA zcat genome/hg38/source/miRBase.mature.fa.gz \\ | awk '/^>/{if($0 ~ />hsa-/) {keep=1; print $1} else{keep=0}; next}{if(keep==1){gsub(/U/, \"T\");print}}' \\ > genome/hg38/fasta/mature_miRNA.fa samtools faidx genome/hg38/fasta/mature_miRNA.fa # generate transcript table (mature miRNA) { echo -e 'chrom\\tstart\\tend\\tname\\tscore\\tstrand\\tgene_id\\ttranscript_id\\tgene_name\\ttranscript_name\\tgene_type\\ttranscript_type\\tsource' awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,0,$2,$1,0,\"+\",$1,$1,$1,$1,\"miRNA\",\"miRNA\",\"miRBase\"}' \\ genome/hg38/fasta/miRNA.fa.fai genome/hg38/fasta/mature_miRNA.fa.fai } > genome/hg38/transcript_table/miRNA.txt # get transcript sizes cut -f1,2 genome/hg38/fasta/miRNA.fa.fai genome/hg38/fasta/mature_miRNA.fa.fai > genome/hg38/chrom_sizes/miRNA # gff3 to genePred awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\";d[\"miRNA\"]=\"transcript\";d[\"miRNA_primary_transcript\"]=\"primary_transcript\"}/^#/{print}!/^#/{$3=d[$3];print $1,$2,$3,$4,$5,$6,$7,$8,$9}' \\ genome/hg38/gff3/miRBase.gff3 > genome/hg38/source/miRBase.fixed.gff3 gff3ToGenePred -useName genome/hg38/source/miRBase.fixed.gff3 genome/hg38/genePred/miRBase.genePred","title":"miRBase (Version 22)"},{"location":"genome_and_annotations/#intron","text":"bin/preprocess.py extract_gene -i genome/hg38/gtf/long_RNA.gtf | bedtools sort > genome/hg38/bed/long_RNA.gene.bed awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"} !/^#/{match($9,/gene_id \"([^\"]+)\"/,a);print $1,$4-1,$5,a[1],0,$7}' genome/hg38/gtf/long_RNA.gtf \\ | bedtools sort > genome/hg38/bed/long_RNA.exon.bed bedtools subtract -sorted -s -a genome/hg38/bed/long_RNA.gene.bed -b genome/hg38/bed/long_RNA.exon.bed \\ | bedtools sort > genome/hg38/bed/long_RNA.intron.bed","title":"Intron"},{"location":"genome_and_annotations/#promoterenhancer-from-chromhmm-hg19","text":"wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmGm12878HMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmH1hescHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHepg2HMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHmecHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHsmmHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmHuvecHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmK562HMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmNhekHMM.bed.gz wget -P genome/hg38/source http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHmm/wgEncodeBroadHmmNhlfHMM.bed.gz # hg19 => hg38 tracks=\"wgEncodeBroadHmmGm12878HMM wgEncodeBroadHmmH1hescHMM wgEncodeBroadHmmHepg2HMM wgEncodeBroadHmmHmecHMM wgEncodeBroadHmmHsmmHMM wgEncodeBroadHmmHuvecHMM wgEncodeBroadHmmK562HMM wgEncodeBroadHmmNhekHMM wgEncodeBroadHmmNhlfHMM\" for track in $tracks;do CrossMap.py bed genome/hg38/source/hg18ToHg38.over.chain.gz <(zcat genome/hg38/source/${track}.bed.gz) genome/hg38/source/${track}.hg38.bed awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}($4==\"1_Active_Promoter\")||($4==\"2_Weak_Promoter\")||($4==\"3_Poised_Promoter\"){print $1,$2,$3,$4,$5,$6}' \\ genome/hg38/source/${track}.hg38.bed | bedtools sort > genome/hg38/bed/promoter.${track}.bed awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}($4==\"4_Strong_Enhancer\")||($4==\"5_Strong_Enhancer\")||($4==\"6_Weak_Enhancer\")||($4==\"7_Weak_Enhancer\"){print $1,$2,$3,$4,$5,$6}' \\ genome/hg38/source/${track}.hg38.bed | bedtools sort > genome/hg38/bed/enhancer.${track}.bed done # merge promoters and enhancers from 9 cell lines cat $(for track in $tracks;do echo genome/hg38/bed/promoter.${track}.bed;done) \\ | bedtools sort | bedtools merge -d 1 \\ | awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,$2,$3,\"promoter\",0,\".\"}' > genome/hg38/bed/promoter.merged.bed cat $(for track in $tracks;do echo genome/hg38/bed/enhancer.${track}.bed;done) \\ | bedtools sort | bedtools merge -d 1 \\ | awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,$2,$3,\"enhancer\",0,\".\"}' > genome/hg38/bed/enhancer.merged.bed","title":"Promoter/enhancer from ChromHMM (hg19)"},{"location":"genome_and_annotations/#repeats","text":"UCSC GenomeBrowser -> Tools -> Table Browser assembly: GRCh38/hg38 group: repeats track: RepeatMasker table: rmsk Dowload to: genome/hg38/source/rmsk.bed.gz gunzip -c genome/hg38/source/rmsk.bed.gz | bedtools sort > genome/hg38/bed/rmsk.bed","title":"Repeats"},{"location":"genome_and_annotations/#circrna-database-circbase","text":"wget -O genome/hg38/source/circbase.hg19.fa.gz http://www.circbase.org/download/human_hg19_circRNAs_putative_spliced_sequence.fa.gz zcat genome/hg38/source/circbase.hg19.fa.gz | bin/preprocess.py extract_circrna_junction -s 150 -o genome/hg38/fasta/circRNA.fa samtools faidx genome/hg38/fasta/circRNA.fa STAR --runMode genomeGenerate --genomeSAindexNbases 10 --genomeChrBinNbits 7 --genomeDir genome/hg38/index/star/circRNA/ --genomeFastaFiles genome/hg38/fasta/circRNA.fa","title":"circRNA database (circBase)"},{"location":"genome_and_annotations/#merge-transcript-table","text":"{ echo -e 'chrom\\tstart\\tend\\tname\\tscore\\tstrand\\tgene_id\\ttranscript_id\\tgene_name\\ttranscript_name\\tgene_type\\ttranscript_type\\tsource' for rna_type in rRNA lncRNA miRNA mRNA piRNA snoRNA snRNA srpRNA tRNA tucpRNA Y_RNA;do sed '1 d' genome/hg38/transcript_table/${rna_type}.txt done } > genome/hg38/transcript_table/all.txt","title":"Merge transcript table"},{"location":"get_started/","text":"exSeek Workflow Installation Install required software packages according to requirements Download the scripts: git clone https://github.com/lulab/exSeek-dev.git Input files Genome and annotation directory Download preprocessed genome annotations to genome/hg38 Refer to the documentation for details. Input data files File name Description ${input_dir}/fastq/${sample_id}.fastq Read files (single-end sequencing) ${input_dir}/fastq/${sample_id}_1.fastq , ${input_dir}/fastq/${sample_id}_2.fastq Read files (paired-end sequencing) ${input_dir}/sample_ids.txt A text file with one sample ID per line. ${input_dir}/sample_classes.txt A tab-deliminated file (with header) with two columns: sample_id, label (optional) ${input_dir}/batch_info.txt A comma-deliminated file (with header) with at least two columns: sample_id, batch1, batch2, ... (optional) ${input_dir}/compare_groups.yaml A YAML file defining positive and negative classes. (optional) ${config_dir}/${dataset}.yaml A YAML file for configuration parameters for the dataset compare_groups.yaml Every key-value pairs defines a compare group and a negative-positive class pair: Normal-CRC: [\"Healthy Control\", \"Colorectal Cancer\"] Dataset configuration file All parameters are specified in a configuration file in YAML format. The default configuration file is (snakemake/default_config.yaml). Example configuration files can be found in config/ . The parameter values in the configuration file can also be overrided through the --config option in snakemake . The following parameters should be changed: Parameter Description Example genome_dir Directory for genome and annotation files genome/hg38 data_dir Directory for input files data/dataset temp_dir Temporary directory tmp output_dir Directory for all output files output/dataset aligner Mapping software bowtie2 adaptor 3' adaptor sequence for single-end RNA-seq AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC Cluster configuration file Please refer the link for descriptions of cluster configuration file. Basic usage of exSeek Run exseek.py --help to get basic usage: usage: exseek.py [-h] --dataset DATASET [--config-dir CONFIG_DIR] [--cluster] [--cluster-config CLUSTER_CONFIG] [--cluster-command CLUSTER_COMMAND] [--singularity SINGULARITY] [--singularity-wrapper-dir SINGULARITY_WRAPPER_DIR] {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} exSeek main program positional arguments: {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} optional arguments: -h, --help show this help message and exit --dataset DATASET, -d DATASET dataset name --config-dir CONFIG_DIR, -c CONFIG_DIR directory for configuration files --cluster submit to cluster --cluster-config CLUSTER_CONFIG cluster configuration file ({config_dir}/cluster.yaml by default) --cluster-command CLUSTER_COMMAND command for submitting job to cluster (default read from {config_dir}/cluster_command.txt --singularity SINGULARITY singularity image file --singularity-wrapper-dir SINGULARITY_WRAPPER_DIR directory for singularity wrappers Note Other arguments are passed to snakemake Specify number of processes to run in parallel with -j Small RNA-seq analysis Configuration file An example configuration file for small RNA single-end sequencing can be found in config/small_se_example.yaml . Quality control, adaptor removal and trimming ${exseek_path}/bin/exseek.py quality_control --dataset ${dataset} Mapping exseek.py mapping --dataset ${dataset} Note If you changed mapping order in the rna_types config variable, you should update the snakefile with the command: exseek.py update_sequential_mapping --dataset ${dataset} Description of output files: output_files Generate count matrix ${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset} Count matrix File path: ${output_dir}/count_matrix/transcript.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name Call domains ${exseek_path}/bin/exseek.py call_domains --dataset ${dataset} Read count matrix File path: ${output_dir}/count_matrix/domain_long.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name|domain_id|transcript_id|start|end Combine read counts of miRNA/piRNA and domains ${exseek_path}/bin/exseek.py combine_domains --dataset ${dataset} Normalization ${exseek_path}/bin/exseek.py normalization --dataset ${dataset} Feature selection ${exseek_path}/bin/exseek.py feature_selection --dataset ${dataset} Differential expression ${exseek_path}/bin/exseek.py differential_expression --dataset ${dataset} Long RNA-seq analysis Configuration file An example configuration file for long RNA paired-end sequencing can be found in config/long_pe_example.yaml . Quality control and adaptor removal ${exseek_path}/bin/exseek.py quality_control --dataset ${dataset} Mapping ${exseek_path}/bin/exseek.py mapping --dataset ${dataset} Generate count matrix ${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset} Frequently asked Questions FAQs","title":"Get Started"},{"location":"get_started/#exseek","text":"","title":"exSeek"},{"location":"get_started/#workflow","text":"","title":"Workflow"},{"location":"get_started/#installation","text":"Install required software packages according to requirements Download the scripts: git clone https://github.com/lulab/exSeek-dev.git","title":"Installation"},{"location":"get_started/#input-files","text":"","title":"Input files"},{"location":"get_started/#genome-and-annotation-directory","text":"Download preprocessed genome annotations to genome/hg38 Refer to the documentation for details.","title":"Genome and annotation directory"},{"location":"get_started/#input-data-files","text":"File name Description ${input_dir}/fastq/${sample_id}.fastq Read files (single-end sequencing) ${input_dir}/fastq/${sample_id}_1.fastq , ${input_dir}/fastq/${sample_id}_2.fastq Read files (paired-end sequencing) ${input_dir}/sample_ids.txt A text file with one sample ID per line. ${input_dir}/sample_classes.txt A tab-deliminated file (with header) with two columns: sample_id, label (optional) ${input_dir}/batch_info.txt A comma-deliminated file (with header) with at least two columns: sample_id, batch1, batch2, ... (optional) ${input_dir}/compare_groups.yaml A YAML file defining positive and negative classes. (optional) ${config_dir}/${dataset}.yaml A YAML file for configuration parameters for the dataset compare_groups.yaml Every key-value pairs defines a compare group and a negative-positive class pair: Normal-CRC: [\"Healthy Control\", \"Colorectal Cancer\"]","title":"Input data files"},{"location":"get_started/#dataset-configuration-file","text":"All parameters are specified in a configuration file in YAML format. The default configuration file is (snakemake/default_config.yaml). Example configuration files can be found in config/ . The parameter values in the configuration file can also be overrided through the --config option in snakemake . The following parameters should be changed: Parameter Description Example genome_dir Directory for genome and annotation files genome/hg38 data_dir Directory for input files data/dataset temp_dir Temporary directory tmp output_dir Directory for all output files output/dataset aligner Mapping software bowtie2 adaptor 3' adaptor sequence for single-end RNA-seq AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC","title":"Dataset configuration file"},{"location":"get_started/#cluster-configuration-file","text":"Please refer the link for descriptions of cluster configuration file.","title":"Cluster configuration file"},{"location":"get_started/#basic-usage-of-exseek","text":"Run exseek.py --help to get basic usage: usage: exseek.py [-h] --dataset DATASET [--config-dir CONFIG_DIR] [--cluster] [--cluster-config CLUSTER_CONFIG] [--cluster-command CLUSTER_COMMAND] [--singularity SINGULARITY] [--singularity-wrapper-dir SINGULARITY_WRAPPER_DIR] {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} exSeek main program positional arguments: {quality_control,prepare_genome,mapping,count_matrix,call_domains,normalization,feature_selection,update_sequential_mapping,update_singularity_wrappers} optional arguments: -h, --help show this help message and exit --dataset DATASET, -d DATASET dataset name --config-dir CONFIG_DIR, -c CONFIG_DIR directory for configuration files --cluster submit to cluster --cluster-config CLUSTER_CONFIG cluster configuration file ({config_dir}/cluster.yaml by default) --cluster-command CLUSTER_COMMAND command for submitting job to cluster (default read from {config_dir}/cluster_command.txt --singularity SINGULARITY singularity image file --singularity-wrapper-dir SINGULARITY_WRAPPER_DIR directory for singularity wrappers Note Other arguments are passed to snakemake Specify number of processes to run in parallel with -j","title":"Basic usage of exSeek"},{"location":"get_started/#small-rna-seq-analysis","text":"","title":"Small RNA-seq analysis"},{"location":"get_started/#configuration-file","text":"An example configuration file for small RNA single-end sequencing can be found in config/small_se_example.yaml .","title":"Configuration file"},{"location":"get_started/#quality-control-adaptor-removal-and-trimming","text":"${exseek_path}/bin/exseek.py quality_control --dataset ${dataset}","title":"Quality control, adaptor removal and trimming"},{"location":"get_started/#mapping","text":"exseek.py mapping --dataset ${dataset} Note If you changed mapping order in the rna_types config variable, you should update the snakefile with the command: exseek.py update_sequential_mapping --dataset ${dataset} Description of output files: output_files","title":"Mapping"},{"location":"get_started/#generate-count-matrix","text":"${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset} Count matrix File path: ${output_dir}/count_matrix/transcript.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name","title":"Generate count matrix"},{"location":"get_started/#call-domains","text":"${exseek_path}/bin/exseek.py call_domains --dataset ${dataset} Read count matrix File path: ${output_dir}/count_matrix/domain_long.txt First row: sample IDs First column: feature names Feature name: gene_id|gene_type|gene_name|domain_id|transcript_id|start|end","title":"Call domains"},{"location":"get_started/#combine-read-counts-of-mirnapirna-and-domains","text":"${exseek_path}/bin/exseek.py combine_domains --dataset ${dataset}","title":"Combine read counts of miRNA/piRNA and domains"},{"location":"get_started/#normalization","text":"${exseek_path}/bin/exseek.py normalization --dataset ${dataset}","title":"Normalization"},{"location":"get_started/#feature-selection","text":"${exseek_path}/bin/exseek.py feature_selection --dataset ${dataset}","title":"Feature selection"},{"location":"get_started/#differential-expression","text":"${exseek_path}/bin/exseek.py differential_expression --dataset ${dataset}","title":"Differential expression"},{"location":"get_started/#long-rna-seq-analysis","text":"","title":"Long RNA-seq analysis"},{"location":"get_started/#configuration-file_1","text":"An example configuration file for long RNA paired-end sequencing can be found in config/long_pe_example.yaml .","title":"Configuration file"},{"location":"get_started/#quality-control-and-adaptor-removal","text":"${exseek_path}/bin/exseek.py quality_control --dataset ${dataset}","title":"Quality control and adaptor removal"},{"location":"get_started/#mapping_1","text":"${exseek_path}/bin/exseek.py mapping --dataset ${dataset}","title":"Mapping"},{"location":"get_started/#generate-count-matrix_1","text":"${exseek_path}/bin/exseek.py count_matrix --dataset ${dataset}","title":"Generate count matrix"},{"location":"get_started/#frequently-asked-questions","text":"FAQs","title":"Frequently asked Questions"},{"location":"igv_browser/","text":"IGV Genome Browser Templates for d in img js css;do [ -d \"templates/igv/$d\" ] || mkdir -p \"templates/igv/$d\" done wget -O templates/igv/img/favicon.ico 'https://igv.org/web/img/favicon.ico' wget -O templates/igv/js/igv.min.js 'https://igv.org/web/release/2.1.0/dist/igv.min.js' wget -O templates/igv/css/bootstrap.min.css 'https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css' wget -O templates/igv/js/bootstrap.min.js 'https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js' wget -O templates/igv/js/jquery-3.2.1.slim.min.js 'https://code.jquery.com/jquery-3.2.1.slim.min.js' wget -O templates/igv/js/popper.min.js 'https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js' Genome reference from IGV wget -O genome/hg38/source/igv.hg38.genome http://s3.amazonaws.com/igv.broadinstitute.org/genomes/hg38.genome unzip genome/hg38/source/igv.hg38.genome -d genome/hg38/igv Generate IGV html IGV Browser reference igv.browser addMultiLocusPanelWithGenomicStateAtIndex: \u0192 (genomicState,index,viewportWidth) addTrack: \u0192 (track) buildViewportsWithGenomicStateList: \u0192 (genomicStateList) cancelTrackPan: \u0192 () compressedSession: \u0192 () dispose: \u0192 () emptyViewportContainers: \u0192 () endTrackDrag: \u0192 () findTracks: \u0192 (property,value) fireEvent: \u0192 (eventName,args,thisObj) getChromosomeLengthBP: \u0192 (genome,referenceFrame) goto: \u0192 (chrName,start,end) hideCenterGuide: \u0192 () hideCursorGuide: \u0192 () hideTrackLabels: \u0192 () isMultiLocusMode: \u0192 () isMultiLocusWholeGenomeView: \u0192 () loadGenome: \u0192 (idOrConfig,initialLocus) loadInProgress: \u0192 () loadSampleInformation: \u0192 (url) loadSession: \u0192 (sessionURL,config) loadTrack: \u0192 (config) loadTrackList: \u0192 (configList) minimumBases: \u0192 () mouseDownOnViewport: \u0192 (e,viewport) on: \u0192 (eventName,fn) presentAlert: \u0192 (alert,$parent,callback) presentMessageWithCallback: \u0192 (message,callback) presentSplitScreenMultiLocusPanel: \u0192 (alignment,genomicState) removeAllTracks: \u0192 (removeSequence) removeMultiLocusPanelWithGenomicState: \u0192 (genomicState,doResize) removeTrack: \u0192 (track) removeTrackByName: \u0192 (name) renderSVG: \u0192 (config) reorderTracks: \u0192 () resize: \u0192 () search: \u0192 (string,init) selectMultiLocusPanelWithGenomicState: \u0192 (selectedGenomicState) sessionURL: \u0192 () setTrackHeight: \u0192 (newHeight) setTrackLabelName: \u0192 (trackView,name) showCenterGuide: \u0192 () showCursorGuide: \u0192 () showTrackLabels: \u0192 () startTrackDrag: \u0192 (trackView) toJSON: \u0192 () un: \u0192 (eventName,fn) updateLocusSearchWidget: \u0192 (genomicState) updateTrackDrag: \u0192 (dragDestination) updateUIWithGenomicStateListChange: \u0192 (genomicStateList) updateViews: \u0192 (genomicState,views) updateZoomSlider: \u0192 ($slider) viewportContainerWidth: \u0192 () viewportWidth: \u0192 () visibilityChange: \u0192 () zoom: \u0192 (scaleFactor) zoomIn: \u0192 () zoomOut: \u0192 () zoomWithRangePercentage: \u0192 (percentage) zoomWithScaleFactor: \u0192 (centerBPOrUndefined,viewportOrUndefined,scaleFactor) File extensions narrowpeak broadpeak peaks bedgraph wig gff3 gff gtf fusionjuncspan refflat seg aed bed vcf bb bigbed bw bigwig bam tdf refgene genepred genepredext bedpe bp snp rmsk Track configuration reference track1: type: wig format: bigwig height: 200 min: 0 max: 100 color: 'rgb(0,0,0)' autoScale: true, logScale: false long_RNA: url: genome/hg38/genePred/long_RNA.genePred type: annotation format: genepred height: 200 { echo 'reference: id: hg38 fastaURL: genome/hg38/fasta/genome.fa indexURL: genome/hg38/fasta/genome.fa.fai cytobandURL: genome/hg38/igv/cytoBandIdeo.txt Refseq Genes: type: annotation format: refGene url: genome/hg38/igv/refGene.txt visibilityWindow: 300000000 height: 80 GENCODE_V27: type: annotation format: bed url: genome/hg38/igv/gencode.bed indexURL: genome/hg38/igv/gencode.bed.idx displayMode: \"EXPANDED\" searchable: true visibilityWindow: 300000000 height: 200' for sample_id in $(head -n 50 data/scirep/sample_ids.txt);do printf \"${sample_id}(+): url: scirep/${sample_id}.transcriptome.+.bigWig type: wig format: bigwig height: 25 ${sample_id}(-): url: scirep/${sample_id}.transcriptome.-.bigWig type: wig format: bigwig height: 25 \" done } > genome_browser/config/scirep.yaml bin/create_igv.py -i templates/igv/main.html -g hg38 \\ --tracklist genome_browser/config/scirep.yaml \\ --base-url http://166.111.156.12:10080/genomebrowse \\ -o genome_browser/igv/scirep.html sync-bigwig bin/create_igv.py -i templates/igv/main.html -g hg38 --genome-dir genome/hg38/ \\ --track genome/hg38/bed/long_RNA.intron.bed \\ --track genome/hg38/bed/rmsk.bed \\ --track genome/hg38/bed/promoter.merged.bed \\ --track genome/hg38/bed/enhancer.merged.bed \\ --track output/scirep/bigwig/Sample_1S1.genome.+.bigWig \\ --track output/scirep/bigwig/Sample_1S1.genome.-.bigWig \\ -o igv.html bin/create_igv.py -i templates/igv/main.html -g hg38 --genome-dir genome/hg38/ \\ --tracklist tmp/tracklist.yaml \\ -o igv.html --track output/scirep/bigwig/Sample_1S1.genome.+.bigWig -o igv.html Reference tracks gtfToGenePred -geneNameAsName2 -genePredExt genome/hg38/gtf/gencode.gtf genome/hg38/genePred/gencode.genePredExt gffread -E --bed genome/hg38/gtf/gencode.gtf -o /dev/stdout | bedtools sort > genome/hg38/igv/gencode.bed ./tools/IGVTools/igvtools index genome/hg38/igv/gencode.bed Domains gffread --bed -o genome/hg38/bed/long_RNA.bed genome/hg38/gtf/long_RNA.gtf gffread --bed -o genome/hg38/bed/gencode_tRNA.bed genome/hg38/gtf/gencode_tRNA.gtf [ -d \"output/scirep/gdomains/20/05.bed\" ] || mkdir -p output/scirep/gdomains/20 { bin/tbed2gbed <(cat genome/hg38/bed/long_RNA.bed genome/hg38/bed/gencode_tRNA.bed) <(grep -v '^chr' output/scirep/domains/20/05.bed) /dev/stdout awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}/^chr/{print $0,0,0,0,1,$3-$2,0}' output/scirep/domains/20/05.bed } | bedtools sort > output/scirep/gdomains/20/05.bed Custom reference genome IGV genome repository: (https://s3.amazonaws.com/igv.org.genomes/genomes.json) Cytoband schema: UCSC genome=\"rRNA\" fastaURL=\"genome/hg38/fasta/${genome}.fa\" fastaIndexURL=\"genome/hg38/fasta/${genome}.fa.fai\" cytobandURL=\"genome/hg38/cytoband/${genome}.txt\" refURL=\"genome/hg38/genePred/${genome}.genePred\" # convert NR_ ids to rRNA names # gene_id|gene_name rRNAIdFile=\"genome/hg38/source/refSeq_rRNA.ids.txt\" awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,0,$2,\"p\"NR\".1\",\"gneg\"}' \"$fastaIndexURL\" > \"$cytobandURL\" bedToGenePred <(awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}NR==FNR{split($0,a,\"|\");name[a[1]]=a[2];next}{print $1,0,$2,name[$1],0,\"+\"}' \"$rRNAIdFile\" \"$fastaIndexURL\") \"$refURL\" genome=\"circRNA\" fastaURL=\"genome/hg38/fasta/${genome}.fa\" fastaIndexURL=\"genome/hg38/fasta/${genome}.fa.fai\" cytobandURL=\"genome/hg38/cytoband/${genome}.txt\" refURL=\"genome/hg38/genePred/${genome}.genePred\" awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,0,$2,\"p\"NR\".1\",\"gneg\"}' \"$fastaIndexURL\" > \"$cytobandURL\" bedToGenePred <(awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,0,$2,$1,0,\"+\"}' \"$fastaIndexURL\") \"$refURL\"","title":"IGV Browser"},{"location":"igv_browser/#igv-genome-browser","text":"","title":"IGV Genome Browser"},{"location":"igv_browser/#templates","text":"for d in img js css;do [ -d \"templates/igv/$d\" ] || mkdir -p \"templates/igv/$d\" done wget -O templates/igv/img/favicon.ico 'https://igv.org/web/img/favicon.ico' wget -O templates/igv/js/igv.min.js 'https://igv.org/web/release/2.1.0/dist/igv.min.js' wget -O templates/igv/css/bootstrap.min.css 'https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css' wget -O templates/igv/js/bootstrap.min.js 'https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js' wget -O templates/igv/js/jquery-3.2.1.slim.min.js 'https://code.jquery.com/jquery-3.2.1.slim.min.js' wget -O templates/igv/js/popper.min.js 'https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js'","title":"Templates"},{"location":"igv_browser/#genome-reference-from-igv","text":"wget -O genome/hg38/source/igv.hg38.genome http://s3.amazonaws.com/igv.broadinstitute.org/genomes/hg38.genome unzip genome/hg38/source/igv.hg38.genome -d genome/hg38/igv","title":"Genome reference from IGV"},{"location":"igv_browser/#generate-igv-html","text":"","title":"Generate IGV html"},{"location":"igv_browser/#igv-browser-reference","text":"","title":"IGV Browser reference"},{"location":"igv_browser/#igvbrowser","text":"addMultiLocusPanelWithGenomicStateAtIndex: \u0192 (genomicState,index,viewportWidth) addTrack: \u0192 (track) buildViewportsWithGenomicStateList: \u0192 (genomicStateList) cancelTrackPan: \u0192 () compressedSession: \u0192 () dispose: \u0192 () emptyViewportContainers: \u0192 () endTrackDrag: \u0192 () findTracks: \u0192 (property,value) fireEvent: \u0192 (eventName,args,thisObj) getChromosomeLengthBP: \u0192 (genome,referenceFrame) goto: \u0192 (chrName,start,end) hideCenterGuide: \u0192 () hideCursorGuide: \u0192 () hideTrackLabels: \u0192 () isMultiLocusMode: \u0192 () isMultiLocusWholeGenomeView: \u0192 () loadGenome: \u0192 (idOrConfig,initialLocus) loadInProgress: \u0192 () loadSampleInformation: \u0192 (url) loadSession: \u0192 (sessionURL,config) loadTrack: \u0192 (config) loadTrackList: \u0192 (configList) minimumBases: \u0192 () mouseDownOnViewport: \u0192 (e,viewport) on: \u0192 (eventName,fn) presentAlert: \u0192 (alert,$parent,callback) presentMessageWithCallback: \u0192 (message,callback) presentSplitScreenMultiLocusPanel: \u0192 (alignment,genomicState) removeAllTracks: \u0192 (removeSequence) removeMultiLocusPanelWithGenomicState: \u0192 (genomicState,doResize) removeTrack: \u0192 (track) removeTrackByName: \u0192 (name) renderSVG: \u0192 (config) reorderTracks: \u0192 () resize: \u0192 () search: \u0192 (string,init) selectMultiLocusPanelWithGenomicState: \u0192 (selectedGenomicState) sessionURL: \u0192 () setTrackHeight: \u0192 (newHeight) setTrackLabelName: \u0192 (trackView,name) showCenterGuide: \u0192 () showCursorGuide: \u0192 () showTrackLabels: \u0192 () startTrackDrag: \u0192 (trackView) toJSON: \u0192 () un: \u0192 (eventName,fn) updateLocusSearchWidget: \u0192 (genomicState) updateTrackDrag: \u0192 (dragDestination) updateUIWithGenomicStateListChange: \u0192 (genomicStateList) updateViews: \u0192 (genomicState,views) updateZoomSlider: \u0192 ($slider) viewportContainerWidth: \u0192 () viewportWidth: \u0192 () visibilityChange: \u0192 () zoom: \u0192 (scaleFactor) zoomIn: \u0192 () zoomOut: \u0192 () zoomWithRangePercentage: \u0192 (percentage) zoomWithScaleFactor: \u0192 (centerBPOrUndefined,viewportOrUndefined,scaleFactor)","title":"igv.browser"},{"location":"igv_browser/#file-extensions","text":"narrowpeak broadpeak peaks bedgraph wig gff3 gff gtf fusionjuncspan refflat seg aed bed vcf bb bigbed bw bigwig bam tdf refgene genepred genepredext bedpe bp snp rmsk","title":"File extensions"},{"location":"igv_browser/#track-configuration-reference","text":"track1: type: wig format: bigwig height: 200 min: 0 max: 100 color: 'rgb(0,0,0)' autoScale: true, logScale: false long_RNA: url: genome/hg38/genePred/long_RNA.genePred type: annotation format: genepred height: 200 { echo 'reference: id: hg38 fastaURL: genome/hg38/fasta/genome.fa indexURL: genome/hg38/fasta/genome.fa.fai cytobandURL: genome/hg38/igv/cytoBandIdeo.txt Refseq Genes: type: annotation format: refGene url: genome/hg38/igv/refGene.txt visibilityWindow: 300000000 height: 80 GENCODE_V27: type: annotation format: bed url: genome/hg38/igv/gencode.bed indexURL: genome/hg38/igv/gencode.bed.idx displayMode: \"EXPANDED\" searchable: true visibilityWindow: 300000000 height: 200' for sample_id in $(head -n 50 data/scirep/sample_ids.txt);do printf \"${sample_id}(+): url: scirep/${sample_id}.transcriptome.+.bigWig type: wig format: bigwig height: 25 ${sample_id}(-): url: scirep/${sample_id}.transcriptome.-.bigWig type: wig format: bigwig height: 25 \" done } > genome_browser/config/scirep.yaml bin/create_igv.py -i templates/igv/main.html -g hg38 \\ --tracklist genome_browser/config/scirep.yaml \\ --base-url http://166.111.156.12:10080/genomebrowse \\ -o genome_browser/igv/scirep.html sync-bigwig bin/create_igv.py -i templates/igv/main.html -g hg38 --genome-dir genome/hg38/ \\ --track genome/hg38/bed/long_RNA.intron.bed \\ --track genome/hg38/bed/rmsk.bed \\ --track genome/hg38/bed/promoter.merged.bed \\ --track genome/hg38/bed/enhancer.merged.bed \\ --track output/scirep/bigwig/Sample_1S1.genome.+.bigWig \\ --track output/scirep/bigwig/Sample_1S1.genome.-.bigWig \\ -o igv.html bin/create_igv.py -i templates/igv/main.html -g hg38 --genome-dir genome/hg38/ \\ --tracklist tmp/tracklist.yaml \\ -o igv.html --track output/scirep/bigwig/Sample_1S1.genome.+.bigWig -o igv.html","title":"Track configuration reference"},{"location":"igv_browser/#reference-tracks","text":"gtfToGenePred -geneNameAsName2 -genePredExt genome/hg38/gtf/gencode.gtf genome/hg38/genePred/gencode.genePredExt gffread -E --bed genome/hg38/gtf/gencode.gtf -o /dev/stdout | bedtools sort > genome/hg38/igv/gencode.bed ./tools/IGVTools/igvtools index genome/hg38/igv/gencode.bed","title":"Reference tracks"},{"location":"igv_browser/#domains","text":"gffread --bed -o genome/hg38/bed/long_RNA.bed genome/hg38/gtf/long_RNA.gtf gffread --bed -o genome/hg38/bed/gencode_tRNA.bed genome/hg38/gtf/gencode_tRNA.gtf [ -d \"output/scirep/gdomains/20/05.bed\" ] || mkdir -p output/scirep/gdomains/20 { bin/tbed2gbed <(cat genome/hg38/bed/long_RNA.bed genome/hg38/bed/gencode_tRNA.bed) <(grep -v '^chr' output/scirep/domains/20/05.bed) /dev/stdout awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}/^chr/{print $0,0,0,0,1,$3-$2,0}' output/scirep/domains/20/05.bed } | bedtools sort > output/scirep/gdomains/20/05.bed","title":"Domains"},{"location":"igv_browser/#custom-reference-genome","text":"IGV genome repository: (https://s3.amazonaws.com/igv.org.genomes/genomes.json) Cytoband schema: UCSC genome=\"rRNA\" fastaURL=\"genome/hg38/fasta/${genome}.fa\" fastaIndexURL=\"genome/hg38/fasta/${genome}.fa.fai\" cytobandURL=\"genome/hg38/cytoband/${genome}.txt\" refURL=\"genome/hg38/genePred/${genome}.genePred\" # convert NR_ ids to rRNA names # gene_id|gene_name rRNAIdFile=\"genome/hg38/source/refSeq_rRNA.ids.txt\" awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,0,$2,\"p\"NR\".1\",\"gneg\"}' \"$fastaIndexURL\" > \"$cytobandURL\" bedToGenePred <(awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}NR==FNR{split($0,a,\"|\");name[a[1]]=a[2];next}{print $1,0,$2,name[$1],0,\"+\"}' \"$rRNAIdFile\" \"$fastaIndexURL\") \"$refURL\" genome=\"circRNA\" fastaURL=\"genome/hg38/fasta/${genome}.fa\" fastaIndexURL=\"genome/hg38/fasta/${genome}.fa.fai\" cytobandURL=\"genome/hg38/cytoband/${genome}.txt\" refURL=\"genome/hg38/genePred/${genome}.genePred\" awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,0,$2,\"p\"NR\".1\",\"gneg\"}' \"$fastaIndexURL\" > \"$cytobandURL\" bedToGenePred <(awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,0,$2,$1,0,\"+\"}' \"$fastaIndexURL\") \"$refURL\"","title":"Custom reference genome"},{"location":"installation/","text":"","title":"Installation"},{"location":"long_rna_mapping/","text":"","title":"Long RNA-seq mapping"},{"location":"matrix_processing/","text":"Matrix Processing usage: bin/matrix-process.R [-h] -s STEP -i INPUT -c CLASS -b BATCH --filterout FILTEROUT --imputeout IMPUTEOUT --normalizeout NORMALIZEOUT --batchremoveout BATCHREMOVEOUT [--filtercount NUMBER] [--filtersample NUMBER] [--imputemethod STRING] [--imputecluster NUMBER] [--imputenum NUMBER] [--imputecutoff NUMBER] [--imputealpha NUMBER] [--normmethod STRING] [--normtopk NUMBER] [--cvthreshold NUMBER] [--removetype STRING] [--refergenefile STRING] [--batchmethod STRING] [--batchindex INT] [-p NUMBER] optional arguments: -h, --help show this help message and exit -s STEP, --step STEP which step to run -i INPUT, --input INPUT input expression matrix file -c CLASS, --class CLASS input class info file -b BATCH, --batch BATCH input batch info file --filterout FILTEROUT output filter path --imputeout IMPUTEOUT output imputation path --normalizeout NORMALIZEOUT output normalization file --batchremoveout BATCHREMOVEOUT output batchremoved file --filtercount NUMBER filter by counts of a gene [default = 5] --filtersample NUMBER filter by counts of sample above certain counts of a gene [default = 10] --imputemethod STRING the imputation algorithm to use [default = scimpute_count] --imputecluster NUMBER cluster number in scImpute [default = 5] --imputenum NUMBER number in viper [default = 5000] --imputecutoff NUMBER cutoff in viper [default = 0.5] --imputealpha NUMBER alpha in viper [default = 0.1] --normmethod STRING the normalization algorithm to use [default = SCNorm] --normtopk NUMBER top K feature as scale factor [default = 20] --cvthreshold NUMBER coefficient variance threshold of reference gene, filter ref gene with CV bigger than [default = 0.5] --removetype STRING remove some time of RNA for normalization scale factor calculation [default = miRNA,piRNA] --refergenefile STRING reference gene file path [default = None] --batchmethod STRING the batch removal algorithm to use [default = RUV] --batchindex INT batch index to select which batch to use [default = 1] -p NUMBER, --processors NUMBER Number of processors to use. This option is useful on multicore *nix or Mac machine only, when performing multiple runs (nrun > 1) [default = 1] Some parameters: -s filter imputation normalization batch_removal --imputemethod scimpute_count,viper_count,null --normmethod SCnorm,TMM,RLE,CPM,CPM_top,CPM_rm,CPM_refer,null --batchmetod RUV,Combat,null --batchindex 1 Example: bin/matrix-process.R -s imputation \\ -i output/lulab_hcc/count_matrix/domains_combined.txt \\ --filterout output/lulab_hcc/matrix_processing/ \\ --imputemethod viper_count \\ --imputeout output/lulab_hcc/matrix_processing/ \\ --filtercount 5 \\ --filtersample 10 \\ --imputecluster 5 \\ --imputenum 5000 \\ --imputecutoff 0.1 \\ --imputealpha 0.5 \\ -p 4 \\ --normalizeout output/lulab_hcc/matrix_processing/ \\ --normmethod RLE \\ --normtopk 20 \\ --removetype miRNA,piRNA \\ --cvthreshold 0.5 \\ --refergenefile data/matrix_processing/refer_gene_id.txt \\ -c data/lulab_hcc/sample_classes.txt \\ -b data/lulab_hcc/batch_info.txt \\ --batchremoveout output/scirep/matrix_processing/ \\ --batchmethod RUV \\ --batchindex 1 Filter filter lowly expressed reads Imputation scImpute Normalization Normalization is performed for the systematic error of each sample (such as the sequencing depth). Different Normalization Methods CPM(counts per million) Use candidate reference gene. For example: 'MIR1228', 'MIR16-1', 'MIR16-2', 'MIR21', 'MIR23A', 'MIR23B', 'MIR23C', 'MIR451A', 'MIR15A', 'MIR15B' remove piRNA and miRNA and use CPM(counts per million) Remove top k and scale others (then add top k back) use packages: SCNorm RLE TMM Select Reference Gene A density plot or a violin plot is used to analyze the coefficient of variation of different reference genes, and select stable miRNAs as an internal references with a small coefficient of variation. It can be seen that the variation coefficient of MIR1228 and MIR15B is not stable enough, and should not be used as an internal reference. Density plot of CV Boxplot of expression value (log) Criteria to use top20 We recommend to remove top20 and use left genes sum as scale factor if they account for more than 50% of total counts. cumulative ratio highest expressed gene Batch Removal Visualize Batch Effect - visualize batch by counts - visualize batch by specific RNA counts [ ] to do select batch factor plot Batch Removal methods RUVs Combat visualize processed result PCA visualization Use alignment score to Quantify Clustering effect. PCA and t-SNE can visualize the aggregation degree of the sample, but it cannot be quantified to compare different methods. We provide the following two functions alignment_socre & knn_score to quantify the binary classification and multi-class classification respectively. The closer the value is to 1, the more aggregated samples are. PCA visualization of original matrix and processed matrix expression vs count depth scImpute CPM CPM, remove mi and piRNA CPM remove top CPM use reference gene RLE -TMM -SCnorm Relative Log Expression box plot","title":"Matrix processing"},{"location":"matrix_processing/#matrix-processing","text":"usage: bin/matrix-process.R [-h] -s STEP -i INPUT -c CLASS -b BATCH --filterout FILTEROUT --imputeout IMPUTEOUT --normalizeout NORMALIZEOUT --batchremoveout BATCHREMOVEOUT [--filtercount NUMBER] [--filtersample NUMBER] [--imputemethod STRING] [--imputecluster NUMBER] [--imputenum NUMBER] [--imputecutoff NUMBER] [--imputealpha NUMBER] [--normmethod STRING] [--normtopk NUMBER] [--cvthreshold NUMBER] [--removetype STRING] [--refergenefile STRING] [--batchmethod STRING] [--batchindex INT] [-p NUMBER] optional arguments: -h, --help show this help message and exit -s STEP, --step STEP which step to run -i INPUT, --input INPUT input expression matrix file -c CLASS, --class CLASS input class info file -b BATCH, --batch BATCH input batch info file --filterout FILTEROUT output filter path --imputeout IMPUTEOUT output imputation path --normalizeout NORMALIZEOUT output normalization file --batchremoveout BATCHREMOVEOUT output batchremoved file --filtercount NUMBER filter by counts of a gene [default = 5] --filtersample NUMBER filter by counts of sample above certain counts of a gene [default = 10] --imputemethod STRING the imputation algorithm to use [default = scimpute_count] --imputecluster NUMBER cluster number in scImpute [default = 5] --imputenum NUMBER number in viper [default = 5000] --imputecutoff NUMBER cutoff in viper [default = 0.5] --imputealpha NUMBER alpha in viper [default = 0.1] --normmethod STRING the normalization algorithm to use [default = SCNorm] --normtopk NUMBER top K feature as scale factor [default = 20] --cvthreshold NUMBER coefficient variance threshold of reference gene, filter ref gene with CV bigger than [default = 0.5] --removetype STRING remove some time of RNA for normalization scale factor calculation [default = miRNA,piRNA] --refergenefile STRING reference gene file path [default = None] --batchmethod STRING the batch removal algorithm to use [default = RUV] --batchindex INT batch index to select which batch to use [default = 1] -p NUMBER, --processors NUMBER Number of processors to use. This option is useful on multicore *nix or Mac machine only, when performing multiple runs (nrun > 1) [default = 1] Some parameters: -s filter imputation normalization batch_removal --imputemethod scimpute_count,viper_count,null --normmethod SCnorm,TMM,RLE,CPM,CPM_top,CPM_rm,CPM_refer,null --batchmetod RUV,Combat,null --batchindex 1 Example: bin/matrix-process.R -s imputation \\ -i output/lulab_hcc/count_matrix/domains_combined.txt \\ --filterout output/lulab_hcc/matrix_processing/ \\ --imputemethod viper_count \\ --imputeout output/lulab_hcc/matrix_processing/ \\ --filtercount 5 \\ --filtersample 10 \\ --imputecluster 5 \\ --imputenum 5000 \\ --imputecutoff 0.1 \\ --imputealpha 0.5 \\ -p 4 \\ --normalizeout output/lulab_hcc/matrix_processing/ \\ --normmethod RLE \\ --normtopk 20 \\ --removetype miRNA,piRNA \\ --cvthreshold 0.5 \\ --refergenefile data/matrix_processing/refer_gene_id.txt \\ -c data/lulab_hcc/sample_classes.txt \\ -b data/lulab_hcc/batch_info.txt \\ --batchremoveout output/scirep/matrix_processing/ \\ --batchmethod RUV \\ --batchindex 1","title":"Matrix Processing"},{"location":"matrix_processing/#filter","text":"filter lowly expressed reads","title":"Filter"},{"location":"matrix_processing/#imputation","text":"scImpute","title":"Imputation"},{"location":"matrix_processing/#normalization","text":"Normalization is performed for the systematic error of each sample (such as the sequencing depth). Different Normalization Methods CPM(counts per million) Use candidate reference gene. For example: 'MIR1228', 'MIR16-1', 'MIR16-2', 'MIR21', 'MIR23A', 'MIR23B', 'MIR23C', 'MIR451A', 'MIR15A', 'MIR15B' remove piRNA and miRNA and use CPM(counts per million) Remove top k and scale others (then add top k back) use packages: SCNorm RLE TMM","title":"Normalization"},{"location":"matrix_processing/#select-reference-gene","text":"A density plot or a violin plot is used to analyze the coefficient of variation of different reference genes, and select stable miRNAs as an internal references with a small coefficient of variation. It can be seen that the variation coefficient of MIR1228 and MIR15B is not stable enough, and should not be used as an internal reference. Density plot of CV Boxplot of expression value (log)","title":"Select Reference Gene"},{"location":"matrix_processing/#criteria-to-use-top20","text":"We recommend to remove top20 and use left genes sum as scale factor if they account for more than 50% of total counts. cumulative ratio highest expressed gene","title":"Criteria to use top20"},{"location":"matrix_processing/#batch-removal","text":"","title":"Batch Removal"},{"location":"matrix_processing/#visualize-batch-effect","text":"","title":"Visualize Batch Effect"},{"location":"matrix_processing/#-visualize-batch-by-counts","text":"","title":"- visualize batch by counts"},{"location":"matrix_processing/#-visualize-batch-by-specific-rna-counts","text":"[ ] to do select batch factor plot","title":"- visualize batch by specific RNA counts"},{"location":"matrix_processing/#batch-removal-methods","text":"RUVs Combat","title":"Batch Removal methods"},{"location":"matrix_processing/#visualize-processed-result","text":"","title":"visualize processed result"},{"location":"matrix_processing/#pca-visualization","text":"Use alignment score to Quantify Clustering effect. PCA and t-SNE can visualize the aggregation degree of the sample, but it cannot be quantified to compare different methods. We provide the following two functions alignment_socre & knn_score to quantify the binary classification and multi-class classification respectively. The closer the value is to 1, the more aggregated samples are. PCA visualization of original matrix and processed matrix","title":"PCA visualization"},{"location":"matrix_processing/#expression-vs-count-depth","text":"scImpute CPM CPM, remove mi and piRNA CPM remove top CPM use reference gene RLE -TMM -SCnorm","title":"expression vs count depth"},{"location":"matrix_processing/#relative-log-expression-box-plot","text":"","title":"Relative Log Expression box plot"},{"location":"output_files/","text":"Small RNA mapping File name Descrpition snakemake/sequential_mapping.snakemake Snakefile for sequential mapping. Required by snakemake/mapping_small.snakemake ${output_dir}/cutadapt/${sample_id}.fastq Reads with adaptor trimmed ${output_dir}/tbam/${sample_id}/${rna_type}.bam BAM files in transcript coordinates ${output_dir}/gbam/${sample_id}/${rna_type}.bam BAM files in genome coordinates ${output_dir}/unmapped/${sample_id}/${rna_type}.fa.gz Unmapped reads in each step ${output_dir}/fastqc/${sample_id}_fastqc.html FastQC report file ${output_dir}/summary/fastqc.html Summary report for FastQC (HTML) ${output_dir}/summary/fastqc.txt Summary table for FastQC ${output_dir}/summary/fastqc.ipynb Summary report for FastQC (Jupyter notebook) ${output_dir}/summary/read_counts.txt Summary table for read counts ${output_dir}/stats/mapped_read_length_by_sample/${sample_id} Length distribution of mapped reads Long RNA mapping File name Descrpition ${output_dir}/cutadapt/${sample_id}.fastq Reads with adaptor trimmed ${output_dir}/bam/${sample_id}/rRNA.bam BAM files for reads mapped to rRNA ${output_dir}/bam/${sample_id}/genome.bam BAM files for reads mapped to genome ${output_dir}/bam/${sample_id}/remove_duplicates.bam BAM files for reads after removing duplicates ${output_dir}/bam/${sample_id}/circRNA.bam BAM files for reads after removing duplicates ${output_dir}/unmapped/${sample_id}/${map_step}_1.fa.gz Unmapped reads in each step ${output_dir}/fastqc/${sample_id}_fastqc.html FastQC report file ${output_dir}/summary/read_counts.txt Summary table for read counts ${output_dir}/stats/mapped_read_length_by_sample/${sample_id} Length distribution of mapped reads ${output_dir}/stats/mapped_insert_size_by_sample/${sample_id} Length distribution of mapped reads Count matrix (small RNA-seq) File name Descrpition ${output_dir}/count_matrix/transcript.txt Count matrix of transcripts ${output_dir}/count_matrix/htseq.txt Count matrix of genes generated using HTSeq-count ${output_dir}/count_matrix/featurecounts.txt Count matrix of genes generated using featureCounts ${output_dir}/counts_by_biotype/${count_method}/${sample_id}/${rna_type} Gene/transcript counts generated using a feature counting tool Long RNA domains File name Descrpition ${output_dir}/domain_counts/${bin_size}/${pvalue}/${sample_id}.bed Read counts in long RNA domains (BED format with read counts in Column 5 ${output_dir}/count_matrix/domain_${pvalue}.txt Read count matrix of long RNA domains ${output_dir}/domains/${bin_size}/${pvalue}.bed Long RNA domain locations ${output_dir}/domains_recurrence/${bin_size}/${pvalue}.bed Recurrence of long RNA domains among samples (Column 5) Matrix processing File name Description ${output_dir}/normalized_matrix/${normalization_method}.${imputation_method}.${batch_removal_method}.txt ${output_dir}/matrix_processing/normalization/${normalization_method}.txt ${output_dir}/matrix_processing/imputation/${normalization_method}.${imputation_method}.txt ${output_dir}/matrix_processing/batch_removal/${batch_removal_method}.${batch_index}.txt Differential expression File name Description ${output_dir}/differential_expression/${count_method}/${compare_group}/${diffexp_method}.txt","title":"Output files"},{"location":"output_files/#small-rna-mapping","text":"File name Descrpition snakemake/sequential_mapping.snakemake Snakefile for sequential mapping. Required by snakemake/mapping_small.snakemake ${output_dir}/cutadapt/${sample_id}.fastq Reads with adaptor trimmed ${output_dir}/tbam/${sample_id}/${rna_type}.bam BAM files in transcript coordinates ${output_dir}/gbam/${sample_id}/${rna_type}.bam BAM files in genome coordinates ${output_dir}/unmapped/${sample_id}/${rna_type}.fa.gz Unmapped reads in each step ${output_dir}/fastqc/${sample_id}_fastqc.html FastQC report file ${output_dir}/summary/fastqc.html Summary report for FastQC (HTML) ${output_dir}/summary/fastqc.txt Summary table for FastQC ${output_dir}/summary/fastqc.ipynb Summary report for FastQC (Jupyter notebook) ${output_dir}/summary/read_counts.txt Summary table for read counts ${output_dir}/stats/mapped_read_length_by_sample/${sample_id} Length distribution of mapped reads","title":"Small RNA mapping"},{"location":"output_files/#long-rna-mapping","text":"File name Descrpition ${output_dir}/cutadapt/${sample_id}.fastq Reads with adaptor trimmed ${output_dir}/bam/${sample_id}/rRNA.bam BAM files for reads mapped to rRNA ${output_dir}/bam/${sample_id}/genome.bam BAM files for reads mapped to genome ${output_dir}/bam/${sample_id}/remove_duplicates.bam BAM files for reads after removing duplicates ${output_dir}/bam/${sample_id}/circRNA.bam BAM files for reads after removing duplicates ${output_dir}/unmapped/${sample_id}/${map_step}_1.fa.gz Unmapped reads in each step ${output_dir}/fastqc/${sample_id}_fastqc.html FastQC report file ${output_dir}/summary/read_counts.txt Summary table for read counts ${output_dir}/stats/mapped_read_length_by_sample/${sample_id} Length distribution of mapped reads ${output_dir}/stats/mapped_insert_size_by_sample/${sample_id} Length distribution of mapped reads","title":"Long RNA mapping"},{"location":"output_files/#count-matrix-small-rna-seq","text":"File name Descrpition ${output_dir}/count_matrix/transcript.txt Count matrix of transcripts ${output_dir}/count_matrix/htseq.txt Count matrix of genes generated using HTSeq-count ${output_dir}/count_matrix/featurecounts.txt Count matrix of genes generated using featureCounts ${output_dir}/counts_by_biotype/${count_method}/${sample_id}/${rna_type} Gene/transcript counts generated using a feature counting tool","title":"Count matrix (small RNA-seq)"},{"location":"output_files/#long-rna-domains","text":"File name Descrpition ${output_dir}/domain_counts/${bin_size}/${pvalue}/${sample_id}.bed Read counts in long RNA domains (BED format with read counts in Column 5 ${output_dir}/count_matrix/domain_${pvalue}.txt Read count matrix of long RNA domains ${output_dir}/domains/${bin_size}/${pvalue}.bed Long RNA domain locations ${output_dir}/domains_recurrence/${bin_size}/${pvalue}.bed Recurrence of long RNA domains among samples (Column 5)","title":"Long RNA domains"},{"location":"output_files/#matrix-processing","text":"File name Description ${output_dir}/normalized_matrix/${normalization_method}.${imputation_method}.${batch_removal_method}.txt ${output_dir}/matrix_processing/normalization/${normalization_method}.txt ${output_dir}/matrix_processing/imputation/${normalization_method}.${imputation_method}.txt ${output_dir}/matrix_processing/batch_removal/${batch_removal_method}.${batch_index}.txt","title":"Matrix processing"},{"location":"output_files/#differential-expression","text":"File name Description ${output_dir}/differential_expression/${count_method}/${compare_group}/${diffexp_method}.txt","title":"Differential expression"},{"location":"prepare_genome_annotation/","text":"Prepare Genome and Annotation Sequence Annotation Index files Genome hg38 Sequence download from gencode v27 [ ]located in folder: located in folder: sequence/ mkdir sequence cd sequence wget wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/GRCh38.p10.genome.fa.gz Decompression gzip -d GRCh38.p10.genome.fa.gz parse genome samtools faidx GRCh38.p10.genome.fa cut -f1,2 GRCh38.p10.genome.fa.fai > hg38.chrom.sizes Index build by bowtie2 and STAR [ ]located in folder: located in folder: index/ using bowtie2 mkdir bowtie2_hg38_index cd bowtie2_hg38_index bowtie2-build ../sequence/GRCh38.p10.genome.fa GRCh38.p10 using STAR mkdir ../STAR_hg38_index cd ../STAR_hg38_index STAR --runMode genomeGenerate --runThreadN 15 --genomeDir . --genomeFastaFiles ../sequence/GRCh38.p10.genome.fa Annotation files for genome hg38 provider: GENCODE and other projects format: gtf and gff statistics RNA_type gene_num transcrips_num source file Date Download/Processed Note allGenes 58,288 200,401 Gencode27 gencode.v27.annotation.gtf / gencode.v27.annotation.gff 2018.5.4 D/D rRNA 544 544 Gencode27 rRNA.gencode27.gtf / rRNA.gencode27.gff 2018.5.4 P/P miRNA 1,881 1,881 Gencode27 miRNA.gencode27.gtf / miRNA.gencode27.gff 2018.5.4 P/P piRNA 812,347 812,347 piRBase piRNA.piRBase.hg38.gtf / piRNA.piRBase.hg38.gff 2018.5.4 D/D snoRNA 943 955 Gencode27(misc_RNA) snoRNA.gencode27.gtf / snoRNA.gencode27.gtf 2018.5.4 P/P snRNA 1,900 1,900 Gencode27 snRNA.gencode27.gtf / snRNA.gencode27.gtf 2018.5.4 P/P srpRNA 680 680 Gencode27(misc_RNA) srpRNA.gencode27.gtf / srpRNA.gencode27.gff 2018.5.4 P/P tRNA 649 649 Gencode27(predicted tRNA) tRNA.gencode27.gtf / tRNA.gencode27.gff 2018.5.4 D/D lncRNA 15,778 27,908 Gencode27(lncRNA) lncRNA.gencode27.gtf / lncRNA.gencode27.gff 2018.5.4 D/D lncRNA 96,308 172,216 NONCODEv5 lncRNA.NONCODEv5.hg38.gtf / lncRNA.NONCODEv5.hg38.gff 2018.5.4 P/P lncRNA 63,427 174,657 mitranscritome lncRNA.mitranscriptome.v2.hg38.gtf / lncRNA.mitranscriptome.v2.hg38.gff 2018.5.4 P/P tucp 3,711 11,244 mitranscritome tucp.mitranscriptome.v2.hg38.gtf / tucp.mitranscriptome.v2.hg38.gff 2018.5.4 P/P lncRNA 131,683 342,295 Gencode27+NONCODEv5+ MiTranscriptome+NC2017 merged_lncRNA.combined.gtf / merged_lncRNA.combined.gff 2018.5.4 P/P mRNA 19,836 80,930 Gencode27(protein_coding) mRNA.gencode27.gtf / mRNA.gencode27.gff 2018.5.4 P/P pre-process annotaion download gencode v27 annotations wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.annotation.gtf.gz wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.annotation.gff3.gz wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.long_noncoding_RNAs.gtf.gz wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.long_noncoding_RNAs.gff3.gz wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.tRNAs.gtf.gz wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.tRNAs.gff3.gz Decompression gzip -d * parse annotations gtf=gencode.v27.annotation.gtf for i in rRNA snRNA snoRNA srpRNA miRNA vaultRNA Y_RNA; do grep \"gene_type \\\"$i\\\"\" $gtf > $i.gencode27.gtf gffread -E $i.gencode27.gtf -o- > $i.gencode27.gff done; grep \"gene_type \\\"protein_coding\\\"\" $gtf | grep -v Selenocysteine > mRNA.gencode27.gtf grep \"RN7SL\" $gtf > srpRNA.gencode27.gtf grep 'Y_RNA' $gtf > Y_RNA.gencode27.gtf for i in mRNA srpRNA Y_RNA; do gffread -E $i.gencode27.gtf -o- > $i.gencode27.gff done; mv gencode.v27.tRNAs.gtf tRNA.gencode27.gtf mv gencode.v27.tRNAs.gff3 tRNA.gencode27.gff mv gencode.v27.long_noncoding_RNAs.gtf lncRNA.gencode27.gtf mv gencode.v27.long_noncoding_RNAs.gff3 lncRNA.gencode27.gff mv gencode.v27.annotation.gff3 gencode.v27.annotation.gff download piRNA from piRBase downlaod lncRNA from NONCODE(http://www.noncode.org/), mitranscriptome(http://mitranscriptome.org/), and Yang Yang's NC paper wget http://mitranscriptome.org/download/mitranscriptome.gtf.tar.gz wget http://www.noncode.org/datadownload/NONCODEv5_human_hg38_lncRNA.gtf.gz wget https://media.nature.com/original/nature-assets/ncomms/2017/170213/ncomms14421/extref/ncomms14421-s3.txt Decompression tar zxvf mitranscriptome.gtf.tar.gz gzip -d mitranscriptome.v2.gtf.gz parse and convert wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz gzip -d hg19ToHg38.over.chain.gz cd mitranscriptome.gtf gzip -d mitranscriptome.v2.gtf.gz gtfToGenePred -genePredExt mitranscriptome.v2.gtf mitranscriptome.v2.gp liftOver -genePred mitranscriptome.v2.gp ../hg19ToHg38.over.chain mitranscriptome.v2.hg38.gp unmapped.gtf genePredToGtf -utr -source=mitranscriptome file mitranscriptome.v2.hg38.gp mitranscriptome.v2.hg38.gtf gffread -E mitranscriptome.v2.hg38.gtf -o- > mitranscriptome.v2.hg38.gff mv ../mitranscriptome.gtf ../mitranscriptome cd .. # filter out lncRNA cd mitranscriptome.gtf zcat mitranscriptome.v2.gtf.gz | grep -e 'tcat \\\"lncrna\\\"' > lncRNA.mitranscriptome.v2.gtf # liftOver hg19 to hg38 gtfToGenePred -genePredExt lncRNA.mitranscriptome.v2.gtf lncRNA.mitranscriptome.v2.gp liftOver -genePred lncRNA.mitranscriptome.v2.gp ../hg19ToHg38.over.chain lncRNA.mitranscriptome.v2.hg38.gp unmapped.gtf genePredToGtf -utr -source=mitranscriptome file lncRNA.mitranscriptome.v2.hg38.gp lncRNA.mitranscriptome.v2.hg38.gtf gffread -E lncRNA.mitranscriptome.v2.hg38.gtf -o- > lncRNA.mitranscriptome.v2.hg38.gff # filter out tucp zcat mitranscriptome.v2.gtf.gz | grep -e 'tcat \\\"tucp\\\"' | awk '$7!=\".\"' > tucp.mitranscriptome.v2.gtf # liftOver hg19 to hg38 gtfToGenePred -genePredExt tucp.mitranscriptome.v2.gtf tucp.mitranscriptome.v2.gp liftOver -genePred tucp.mitranscriptome.v2.gp ../hg19ToHg38.over.chain tucp.mitranscriptome.v2.hg38.gp unmapped.gtf genePredToGtf -utr -source=mitranscriptome file tucp.mitranscriptome.v2.hg38.gp tucp.mitranscriptome.v2.hg38.gtf gffread -E tucp.mitranscriptome.v2.hg38.gtf -o- > tucp.mitranscriptome.v2.hg38.gff cd .. gtfToGenePred -genePredExt ncomms14421-s3.txt lncRNA.lulab_ncomms14421.gp liftOver -genePred lncRNA.lulab_ncomms14421.gp hg19ToHg38.over.chain lncRNA.lulab_ncomms14421.hg38.gp unmapped.gtf genePredToGtf -utr -source=lulab_ncomms14421 file lncRNA.lulab_ncomms14421.hg38.gp lncRNA.lulab_ncomms14421.hg38.gtf gffread -E lncRNA.lulab_ncomms14421.hg38.gtf -o- > lncRNA.lulab_ncomms14421.hg38.gff cd mitranscriptome.gtf mv * .. cd mitranscriptome mv * .. rm -rf mitranscriptome mitranscriptome.gtf mitranscriptome.gtf.tar.gz rm -rf *.gp unmapped.gtf mv NONCODEv5_human_hg38_lncRNA.gtf lncRNA.NONCODEv5.hg38.gtf merge lncRNA annotations gffcompare -o merged_lncRNA -s ../sequence/GRCh38.p10.genome.fa lncRNA.NONCODEv5.hg38.gtf lncRNA.mitranscriptome.v2.hg38.gtf lncRNA.gencode27.gtf lncRNA.lulab_ncomms14421.hg38.gtf gffread -E merged_lncRNA.combined.gtf -o- > merged_lncRNA.combined.gff mkdir gtf gff cd .. mkdir gtf gff mv gencode/*.gtf gtf mv gencode/*.gff gff establish indexes if [ \"$1\" = \"0\" ]; then for i in ${RNAs[@]} ; do echo \"start $i.gtf:\" rsem-prepare-reference --gtf $gtf/$i.gtf --bowtie2 $hg38 RNA_index/$i echo \"$i finished.\" done cut lncRNA into bins convert combined gtf to combined bed gffread --bed merged_lncRNA.combined.gtf -o merged_lncRNA.combined.bed grep the longest transciprt for each lncRNA gene and calculate its length awk 'NR==FNR {split($10,m,\"\\\"\");split($12,n,\"\\\"\");D[m[2]]=n[2]} \\ NR>FNR {split($11,ex,\",\");for (k in ex) len[$4]+=ex[k]; b[D[$4]] = len[$4] > a[D[$4]] ? $4 : b[D[$4]]; a[D[$4]] = len[$4] > a[D[$4]] ? len[$4] : a[D[$4]] } \\ END { OFS = \"\\t\"; for(x in a) print x, a[x],b[x]}' merged_lncRNA.combined.gtf merged_lncRNA.combined.bed >merged_lncRNA.combined.longest.tran grep the exons of the longest transciprts awk '{print $3}' merged_lncRNA.combined.longest.tran| grep -Ff - merged_lncRNA.combined.gtf|awk '$3==\"exon\"' >merged_lncRNA.combined.longest.exon.gtf cut full length lncRNA transcripts into bins: bin_size_30, step_size_15 (1)deal with transcirpts longer than 30bp awk 'BEGIN{ OFS=\"\\t\" } ($5-$4)>30 {split($10,a,\"\\\"\"); \\ for(i=0;i<=($5-$4-30)/15;i++) {print $1,$4+i*15, $4+i*15+30,a[2]\"__\"$4+i*15\"__\"$4+i*15+30,$6,$7} \\ print $1, $4+(i+1)*15,$5,a[2]\"__\"$4+(i+1)*15\"__\"$5,$6,$7}' \\ merged_lncRNA.combined.longest.exon.gtf |awk '$3>$2' >merged_lncRNA.combined.longest.exon.bin30.bed (2)deal with transcirpts no longer than 30bp awk 'BEGIN{ OFS=\"\\t\" } ($5-$4)<=30 {split($10,a,\"\\\"\");print $1,$4,$5,a[2]\"__\"$4\"__\"$5,$6,$7}' \\ merged_lncRNA.combined.longest.exon.gtf | awk '$3>$2' > shorterthan30.bed (3)concatenate two bed files generated abovely cat merged_lncRNA.combined.longest.exon.bin30.bed shorterthan30.bed|sort -k1,1 -k2,2n -k3,3 >merged_lncRNA.combined.longest.exon.bin30.all.bed awk 'BEGIN{FS=OFS=\"\\t\"}{print $1,$2,$3,$4,1,$6}' merged_lncRNA.combined.longest.exon.bin30.all.bed > foo bedToGenePred foo /dev/stdout | genePredToGtf -source=merged_lncRNA_bin file /dev/stdin merged_lncRNA.combined.longest.exon.bin30.all.gtf for i in `ls ./gtf`; do j=${i%.*}; echo $j gffread --bed ./gtf/$j.gtf -o ./binned/$j.bed awk 'NR==FNR {split($10,m,\"\\\"\");split($12,n,\"\\\"\");D[m[2]]=n[2]} \\ NR>FNR {split($11,ex,\",\");for (k in ex) len[$4]+=ex[k]; b[D[$4]] = len[$4] > a[D[$4]] ? $4 : b[D[$4]]; a[D[$4]] = len[$4] > a[D[$4]] ? len[$4] : a[D[$4]] } \\ END { OFS = \"\\t\"; for(x in a) print x, a[x],b[x]}' ./gtf/$j.gtf ./binned/$j.bed > ./binned/$j.longest.tran awk '{print $3}' ./binned/$j.longest.tran | grep -Ff - ./gtf/$j.gtf | awk '$3==\"exon\"' > ./binned/$j.longest.exon.gtf awk 'BEGIN{ OFS=\"\\t\" } ($5-$4)>30 {split($10,a,\"\\\"\"); \\ for(i=0;i<=($5-$4-30)/15;i++) {print $1,$4+i*15, $4+i*15+30,a[2]\"__\"$4+i*15\"__\"$4+i*15+30,$6,$7} \\ print $1, $4+(i+1)*15,$5,a[2]\"__\"$4+(i+1)*15\"__\"$5,$6,$7}' \\ ./binned/$j.longest.exon.gtf | awk '$3>$2' > ./binned/$j.longest.exon.bin30.bed awk 'BEGIN{ OFS=\"\\t\" } ($5-$4)<=30 {split($10,a,\"\\\"\");print $1,$4,$5,a[2]\"__\"$4\"__\"$5,$6,$7}' \\ ./binned/$j.longest.exon.gtf | awk '$3>$2' > ./binned/$j.shorterthan30.bed cat ./binned/$j.longest.exon.bin30.bed ./binned/$j.shorterthan30.bed | sort -k1,1 -k2,2n -k3,3 > ./binned/$j.longest.exon.bin30.all.bed awk 'BEGIN{FS=OFS=\"\\t\"}{print $1,$2,$3,$4,1,$6}' ./binned/$j.longest.exon.bin30.all.bed > ./binned/$j.foo bedToGenePred ./binned/$j.foo /dev/stdout | genePredToGtf -source=${j}_bin file /dev/stdin ./binned/$j.longest.exon.bin30.all.gtf done","title":"Prepare Genome and Annotation"},{"location":"prepare_genome_annotation/#prepare-genome-and-annotation","text":"Sequence Annotation Index files","title":"Prepare Genome and Annotation"},{"location":"prepare_genome_annotation/#genome-hg38","text":"","title":"Genome hg38"},{"location":"prepare_genome_annotation/#sequence","text":"","title":"Sequence"},{"location":"prepare_genome_annotation/#download-from-gencode-v27","text":"[ ]located in folder:","title":"download from gencode v27"},{"location":"prepare_genome_annotation/#located-in-folder-sequence","text":"mkdir sequence cd sequence wget wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/GRCh38.p10.genome.fa.gz","title":"located in folder: sequence/"},{"location":"prepare_genome_annotation/#decompression","text":"gzip -d GRCh38.p10.genome.fa.gz","title":"Decompression"},{"location":"prepare_genome_annotation/#parse-genome","text":"samtools faidx GRCh38.p10.genome.fa cut -f1,2 GRCh38.p10.genome.fa.fai > hg38.chrom.sizes","title":"parse genome"},{"location":"prepare_genome_annotation/#index","text":"","title":"Index"},{"location":"prepare_genome_annotation/#build-by-bowtie2-and-star","text":"[ ]located in folder:","title":"build by bowtie2 and STAR"},{"location":"prepare_genome_annotation/#located-in-folder-index","text":"using bowtie2 mkdir bowtie2_hg38_index cd bowtie2_hg38_index bowtie2-build ../sequence/GRCh38.p10.genome.fa GRCh38.p10 using STAR mkdir ../STAR_hg38_index cd ../STAR_hg38_index STAR --runMode genomeGenerate --runThreadN 15 --genomeDir . --genomeFastaFiles ../sequence/GRCh38.p10.genome.fa","title":"located in folder: index/"},{"location":"prepare_genome_annotation/#annotation-files-for-genome-hg38","text":"provider: GENCODE and other projects format: gtf and gff","title":"Annotation files for genome hg38"},{"location":"prepare_genome_annotation/#statistics","text":"RNA_type gene_num transcrips_num source file Date Download/Processed Note allGenes 58,288 200,401 Gencode27 gencode.v27.annotation.gtf / gencode.v27.annotation.gff 2018.5.4 D/D rRNA 544 544 Gencode27 rRNA.gencode27.gtf / rRNA.gencode27.gff 2018.5.4 P/P miRNA 1,881 1,881 Gencode27 miRNA.gencode27.gtf / miRNA.gencode27.gff 2018.5.4 P/P piRNA 812,347 812,347 piRBase piRNA.piRBase.hg38.gtf / piRNA.piRBase.hg38.gff 2018.5.4 D/D snoRNA 943 955 Gencode27(misc_RNA) snoRNA.gencode27.gtf / snoRNA.gencode27.gtf 2018.5.4 P/P snRNA 1,900 1,900 Gencode27 snRNA.gencode27.gtf / snRNA.gencode27.gtf 2018.5.4 P/P srpRNA 680 680 Gencode27(misc_RNA) srpRNA.gencode27.gtf / srpRNA.gencode27.gff 2018.5.4 P/P tRNA 649 649 Gencode27(predicted tRNA) tRNA.gencode27.gtf / tRNA.gencode27.gff 2018.5.4 D/D lncRNA 15,778 27,908 Gencode27(lncRNA) lncRNA.gencode27.gtf / lncRNA.gencode27.gff 2018.5.4 D/D lncRNA 96,308 172,216 NONCODEv5 lncRNA.NONCODEv5.hg38.gtf / lncRNA.NONCODEv5.hg38.gff 2018.5.4 P/P lncRNA 63,427 174,657 mitranscritome lncRNA.mitranscriptome.v2.hg38.gtf / lncRNA.mitranscriptome.v2.hg38.gff 2018.5.4 P/P tucp 3,711 11,244 mitranscritome tucp.mitranscriptome.v2.hg38.gtf / tucp.mitranscriptome.v2.hg38.gff 2018.5.4 P/P lncRNA 131,683 342,295 Gencode27+NONCODEv5+ MiTranscriptome+NC2017 merged_lncRNA.combined.gtf / merged_lncRNA.combined.gff 2018.5.4 P/P mRNA 19,836 80,930 Gencode27(protein_coding) mRNA.gencode27.gtf / mRNA.gencode27.gff 2018.5.4 P/P","title":"statistics"},{"location":"prepare_genome_annotation/#pre-process-annotaion","text":"","title":"pre-process annotaion"},{"location":"prepare_genome_annotation/#download-gencode-v27-annotations","text":"wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.annotation.gtf.gz wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.annotation.gff3.gz wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.long_noncoding_RNAs.gtf.gz wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.long_noncoding_RNAs.gff3.gz wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.tRNAs.gtf.gz wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.tRNAs.gff3.gz","title":"download gencode v27 annotations"},{"location":"prepare_genome_annotation/#decompression_1","text":"gzip -d *","title":"Decompression"},{"location":"prepare_genome_annotation/#parse-annotations","text":"gtf=gencode.v27.annotation.gtf for i in rRNA snRNA snoRNA srpRNA miRNA vaultRNA Y_RNA; do grep \"gene_type \\\"$i\\\"\" $gtf > $i.gencode27.gtf gffread -E $i.gencode27.gtf -o- > $i.gencode27.gff done; grep \"gene_type \\\"protein_coding\\\"\" $gtf | grep -v Selenocysteine > mRNA.gencode27.gtf grep \"RN7SL\" $gtf > srpRNA.gencode27.gtf grep 'Y_RNA' $gtf > Y_RNA.gencode27.gtf for i in mRNA srpRNA Y_RNA; do gffread -E $i.gencode27.gtf -o- > $i.gencode27.gff done; mv gencode.v27.tRNAs.gtf tRNA.gencode27.gtf mv gencode.v27.tRNAs.gff3 tRNA.gencode27.gff mv gencode.v27.long_noncoding_RNAs.gtf lncRNA.gencode27.gtf mv gencode.v27.long_noncoding_RNAs.gff3 lncRNA.gencode27.gff mv gencode.v27.annotation.gff3 gencode.v27.annotation.gff","title":"parse annotations"},{"location":"prepare_genome_annotation/#download-pirna-from-pirbase","text":"","title":"download piRNA from piRBase"},{"location":"prepare_genome_annotation/#downlaod-lncrna-from-noncodehttpwwwnoncodeorg-mitranscriptomehttpmitranscriptomeorg-and-yang-yangs-nc-paper","text":"wget http://mitranscriptome.org/download/mitranscriptome.gtf.tar.gz wget http://www.noncode.org/datadownload/NONCODEv5_human_hg38_lncRNA.gtf.gz wget https://media.nature.com/original/nature-assets/ncomms/2017/170213/ncomms14421/extref/ncomms14421-s3.txt","title":"downlaod lncRNA from NONCODE(http://www.noncode.org/), mitranscriptome(http://mitranscriptome.org/), and Yang Yang's NC paper"},{"location":"prepare_genome_annotation/#decompression_2","text":"tar zxvf mitranscriptome.gtf.tar.gz gzip -d mitranscriptome.v2.gtf.gz","title":"Decompression"},{"location":"prepare_genome_annotation/#parse-and-convert","text":"wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz gzip -d hg19ToHg38.over.chain.gz cd mitranscriptome.gtf gzip -d mitranscriptome.v2.gtf.gz gtfToGenePred -genePredExt mitranscriptome.v2.gtf mitranscriptome.v2.gp liftOver -genePred mitranscriptome.v2.gp ../hg19ToHg38.over.chain mitranscriptome.v2.hg38.gp unmapped.gtf genePredToGtf -utr -source=mitranscriptome file mitranscriptome.v2.hg38.gp mitranscriptome.v2.hg38.gtf gffread -E mitranscriptome.v2.hg38.gtf -o- > mitranscriptome.v2.hg38.gff mv ../mitranscriptome.gtf ../mitranscriptome cd .. # filter out lncRNA cd mitranscriptome.gtf zcat mitranscriptome.v2.gtf.gz | grep -e 'tcat \\\"lncrna\\\"' > lncRNA.mitranscriptome.v2.gtf # liftOver hg19 to hg38 gtfToGenePred -genePredExt lncRNA.mitranscriptome.v2.gtf lncRNA.mitranscriptome.v2.gp liftOver -genePred lncRNA.mitranscriptome.v2.gp ../hg19ToHg38.over.chain lncRNA.mitranscriptome.v2.hg38.gp unmapped.gtf genePredToGtf -utr -source=mitranscriptome file lncRNA.mitranscriptome.v2.hg38.gp lncRNA.mitranscriptome.v2.hg38.gtf gffread -E lncRNA.mitranscriptome.v2.hg38.gtf -o- > lncRNA.mitranscriptome.v2.hg38.gff # filter out tucp zcat mitranscriptome.v2.gtf.gz | grep -e 'tcat \\\"tucp\\\"' | awk '$7!=\".\"' > tucp.mitranscriptome.v2.gtf # liftOver hg19 to hg38 gtfToGenePred -genePredExt tucp.mitranscriptome.v2.gtf tucp.mitranscriptome.v2.gp liftOver -genePred tucp.mitranscriptome.v2.gp ../hg19ToHg38.over.chain tucp.mitranscriptome.v2.hg38.gp unmapped.gtf genePredToGtf -utr -source=mitranscriptome file tucp.mitranscriptome.v2.hg38.gp tucp.mitranscriptome.v2.hg38.gtf gffread -E tucp.mitranscriptome.v2.hg38.gtf -o- > tucp.mitranscriptome.v2.hg38.gff cd .. gtfToGenePred -genePredExt ncomms14421-s3.txt lncRNA.lulab_ncomms14421.gp liftOver -genePred lncRNA.lulab_ncomms14421.gp hg19ToHg38.over.chain lncRNA.lulab_ncomms14421.hg38.gp unmapped.gtf genePredToGtf -utr -source=lulab_ncomms14421 file lncRNA.lulab_ncomms14421.hg38.gp lncRNA.lulab_ncomms14421.hg38.gtf gffread -E lncRNA.lulab_ncomms14421.hg38.gtf -o- > lncRNA.lulab_ncomms14421.hg38.gff cd mitranscriptome.gtf mv * .. cd mitranscriptome mv * .. rm -rf mitranscriptome mitranscriptome.gtf mitranscriptome.gtf.tar.gz rm -rf *.gp unmapped.gtf mv NONCODEv5_human_hg38_lncRNA.gtf lncRNA.NONCODEv5.hg38.gtf","title":"parse and convert"},{"location":"prepare_genome_annotation/#merge-lncrna-annotations","text":"gffcompare -o merged_lncRNA -s ../sequence/GRCh38.p10.genome.fa lncRNA.NONCODEv5.hg38.gtf lncRNA.mitranscriptome.v2.hg38.gtf lncRNA.gencode27.gtf lncRNA.lulab_ncomms14421.hg38.gtf gffread -E merged_lncRNA.combined.gtf -o- > merged_lncRNA.combined.gff","title":"merge lncRNA annotations"},{"location":"prepare_genome_annotation/#mkdir-gtf-gff","text":"cd .. mkdir gtf gff mv gencode/*.gtf gtf mv gencode/*.gff gff","title":"mkdir gtf gff"},{"location":"prepare_genome_annotation/#establish-indexes","text":"if [ \"$1\" = \"0\" ]; then for i in ${RNAs[@]} ; do echo \"start $i.gtf:\" rsem-prepare-reference --gtf $gtf/$i.gtf --bowtie2 $hg38 RNA_index/$i echo \"$i finished.\" done","title":"establish indexes"},{"location":"prepare_genome_annotation/#cut-lncrna-into-bins","text":"","title":"cut lncRNA into bins"},{"location":"prepare_genome_annotation/#convert-combined-gtf-to-combined-bed","text":"gffread --bed merged_lncRNA.combined.gtf -o merged_lncRNA.combined.bed","title":"convert combined gtf to combined bed"},{"location":"prepare_genome_annotation/#grep-the-longest-transciprt-for-each-lncrna-gene-and-calculate-its-length","text":"awk 'NR==FNR {split($10,m,\"\\\"\");split($12,n,\"\\\"\");D[m[2]]=n[2]} \\ NR>FNR {split($11,ex,\",\");for (k in ex) len[$4]+=ex[k]; b[D[$4]] = len[$4] > a[D[$4]] ? $4 : b[D[$4]]; a[D[$4]] = len[$4] > a[D[$4]] ? len[$4] : a[D[$4]] } \\ END { OFS = \"\\t\"; for(x in a) print x, a[x],b[x]}' merged_lncRNA.combined.gtf merged_lncRNA.combined.bed >merged_lncRNA.combined.longest.tran","title":"grep the longest transciprt for each lncRNA gene and calculate its length"},{"location":"prepare_genome_annotation/#grep-the-exons-of-the-longest-transciprts","text":"awk '{print $3}' merged_lncRNA.combined.longest.tran| grep -Ff - merged_lncRNA.combined.gtf|awk '$3==\"exon\"' >merged_lncRNA.combined.longest.exon.gtf","title":"grep the exons of the longest transciprts"},{"location":"prepare_genome_annotation/#cut-full-length-lncrna-transcripts-into-bins-bin_size_30-step_size_15","text":"","title":"cut full length lncRNA transcripts into bins: bin_size_30, step_size_15"},{"location":"prepare_genome_annotation/#1deal-with-transcirpts-longer-than-30bp","text":"awk 'BEGIN{ OFS=\"\\t\" } ($5-$4)>30 {split($10,a,\"\\\"\"); \\ for(i=0;i<=($5-$4-30)/15;i++) {print $1,$4+i*15, $4+i*15+30,a[2]\"__\"$4+i*15\"__\"$4+i*15+30,$6,$7} \\ print $1, $4+(i+1)*15,$5,a[2]\"__\"$4+(i+1)*15\"__\"$5,$6,$7}' \\ merged_lncRNA.combined.longest.exon.gtf |awk '$3>$2' >merged_lncRNA.combined.longest.exon.bin30.bed","title":"(1)deal with transcirpts longer than 30bp"},{"location":"prepare_genome_annotation/#2deal-with-transcirpts-no-longer-than-30bp","text":"awk 'BEGIN{ OFS=\"\\t\" } ($5-$4)<=30 {split($10,a,\"\\\"\");print $1,$4,$5,a[2]\"__\"$4\"__\"$5,$6,$7}' \\ merged_lncRNA.combined.longest.exon.gtf | awk '$3>$2' > shorterthan30.bed","title":"(2)deal with transcirpts no longer than 30bp"},{"location":"prepare_genome_annotation/#3concatenate-two-bed-files-generated-abovely","text":"cat merged_lncRNA.combined.longest.exon.bin30.bed shorterthan30.bed|sort -k1,1 -k2,2n -k3,3 >merged_lncRNA.combined.longest.exon.bin30.all.bed awk 'BEGIN{FS=OFS=\"\\t\"}{print $1,$2,$3,$4,1,$6}' merged_lncRNA.combined.longest.exon.bin30.all.bed > foo bedToGenePred foo /dev/stdout | genePredToGtf -source=merged_lncRNA_bin file /dev/stdin merged_lncRNA.combined.longest.exon.bin30.all.gtf for i in `ls ./gtf`; do j=${i%.*}; echo $j gffread --bed ./gtf/$j.gtf -o ./binned/$j.bed awk 'NR==FNR {split($10,m,\"\\\"\");split($12,n,\"\\\"\");D[m[2]]=n[2]} \\ NR>FNR {split($11,ex,\",\");for (k in ex) len[$4]+=ex[k]; b[D[$4]] = len[$4] > a[D[$4]] ? $4 : b[D[$4]]; a[D[$4]] = len[$4] > a[D[$4]] ? len[$4] : a[D[$4]] } \\ END { OFS = \"\\t\"; for(x in a) print x, a[x],b[x]}' ./gtf/$j.gtf ./binned/$j.bed > ./binned/$j.longest.tran awk '{print $3}' ./binned/$j.longest.tran | grep -Ff - ./gtf/$j.gtf | awk '$3==\"exon\"' > ./binned/$j.longest.exon.gtf awk 'BEGIN{ OFS=\"\\t\" } ($5-$4)>30 {split($10,a,\"\\\"\"); \\ for(i=0;i<=($5-$4-30)/15;i++) {print $1,$4+i*15, $4+i*15+30,a[2]\"__\"$4+i*15\"__\"$4+i*15+30,$6,$7} \\ print $1, $4+(i+1)*15,$5,a[2]\"__\"$4+(i+1)*15\"__\"$5,$6,$7}' \\ ./binned/$j.longest.exon.gtf | awk '$3>$2' > ./binned/$j.longest.exon.bin30.bed awk 'BEGIN{ OFS=\"\\t\" } ($5-$4)<=30 {split($10,a,\"\\\"\");print $1,$4,$5,a[2]\"__\"$4\"__\"$5,$6,$7}' \\ ./binned/$j.longest.exon.gtf | awk '$3>$2' > ./binned/$j.shorterthan30.bed cat ./binned/$j.longest.exon.bin30.bed ./binned/$j.shorterthan30.bed | sort -k1,1 -k2,2n -k3,3 > ./binned/$j.longest.exon.bin30.all.bed awk 'BEGIN{FS=OFS=\"\\t\"}{print $1,$2,$3,$4,1,$6}' ./binned/$j.longest.exon.bin30.all.bed > ./binned/$j.foo bedToGenePred ./binned/$j.foo /dev/stdout | genePredToGtf -source=${j}_bin file /dev/stdin ./binned/$j.longest.exon.bin30.all.gtf done","title":"(3)concatenate two bed files generated abovely"},{"location":"quality_control/","text":"","title":"Quality Control"},{"location":"requirements/","text":"Requirements Software Python 3.6 (miniconda) Python 2.7 (miniconda) Java 8 R 3.4 (https://mran.microsoft.com/download) Configure conda channels conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/mro/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ Install Python packages using conda conda install -y numpy scipy scikit-learn conda install -y pandas matplotlib seaborn conda install -y tqdm snakemake h5py bokeh conda install -y umap jinja2 pip install mlxtend pip install flask Flask-AutoIndex Install Bioconda packages List of all available Bioconda packages: (https://bioconda.github.io/recipes.html) conda install -y bedtools samtools star subread bowtie2 conda install -y rsem bamtools cutadapt picard gffread gffcompare conda install -y ucsc-bedtogenepred ucsc-genepredtogtf ucsc-bedgraphtobigwig ucsc-bigwigtobedgraph conda install -y htseq fastx_toolkit biopython rpy2 conda install -y flexbar Install Ubuntu packages sudo apt-get install -y gzip pigz openjdk-8-jdk libgraphviz-dev uuid-dev zlib1g-dev libpng-dev gawk Install R packages Install by running the following code in an R interactive session: options(\"repos\" = c(CRAN=\"https://mirrors.tuna.tsinghua.edu.cn/CRAN/\")) options(BioC_mirror=\"https://mirrors.tuna.tsinghua.edu.cn/bioconductor\") # From CRAN install.packages(c('devtools', 'sva', 'VGAM', 'argparse', 'magrittr', 'readr', 'mvoutlier', 'ggpubr', 'fastqr')) # From Bioconductor source('https://bioconductor.org/biocLite.R') biocLite(c('SingleCellExperiment', 'scater', 'scran', 'SCnorm', 'EDASeq', 'RUVSeq', 'DESeq2', 'edgeR', 'sva', 'apeglm')) # From R-forge install.packages('countreg', repos = c('http://R-Forge.R-project.org', 'https://mirrors.tuna.tsinghua.edu.cn/CRAN/'), dep = TRUE) # From GitHub library(devtools) install_github('ChenMengjie/VIPER') install_github('kassambara/easyGgplot2') install_github(\"Vivianstats/scImpute\") install_github(\"hemberg-lab/scRNA.seq.funcs\") Other packages find_circ 1.2 (depends on Python 2.7) GTFTools (depends on Python) Prinseq (requires Perl) Singularity Build image singularity build singularity/exseek.img singularity/Singularity Make wrappers for singularity executables bin/make_singularity_wrappers.py \\ --image ~/singularity/simg/exseek.simg \\ --list-file singularity/exports.txt \\ --singularity-path $(which singularity) \\ -o ~/singularity/wrappers/exseek Add wrappers to PATH export PATH=\"$HOME/singularity/wrappers/exseek:$PATH\" Build Pykent wget -O tools/ucsc-tools.tar.gz http://hgdownload.soe.ucsc.edu/admin/exe/userApps.src.tgz tar -C tools -zxf tools/ucsc-tools.tar.gz (cd tools/userApps/kent/src/htslib/ CFLAGS=\"-fPIC -DUCSC_CRAM=0 -DKNETFILE_HOOKS=1\" ./configure make ) (cd tools/userApps/kent/src/lib/ echo ' %.o: %.c ${CC} -fPIC ${COPT} ${CFLAGS} ${HG_DEFS} ${LOWELAB_DEFS} ${HG_WARN} ${HG_INC} ${XINC} -o $@ -c $< $(MACHTYPE)/libjkweb.so: $(O) $(MACHTYPE) gcc -fPIC -shared -o $(MACHTYPE)/libjkweb.so $(O) -Wl,-z,defs -L../htslib -lhts -lm -lz -lpthread -lpng -lcrypto -lssl -luuid ' > makefile make x86_64/libjkweb.so ) cp tools/userApps/kent/src/lib/x86_64/libjkweb.so lib/","title":"Requirements"},{"location":"requirements/#requirements","text":"","title":"Requirements"},{"location":"requirements/#software","text":"Python 3.6 (miniconda) Python 2.7 (miniconda) Java 8 R 3.4 (https://mran.microsoft.com/download)","title":"Software"},{"location":"requirements/#configure-conda-channels","text":"conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/mro/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/","title":"Configure conda channels"},{"location":"requirements/#install-python-packages-using-conda","text":"conda install -y numpy scipy scikit-learn conda install -y pandas matplotlib seaborn conda install -y tqdm snakemake h5py bokeh conda install -y umap jinja2 pip install mlxtend pip install flask Flask-AutoIndex","title":"Install Python packages using conda"},{"location":"requirements/#install-bioconda-packages","text":"List of all available Bioconda packages: (https://bioconda.github.io/recipes.html) conda install -y bedtools samtools star subread bowtie2 conda install -y rsem bamtools cutadapt picard gffread gffcompare conda install -y ucsc-bedtogenepred ucsc-genepredtogtf ucsc-bedgraphtobigwig ucsc-bigwigtobedgraph conda install -y htseq fastx_toolkit biopython rpy2 conda install -y flexbar","title":"Install Bioconda packages"},{"location":"requirements/#install-ubuntu-packages","text":"sudo apt-get install -y gzip pigz openjdk-8-jdk libgraphviz-dev uuid-dev zlib1g-dev libpng-dev gawk","title":"Install Ubuntu packages"},{"location":"requirements/#install-r-packages","text":"Install by running the following code in an R interactive session: options(\"repos\" = c(CRAN=\"https://mirrors.tuna.tsinghua.edu.cn/CRAN/\")) options(BioC_mirror=\"https://mirrors.tuna.tsinghua.edu.cn/bioconductor\") # From CRAN install.packages(c('devtools', 'sva', 'VGAM', 'argparse', 'magrittr', 'readr', 'mvoutlier', 'ggpubr', 'fastqr')) # From Bioconductor source('https://bioconductor.org/biocLite.R') biocLite(c('SingleCellExperiment', 'scater', 'scran', 'SCnorm', 'EDASeq', 'RUVSeq', 'DESeq2', 'edgeR', 'sva', 'apeglm')) # From R-forge install.packages('countreg', repos = c('http://R-Forge.R-project.org', 'https://mirrors.tuna.tsinghua.edu.cn/CRAN/'), dep = TRUE) # From GitHub library(devtools) install_github('ChenMengjie/VIPER') install_github('kassambara/easyGgplot2') install_github(\"Vivianstats/scImpute\") install_github(\"hemberg-lab/scRNA.seq.funcs\")","title":"Install R packages"},{"location":"requirements/#other-packages","text":"find_circ 1.2 (depends on Python 2.7) GTFTools (depends on Python) Prinseq (requires Perl)","title":"Other packages"},{"location":"requirements/#singularity","text":"","title":"Singularity"},{"location":"requirements/#build-image","text":"singularity build singularity/exseek.img singularity/Singularity","title":"Build image"},{"location":"requirements/#make-wrappers-for-singularity-executables","text":"bin/make_singularity_wrappers.py \\ --image ~/singularity/simg/exseek.simg \\ --list-file singularity/exports.txt \\ --singularity-path $(which singularity) \\ -o ~/singularity/wrappers/exseek","title":"Make wrappers for singularity executables"},{"location":"requirements/#add-wrappers-to-path","text":"export PATH=\"$HOME/singularity/wrappers/exseek:$PATH\"","title":"Add wrappers to PATH"},{"location":"requirements/#build-pykent","text":"wget -O tools/ucsc-tools.tar.gz http://hgdownload.soe.ucsc.edu/admin/exe/userApps.src.tgz tar -C tools -zxf tools/ucsc-tools.tar.gz (cd tools/userApps/kent/src/htslib/ CFLAGS=\"-fPIC -DUCSC_CRAM=0 -DKNETFILE_HOOKS=1\" ./configure make ) (cd tools/userApps/kent/src/lib/ echo ' %.o: %.c ${CC} -fPIC ${COPT} ${CFLAGS} ${HG_DEFS} ${LOWELAB_DEFS} ${HG_WARN} ${HG_INC} ${XINC} -o $@ -c $< $(MACHTYPE)/libjkweb.so: $(O) $(MACHTYPE) gcc -fPIC -shared -o $(MACHTYPE)/libjkweb.so $(O) -Wl,-z,defs -L../htslib -lhts -lm -lz -lpthread -lpng -lcrypto -lssl -luuid ' > makefile make x86_64/libjkweb.so ) cp tools/userApps/kent/src/lib/x86_64/libjkweb.so lib/","title":"Build Pykent"},{"location":"run_pipeline/","text":"Generate sequential mapping snakefile snakemake --snakefile snakemake/prepare_genome.snakemake --configfile snakemake/config.yaml --rerun-incomplete -k SciRep bin/generate_snakemake.py sequential_mapping --rna-types rRNA,miRNA,piRNA,Y_RNA,srpRNA,tRNA,snRNA,snoRNA,lncRNA,mRNA,tucpRNA \\ -o snakemake/sequential_mapping.snakemake snakemake --snakefile snakemake/mapping_small.snakemake --configfile config/scirep.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" snakemake --snakefile snakemake/expression_matrix.snakemake --configfile config/scirep.yaml --rerun-incomplete -k snakemake --snakefile snakemake/feature_selection.snakemake --configfile config/scirep.yaml --rerun-incomplete -k snakemake --snakefile snakemake/feature_selection.snakemake --configfile config/scirep.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" snakemake --snakefile snakemake/call_domains_long.snakemake --configfile config/scirep.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" snakemake --snakefile snakemake/bigwig.snakemake --configfile config/scirep.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" export PATH=$PWD/singularity/wrappers:$PATH PATH=\"$PWD/singularity/wrappers:$PATH\" snakemake --snakefile snakemake/normalization.snakemake --configfile config/scirep.yaml --rerun-incomplete -k bin/report.py visualize_domains --sample-ids-file data/scirep/sample_ids.txt \\ --output-dir output/scirep \\ --count-matrix output/scirep/count_matrix/domains_combined.txt \\ --features output/scirep/feature_selection/filter.scimpute_count.Norm_CPM.Batch_RUV.domains_combined/Normal-CRC/random_forest.10.robust/features.txt \\ --chrom-sizes genome/hg38/chrom_sizes/transcriptome_genome \\ --output-file tmp/visualize_domains.pdf bin/feature_selection.py calculate_clustering_score \\ --matrix output/scirep/matrix_processing/filter.scimpute_count.Norm_null.domains_combined.txt \\ --sample-classes data/scirep/sample_classes.txt --transpose snakemake --snakefile snakemake/evaluate_features.snakemake --configfile config/scirep.yaml Lulab HCC /Share/home/caojingyi/exRNA/process/18.new_hcc_lulab/Snakefile snakemake --snakefile snakemake/mapping_small.snakemake --configfile config/lulab_hcc.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" \\ snakemake --snakefile snakemake/mapping_small.snakemake --configfile config/lulab_hcc.yaml --rerun-incomplete -k snakemake --snakefile snakemake/expression_matrix.snakemake --configfile config/lulab_hcc.yaml --rerun-incomplete -k snakemake --snakefile snakemake/normalization.snakemake --configfile config/lulab_hcc.yaml --rerun-incomplete -k snakemake --snakefile snakemake/feature_selection.snakemake --configfile config/lulab_hcc.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" snakemake --snakefile snakemake/evaluate_features.snakemake --configfile config/lulab_hcc.yaml exoRBase # subsample reads [ -d \"data/exorbase_test/fastq\" ] || mkdir -p \"data/exorbase_test/fastq\" cp data/exorbase/*.txt data/exorbase_test for f in data/exorbase/fastq/*.fastq;do sample_id=$(basename $f) sample_id=${sample_id/.fastq/} echo data/exorbase_test/fastq/${sample_id}.fastq head -n 400000 $f > data/exorbase_test/fastq/${sample_id}.fastq done snakemake --snakefile snakemake/mapping_long.snakemake --rerun-incomplete -k --configfile config/exorbase.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" -j60 snakemake --snakefile snakemake/normalization.snakemake --configfile config/exorbase.yaml --rerun-incomplete -k snakemake --snakefile snakemake/feature_selection.snakemake --configfile config/exorbase.yaml --rerun-incomplete -k TCGA miRNA-seq (CRC) snakemake --snakefile snakemake/bam_to_fastx.snakemake --rerun-incomplete -k --configfile config/tcga_crc.yaml snakemake --snakefile snakemake/mapping_small.snakemake --rerun-incomplete -k --configfile config/tcga_crc.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" TCGA miRNA-seq (HCC) snakemake --snakefile snakemake/bam_to_fastx.snakemake --rerun-incomplete -k --configfile config/tcga_hcc.yaml snakemake --snakefile snakemake/mapping_small.snakemake --rerun-incomplete -k --configfile config/tcga_hcc.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" snakemake --snakefile snakemake/bigwig.snakemake --configfile config/tcga_hcc.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" snakemake --snakefile snakemake/call_domains_long.snakemake --configfile config/tcga_hcc.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" GSE113994 (Healthy, cfRNA, PNAS 2018) snakemake --snakefile snakemake/quality_control.snakemake --rerun-incomplete -k --configfile config/GSE113994.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" snakemake --snakefile snakemake/mapping_small.snakemake --rerun-incomplete -k --configfile config/GSE113994.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" GSE45722 (Healthy, exosome, BMC Genomics 2013) snakemake --snakefile snakemake/quality_control.snakemake --rerun-incomplete -k --configfile config/GSE45722.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" -j40 snakemake --snakefile snakemake/mapping_small.snakemake --rerun-incomplete -k --configfile config/GSE45722.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" -j40 GSE114711 (Healthy, exosome, Scientific Reports 2018) snakemake --snakefile snakemake/quality_control.snakemake --rerun-incomplete -k --configfile config/GSE114711.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" -j40 snakemake --snakefile snakemake/mapping_small.snakemake --rerun-incomplete -k --configfile config/GSE114711.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" -j40 Gini index comparison between exRNA and TCGA for dataset in 'scirep' 'tcga_crc' 'tcga_hcc' 'GSE114711' 'GSE45722';do mkdir -p \"output/${dataset}/analysis\" echo bin/extract_bigwig.py abundant_rna_coverage_matrix \\ --matrix output/${dataset}/count_matrix/transcript.txt \\ --bigwig-pattern \"output/${dataset}/tbigwig/{sample_id}.{gene_type}.bigWig\" -n 100 \\ -o output/${dataset}/analysis/abundant_rna_coverage_matrix.h5 done Integrated dataset SciRep2016, GSE45722, GSE114711 Copy files dataset='exosome_small' mkdir -p data/${dataset} sources=(scirep GSE45722 GSE114711) # sample_ids.txt cat data/scirep/sample_ids.txt data/GSE45722/sample_ids.txt \\ data/GSE114711/sample_ids.txt > data/${dataset}/sample_ids.txt # sample_classes.txt { awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,$2}' data/scirep/sample_classes.txt awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,\"Healthy Control\"}' data/GSE45722/sample_classes.txt awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,\"Healthy Control\"}' data/GSE114711/sample_classes.txt } > data/${dataset}/sample_classes.txt # batch_info.txt { echo -e 'sample_id\\tpublication' awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,\"scirep\"}' data/scirep/sample_classes.txt awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,\"GSE45722_healthy\"}' data/GSE45722/sample_classes.txt awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,\"GSE114711_healthy\"}' data/GSE114711/sample_classes.txt } > data/exosome_small/batch_info.txt # count_matrix/domains_long.txt mkdir -p output/${dataset}/count_matrix bin/preprocess.py merge_data_frames \\ -i output/scirep/count_matrix/transcript.txt \\ -i output/GSE45722/count_matrix/transcript.txt \\ -i output/GSE114711/count_matrix/transcript.txt \\ --on feature --fillna 0 \\ -o output/${dataset}/count_matrix/transcript.txt # domains_by_sample/20/05 mkdir -p output/${dataset}/domains_by_sample/20/05 rsync -ra output/scirep/domains_by_sample/20/05/*.bed output/${dataset}/domains_by_sample/20/05 rsync -ra output/GSE45722/domains_by_sample/20/05/*.bed output/${dataset}/domains_by_sample/20/05 rsync -ra output/GSE114711/domains_by_sample/20/05/*.bed output/${dataset}/domains_by_sample/20/05 # tbed mkdir -p output/${dataset}/tbed mkdir -p output/${dataset}/gbed for d in ${sources[@]};do rsync -rav output/$d/tbed/ output/${dataset}/tbed rsync -rav output/$d/gbed/ output/${dataset}/gbed done Analysis bin/exseek.py call_domains -d exosome_small Data exoRBase [ -d data/exorbase/fastq ] || mkdir -p data/exorbase/fastq ln -f -s /BioII/lulab_b/shared/projects/exRNA/published_exRNA/exosome_exoRBase/exosome_GSE100063_CRC/fastq/*.fastq data/exorbase/fastq ln -f -s /BioII/lulab_b/caojingyi/exoRBase/fastq/HCC/*.fastq data/exorbase/fastq ln -f -s /BioII/lulab_b/caojingyi/exoRBase/fastq/Normal/*.fastq data/exorbase/fastq ln -f -s /BioII/lulab_b/shared/projects/exRNA/published_exRNA/exosome_exoRBase/exosome_GSE100232_PAAD/fastq/*.fastq data/exorbase/fastq ln -f -s /BioII/lulab_b/shared/projects/exRNA/published_exRNA/exosome_exoRBase/exosome_GSE99985_CHD/fastq/*.fastq data/exorbase/fastq ln -f -s /BioII/lulab_b/caojingyi/exoRBase/fastq/*.fastq data/exorbase/fastq ls data/exorbase/fastq | cut -d'_' -f1 | sort | uniq > data/exorbase/sample_ids.txt ln -f -s /BioII/zhuyumin/exLocator/exosome_SR2018_GSE114711/1.fastq/*.fastq data/GSE114711/fastq Spike-in Small RNA-seq /BioII/lulab_b/wangsiqi/exRNA/exRNA-panel/NEB/03.1811_T4PNK/ExiSEQ-spikeIn cp /BioII/lulab_b/wangsiqi/exRNA/exRNA-panel/NEB/03.1811_T4PNK/ExiSEQ-spikeIn/ExiSEQ-spikeIn.fa genome/hg38/fasta/spikein_small.fa samtools faidx genome/hg38/fasta/spikein_small.fa Long RNA-seq /BioII/lulab_b/wangsiqi/exRNA/exRNA-panel/pico-smart/exSeek/ERCC-spikeIn cp /BioII/lulab_b/wangsiqi/exRNA/exRNA-panel/pico-smart/exSeek/ERCC-spikeIn/ERCC92.fa genome/hg38/fasta/spikein_long.fa samtools faidx genome/hg38/fasta/spikein_long.fa BigWig files dest=\"/BioII/lulab_b/shared/projects/exSeek/output/exorbase/bigwig\" [ -d \"$dest\" ] || mkdir -p \"$dest\" rsync -rav --delete /Share/home/shibinbin/projects/exSeek-dev/output/exorbase/bigwig/ \"$dest/\" bin/create_igv.py -r genome/hg38 -g hg38 -i templates/igv/main.html \\ -o igv.html \\ --track output/exorbase/bigwig/SRR5679904.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5679904.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5679905.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5679905.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5679906.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5679906.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5679907.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5679907.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5679908.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5679908.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5679909.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5679909.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5687235.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5687235.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5687236.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5687236.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5687237.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5687237.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5687238.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5687238.genome_rmdup.+.bigWig Visualize domains bin/report.py visualize_domains --sample-classes data/scirep/sample_classes.txt \\ --features output/scirep/feature_selection/filter.viper_count.Norm_CPM.Batch_RUV.domains_combined/Normal-CRC/random_forest.10.robust/features.txt \\ --genome-dir genome/hg38 \\ --flanking 20 -o tmp/visualize_domains.pdf --output-dir output/scirep [ -d \"output/scirep/visualize_domains\" ] || mkdir -p output/scirep/visualize_domains for features in $(cat /home/chenxupeng/projects/exseek/output/selected_feature/scirep/selected_features.txt);do compare_group=$(echo $features | cut -d'/' -f5 ) bin/report.py visualize_domains --sample-classes data/scirep/sample_classes.txt \\ --features $features \\ --genome-dir genome/hg38 \\ --flanking 20 -o output/scirep/visualize_domains/${compare_group}.pdf --output-dir output/scirep done Feature selection bin/machine_learning.py cross_validation \\ --matrix output/scirep/matrix_processing/filter.viper_count.Norm_CPM.Batch_RUV.domains_combined.txt \\ --sample-classes data/scirep/sample_classes.txt \\ -o tmp/cross_validation \\ --transpose \\ --positive-class 'Colorectal Cancer' --negative-class 'Healthy Control' \\ --cv-params '{\"splitter\": \"stratified_shuffle_split\", \"n_splits\": 5, \"test_size\": 0.2}' \\ --zero-fraction-filter \\ --log-transform '{\"base\": 2}' \\ --rpkm-filter '{\"threshold\": 10}' \\ --scaler robust \\ --selector robust --selector-params '{\"cv\": {\"splitter\": \"stratified_shuffle_split\", \"n_splits\": 10, \"test_size\": 0.2}}' \\ --grid-search \\ --grid-search-param-grid '{\"n_estimators\": [25, 50, 75], \"max_depth\": [3, 4, 5]}' \\ --grid-search-cv-params '{\"splitter\": \"stratified_shuffle_split\", \"n_splits\": 5, \"test_size\": 0.2}' \\ --classifier random_forest Notes 2018.12.29 Feature selection with pairs of features Find enriched rRNA fragments Validate tRNA fragment features","title":"Run pipeline"},{"location":"run_pipeline/#generate-sequential-mapping-snakefile","text":"snakemake --snakefile snakemake/prepare_genome.snakemake --configfile snakemake/config.yaml --rerun-incomplete -k","title":"Generate sequential mapping snakefile"},{"location":"run_pipeline/#scirep","text":"bin/generate_snakemake.py sequential_mapping --rna-types rRNA,miRNA,piRNA,Y_RNA,srpRNA,tRNA,snRNA,snoRNA,lncRNA,mRNA,tucpRNA \\ -o snakemake/sequential_mapping.snakemake snakemake --snakefile snakemake/mapping_small.snakemake --configfile config/scirep.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" snakemake --snakefile snakemake/expression_matrix.snakemake --configfile config/scirep.yaml --rerun-incomplete -k snakemake --snakefile snakemake/feature_selection.snakemake --configfile config/scirep.yaml --rerun-incomplete -k snakemake --snakefile snakemake/feature_selection.snakemake --configfile config/scirep.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" snakemake --snakefile snakemake/call_domains_long.snakemake --configfile config/scirep.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" snakemake --snakefile snakemake/bigwig.snakemake --configfile config/scirep.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" export PATH=$PWD/singularity/wrappers:$PATH PATH=\"$PWD/singularity/wrappers:$PATH\" snakemake --snakefile snakemake/normalization.snakemake --configfile config/scirep.yaml --rerun-incomplete -k bin/report.py visualize_domains --sample-ids-file data/scirep/sample_ids.txt \\ --output-dir output/scirep \\ --count-matrix output/scirep/count_matrix/domains_combined.txt \\ --features output/scirep/feature_selection/filter.scimpute_count.Norm_CPM.Batch_RUV.domains_combined/Normal-CRC/random_forest.10.robust/features.txt \\ --chrom-sizes genome/hg38/chrom_sizes/transcriptome_genome \\ --output-file tmp/visualize_domains.pdf bin/feature_selection.py calculate_clustering_score \\ --matrix output/scirep/matrix_processing/filter.scimpute_count.Norm_null.domains_combined.txt \\ --sample-classes data/scirep/sample_classes.txt --transpose snakemake --snakefile snakemake/evaluate_features.snakemake --configfile config/scirep.yaml","title":"SciRep"},{"location":"run_pipeline/#lulab-hcc","text":"/Share/home/caojingyi/exRNA/process/18.new_hcc_lulab/Snakefile snakemake --snakefile snakemake/mapping_small.snakemake --configfile config/lulab_hcc.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" \\ snakemake --snakefile snakemake/mapping_small.snakemake --configfile config/lulab_hcc.yaml --rerun-incomplete -k snakemake --snakefile snakemake/expression_matrix.snakemake --configfile config/lulab_hcc.yaml --rerun-incomplete -k snakemake --snakefile snakemake/normalization.snakemake --configfile config/lulab_hcc.yaml --rerun-incomplete -k snakemake --snakefile snakemake/feature_selection.snakemake --configfile config/lulab_hcc.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" snakemake --snakefile snakemake/evaluate_features.snakemake --configfile config/lulab_hcc.yaml","title":"Lulab HCC"},{"location":"run_pipeline/#exorbase","text":"# subsample reads [ -d \"data/exorbase_test/fastq\" ] || mkdir -p \"data/exorbase_test/fastq\" cp data/exorbase/*.txt data/exorbase_test for f in data/exorbase/fastq/*.fastq;do sample_id=$(basename $f) sample_id=${sample_id/.fastq/} echo data/exorbase_test/fastq/${sample_id}.fastq head -n 400000 $f > data/exorbase_test/fastq/${sample_id}.fastq done snakemake --snakefile snakemake/mapping_long.snakemake --rerun-incomplete -k --configfile config/exorbase.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" -j60 snakemake --snakefile snakemake/normalization.snakemake --configfile config/exorbase.yaml --rerun-incomplete -k snakemake --snakefile snakemake/feature_selection.snakemake --configfile config/exorbase.yaml --rerun-incomplete -k","title":"exoRBase"},{"location":"run_pipeline/#tcga-mirna-seq-crc","text":"snakemake --snakefile snakemake/bam_to_fastx.snakemake --rerun-incomplete -k --configfile config/tcga_crc.yaml snakemake --snakefile snakemake/mapping_small.snakemake --rerun-incomplete -k --configfile config/tcga_crc.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\"","title":"TCGA miRNA-seq (CRC)"},{"location":"run_pipeline/#tcga-mirna-seq-hcc","text":"snakemake --snakefile snakemake/bam_to_fastx.snakemake --rerun-incomplete -k --configfile config/tcga_hcc.yaml snakemake --snakefile snakemake/mapping_small.snakemake --rerun-incomplete -k --configfile config/tcga_hcc.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" snakemake --snakefile snakemake/bigwig.snakemake --configfile config/tcga_hcc.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" snakemake --snakefile snakemake/call_domains_long.snakemake --configfile config/tcga_hcc.yaml --rerun-incomplete -k \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\"","title":"TCGA miRNA-seq (HCC)"},{"location":"run_pipeline/#gse113994-healthy-cfrna-pnas-2018","text":"snakemake --snakefile snakemake/quality_control.snakemake --rerun-incomplete -k --configfile config/GSE113994.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" snakemake --snakefile snakemake/mapping_small.snakemake --rerun-incomplete -k --configfile config/GSE113994.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\"","title":"GSE113994 (Healthy, cfRNA, PNAS 2018)"},{"location":"run_pipeline/#gse45722-healthy-exosome-bmc-genomics-2013","text":"snakemake --snakefile snakemake/quality_control.snakemake --rerun-incomplete -k --configfile config/GSE45722.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" -j40 snakemake --snakefile snakemake/mapping_small.snakemake --rerun-incomplete -k --configfile config/GSE45722.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" -j40","title":"GSE45722 (Healthy, exosome, BMC Genomics 2013)"},{"location":"run_pipeline/#gse114711-healthy-exosome-scientific-reports-2018","text":"snakemake --snakefile snakemake/quality_control.snakemake --rerun-incomplete -k --configfile config/GSE114711.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" -j40 snakemake --snakefile snakemake/mapping_small.snakemake --rerun-incomplete -k --configfile config/GSE114711.yaml \\ --cluster-config snakemake/cluster.yaml \\ --cluster \"bsub -q {cluster.queue} -J {cluster.name} -e {cluster.stderr} -o {cluster.stdout} -R {cluster.resources} -n {cluster.threads}\" -j40","title":"GSE114711 (Healthy, exosome, Scientific Reports 2018)"},{"location":"run_pipeline/#gini-index-comparison-between-exrna-and-tcga","text":"for dataset in 'scirep' 'tcga_crc' 'tcga_hcc' 'GSE114711' 'GSE45722';do mkdir -p \"output/${dataset}/analysis\" echo bin/extract_bigwig.py abundant_rna_coverage_matrix \\ --matrix output/${dataset}/count_matrix/transcript.txt \\ --bigwig-pattern \"output/${dataset}/tbigwig/{sample_id}.{gene_type}.bigWig\" -n 100 \\ -o output/${dataset}/analysis/abundant_rna_coverage_matrix.h5 done","title":"Gini index comparison between exRNA and TCGA"},{"location":"run_pipeline/#integrated-dataset-scirep2016-gse45722-gse114711","text":"","title":"Integrated dataset SciRep2016, GSE45722, GSE114711"},{"location":"run_pipeline/#copy-files","text":"dataset='exosome_small' mkdir -p data/${dataset} sources=(scirep GSE45722 GSE114711) # sample_ids.txt cat data/scirep/sample_ids.txt data/GSE45722/sample_ids.txt \\ data/GSE114711/sample_ids.txt > data/${dataset}/sample_ids.txt # sample_classes.txt { awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,$2}' data/scirep/sample_classes.txt awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,\"Healthy Control\"}' data/GSE45722/sample_classes.txt awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,\"Healthy Control\"}' data/GSE114711/sample_classes.txt } > data/${dataset}/sample_classes.txt # batch_info.txt { echo -e 'sample_id\\tpublication' awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,\"scirep\"}' data/scirep/sample_classes.txt awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,\"GSE45722_healthy\"}' data/GSE45722/sample_classes.txt awk 'BEGIN{OFS=\"\\t\";FS=\"\\t\"}{print $1,\"GSE114711_healthy\"}' data/GSE114711/sample_classes.txt } > data/exosome_small/batch_info.txt # count_matrix/domains_long.txt mkdir -p output/${dataset}/count_matrix bin/preprocess.py merge_data_frames \\ -i output/scirep/count_matrix/transcript.txt \\ -i output/GSE45722/count_matrix/transcript.txt \\ -i output/GSE114711/count_matrix/transcript.txt \\ --on feature --fillna 0 \\ -o output/${dataset}/count_matrix/transcript.txt # domains_by_sample/20/05 mkdir -p output/${dataset}/domains_by_sample/20/05 rsync -ra output/scirep/domains_by_sample/20/05/*.bed output/${dataset}/domains_by_sample/20/05 rsync -ra output/GSE45722/domains_by_sample/20/05/*.bed output/${dataset}/domains_by_sample/20/05 rsync -ra output/GSE114711/domains_by_sample/20/05/*.bed output/${dataset}/domains_by_sample/20/05 # tbed mkdir -p output/${dataset}/tbed mkdir -p output/${dataset}/gbed for d in ${sources[@]};do rsync -rav output/$d/tbed/ output/${dataset}/tbed rsync -rav output/$d/gbed/ output/${dataset}/gbed done","title":"Copy files"},{"location":"run_pipeline/#analysis","text":"bin/exseek.py call_domains -d exosome_small","title":"Analysis"},{"location":"run_pipeline/#data","text":"","title":"Data"},{"location":"run_pipeline/#exorbase_1","text":"[ -d data/exorbase/fastq ] || mkdir -p data/exorbase/fastq ln -f -s /BioII/lulab_b/shared/projects/exRNA/published_exRNA/exosome_exoRBase/exosome_GSE100063_CRC/fastq/*.fastq data/exorbase/fastq ln -f -s /BioII/lulab_b/caojingyi/exoRBase/fastq/HCC/*.fastq data/exorbase/fastq ln -f -s /BioII/lulab_b/caojingyi/exoRBase/fastq/Normal/*.fastq data/exorbase/fastq ln -f -s /BioII/lulab_b/shared/projects/exRNA/published_exRNA/exosome_exoRBase/exosome_GSE100232_PAAD/fastq/*.fastq data/exorbase/fastq ln -f -s /BioII/lulab_b/shared/projects/exRNA/published_exRNA/exosome_exoRBase/exosome_GSE99985_CHD/fastq/*.fastq data/exorbase/fastq ln -f -s /BioII/lulab_b/caojingyi/exoRBase/fastq/*.fastq data/exorbase/fastq ls data/exorbase/fastq | cut -d'_' -f1 | sort | uniq > data/exorbase/sample_ids.txt ln -f -s /BioII/zhuyumin/exLocator/exosome_SR2018_GSE114711/1.fastq/*.fastq data/GSE114711/fastq","title":"exoRBase"},{"location":"run_pipeline/#spike-in","text":"","title":"Spike-in"},{"location":"run_pipeline/#small-rna-seq","text":"/BioII/lulab_b/wangsiqi/exRNA/exRNA-panel/NEB/03.1811_T4PNK/ExiSEQ-spikeIn cp /BioII/lulab_b/wangsiqi/exRNA/exRNA-panel/NEB/03.1811_T4PNK/ExiSEQ-spikeIn/ExiSEQ-spikeIn.fa genome/hg38/fasta/spikein_small.fa samtools faidx genome/hg38/fasta/spikein_small.fa","title":"Small RNA-seq"},{"location":"run_pipeline/#long-rna-seq","text":"/BioII/lulab_b/wangsiqi/exRNA/exRNA-panel/pico-smart/exSeek/ERCC-spikeIn cp /BioII/lulab_b/wangsiqi/exRNA/exRNA-panel/pico-smart/exSeek/ERCC-spikeIn/ERCC92.fa genome/hg38/fasta/spikein_long.fa samtools faidx genome/hg38/fasta/spikein_long.fa","title":"Long RNA-seq"},{"location":"run_pipeline/#bigwig-files","text":"dest=\"/BioII/lulab_b/shared/projects/exSeek/output/exorbase/bigwig\" [ -d \"$dest\" ] || mkdir -p \"$dest\" rsync -rav --delete /Share/home/shibinbin/projects/exSeek-dev/output/exorbase/bigwig/ \"$dest/\" bin/create_igv.py -r genome/hg38 -g hg38 -i templates/igv/main.html \\ -o igv.html \\ --track output/exorbase/bigwig/SRR5679904.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5679904.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5679905.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5679905.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5679906.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5679906.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5679907.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5679907.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5679908.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5679908.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5679909.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5679909.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5687235.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5687235.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5687236.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5687236.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5687237.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5687237.genome_rmdup.+.bigWig \\ --track output/exorbase/bigwig/SRR5687238.genome_rmdup.-.bigWig \\ --track output/exorbase/bigwig/SRR5687238.genome_rmdup.+.bigWig","title":"BigWig files"},{"location":"run_pipeline/#visualize-domains","text":"bin/report.py visualize_domains --sample-classes data/scirep/sample_classes.txt \\ --features output/scirep/feature_selection/filter.viper_count.Norm_CPM.Batch_RUV.domains_combined/Normal-CRC/random_forest.10.robust/features.txt \\ --genome-dir genome/hg38 \\ --flanking 20 -o tmp/visualize_domains.pdf --output-dir output/scirep [ -d \"output/scirep/visualize_domains\" ] || mkdir -p output/scirep/visualize_domains for features in $(cat /home/chenxupeng/projects/exseek/output/selected_feature/scirep/selected_features.txt);do compare_group=$(echo $features | cut -d'/' -f5 ) bin/report.py visualize_domains --sample-classes data/scirep/sample_classes.txt \\ --features $features \\ --genome-dir genome/hg38 \\ --flanking 20 -o output/scirep/visualize_domains/${compare_group}.pdf --output-dir output/scirep done","title":"Visualize domains"},{"location":"run_pipeline/#feature-selection","text":"bin/machine_learning.py cross_validation \\ --matrix output/scirep/matrix_processing/filter.viper_count.Norm_CPM.Batch_RUV.domains_combined.txt \\ --sample-classes data/scirep/sample_classes.txt \\ -o tmp/cross_validation \\ --transpose \\ --positive-class 'Colorectal Cancer' --negative-class 'Healthy Control' \\ --cv-params '{\"splitter\": \"stratified_shuffle_split\", \"n_splits\": 5, \"test_size\": 0.2}' \\ --zero-fraction-filter \\ --log-transform '{\"base\": 2}' \\ --rpkm-filter '{\"threshold\": 10}' \\ --scaler robust \\ --selector robust --selector-params '{\"cv\": {\"splitter\": \"stratified_shuffle_split\", \"n_splits\": 10, \"test_size\": 0.2}}' \\ --grid-search \\ --grid-search-param-grid '{\"n_estimators\": [25, 50, 75], \"max_depth\": [3, 4, 5]}' \\ --grid-search-cv-params '{\"splitter\": \"stratified_shuffle_split\", \"n_splits\": 5, \"test_size\": 0.2}' \\ --classifier random_forest","title":"Feature selection"},{"location":"run_pipeline/#notes","text":"","title":"Notes"},{"location":"run_pipeline/#20181229","text":"Feature selection with pairs of features Find enriched rRNA fragments Validate tRNA fragment features","title":"2018.12.29"},{"location":"small_rna_mapping/","text":"","title":"Small RNA-seq mapping"}]}